[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Estatística & Probabilidade aplicada às Engenharias e Ciências",
    "section": "",
    "text": "Bem-vindo\nEste é um livro digital da 1ª edição do “Estatística & Probabilidade aplicado às Engenharias e Ciências”, um livro com o selo Democratizando Conhecimento (DC). O Livro é voltado para quem deseja iniciar no estudo sobre a estatística. Daremos as bases e fundamentos, de modo aplicado a problemas na área das Engenharias e Ciências, de assuntos desde o que é uma população, amostra, até estudos sobre a teoria de decisão, estudo de regressão, dentre outros assuntos básicos, para que assim, a partir desse material, o leitor tenha base para ler, assuntos mais aprofundados na área da estatística.",
    "crumbs": [
      "Bem-vindo"
    ]
  },
  {
    "objectID": "index.html#sugestões-e-críticas",
    "href": "index.html#sugestões-e-críticas",
    "title": "Estatística & Probabilidade aplicada às Engenharias e Ciências",
    "section": "Sugestões e críticas",
    "text": "Sugestões e críticas\nSugestões e críticas sobre o livro podem ser enviadas para livrosdeben@gmail.com.",
    "crumbs": [
      "Bem-vindo"
    ]
  },
  {
    "objectID": "cap01.html",
    "href": "cap01.html",
    "title": "1  Definições Gerais da Estatística e técnicas de somatórios",
    "section": "",
    "text": "1.1 Introdução\nEm pleno século XXI, passamos por um processo de transformação na era digital. Uma grande massa de informações surge instantaneamente a cada momento sobre os mais diversos temas possíveis. Por exemplo, nas redes sociais quando percebemos o número de curtidas de uma determinada declaração, número de downloads de um determinado vídeo, a repercussão que determinada declaração proporciona, o número de propagandas, etc, tudo isso cria um grande banco de dados sobre os usuários, que hoje se torna mais valiosa do que a própria moeda local. Isso é a nova revolução chamada “Big Data”. Por meio de grande banco de dados, podemos por exemplo, traçar um perfil dos usuários, como eles se comportam, quais as suas preferências, escolhas, diversão, etc. Contudo, o entendimento dessas informações podem não ser tão claras, ou devido a complexidade do problema, ou pela quantidade de informações recebidas rapidamente, ou outros fatores. Diversos outros exemplos poderiam ser citados, tudo isso para mostrar a necessidade de entender o que está por trás desses dados, cuja compreensão é o grande objetivo nessa era global.\nNesse enfoque, temos a Estatística como Ciência que fornece métodos para coleta, organização, descrição, análise e interpretação de dados (observacionais ou experimentais) e para a utilização dos mesmos na tomada de decisões. Os dados são informações retiradas de um conjunto de elementos de interesse. Podemos estar interessados na Produção anual de Gás Natural Não associado com o petróleo (GASN) de um determinado país, e ao longo dos anos, coletarmos informações para ao final, por exemplo, termos informações que nos indique o potencial energético desse recurso natural nesse local ou consequências dessa fonte energética na economia do país.\nAssim, por meio da utilização de técnicas estatísticas, tentamos entender as informações contidas nos dados. Devido a complexidade dessas informações em algumas situações, o estudo sobre essas técnicas têm aumentado, fazendo parte do nosso cotidiano. Nessa era digital, a grande quantidade de informações é gigantesca e valiosa, e as empresas tentam entender o que está por trás desses dados, ou você acha que o Facebook foi criado simplesmente para gerar entreterimento às pessoas? Ou você também acha que o Google criou uma plataforma de pesquisa simplesmente para facilitar a vida das pessoas? Algo muito nobre está por trás de tudo isso, os dados.\nNo passado, tratar uma grande massa de números era uma tarefa custosa e cansativa, que exigia horas de trabalho tedioso. Porém, hoje, esse volume de informações pode ser analisado rapidamente por meio de um computador pessoal e programas adequados. O computador contribui positivamente na difusão e uso dos métodos estatísticos. Você já se perguntou como é que lojas virtuais lhe oferta produtos sendo que nunca acessou aquele site antes? Já percebeu que o Netflix quando lhe oferece uma série a tela de entrada as vezes se altera? Tudo isso é fruto das técnicas de máquinas de aprendizagem (do inglês, Machine Learning), uma área da inteligência artificial. Juntamente com a estatística, essas ferramentas estão presentes em várias das tecnologias que utilizamos hoje.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Definições Gerais da Estatística e técnicas de somatórios</span>"
    ]
  },
  {
    "objectID": "cap01.html#defgerest",
    "href": "cap01.html#defgerest",
    "title": "1  Definições Gerais da Estatística e técnicas de somatórios",
    "section": "1.2 Definições gerais da Estatística",
    "text": "1.2 Definições gerais da Estatística\nInicialmente, podemos dividir a Estatística em três ramos:\n\nEstatística Descritiva;\nProbabilidade;\nEstatística Inferencial.\n\nDefinimos cada uma dessas áreas a seguir. A primeira delas é a Estatística Descritiva, apresentada na Definição 1.1.\n\nDefinição 1.1: Estatística Descritiva ou Estatística DedutivaUm conjunto de técnicas estatísticas destinadas a coleta, descrição e sintetização dos dados, a fim de podermos entender características de interesse da população1, é chamada de Estatística Descritiva ou Estatística Dedutiva.\n\n\nAs técnicas mencionadas na Definição 1.1 são: coleta, organização, tabulação, representação gráfica, bem como medidas que sintetizam todas as informações contidas nos dados.\nAs quatro primeiras técnicas serão abordadas no Capítulo 2. As medidas serão estudadas nos Capítulo 3 e Capítulo 4. Essa fase é de grande relevância, pois com base na Estatística Descritiva podemos sintetizar as informações contidas nos dados, e torná-las mais compreensíveis que de outro modo seriam complexas de serem entendidas.\nNo Capítulo 7, daremos uma maior ênfase sobre a definição de uma população. De modo simples, podemos definir como um conjunto de elementos com uma característica em comum. Uma vez definida a característica que delimita essa população (subseção 1.3), e também a característica de interesse (chamada de variável) da pesquisa, faremos a coleta dos valores observados da variável em cada elemento da população ou de um subconjunto (amostra). Os valores observados são chamados de dados.\n\nDefinição 1.2: Dado ou valor observadoA característica de interesse observada em cada elemento da população é definida como valor observado ou dado.\n\n\nTodas as técnicas mencionadas anteriormente auxiliam na descrição dos dados, uma não necessariamente sobrepõe a outra. Vejamos, a Company (2018) lançou o relatório técnico de 2018 sobre os diversos tipos de produção de energias dos países, e na Figura 1.1 é mostrado um gráfico que sintetiza a produção e o consumo de petróleo do Brasil, em milhões de barris por dia (MMbbl/d), nos períodos de 2007 a 2017.\n\n# BP Statistical Review 2018\n\n# Anexando pacote\nlibrary(ggplot2)\n# Se nao existir o pacote, use\n#install.packages(\"ggplot2\")\n\n# Producao e consumo de petroleo no brasil (Mtoe)\nano  &lt;- as.factor(c(2007:2017, 2007:2017))\nprodcons &lt;- c(1831, 1897, 2029, 2137, 2179, 2145, 2110, 2341, 2525, 2608, 2734,\n              2308, 2481, 2498, 2716, 2839, 2915, 3124, 3242, 3181, 3013, 3017)\nid &lt;- c(rep(\"Produção\", 11), rep(\"Consumo\",11))\n\n# Objeto que armazena as informacoes\ndados &lt;- data.frame(ano, Legenda = id, prodcons)\n\n# Funcao para criacao do grafico de barras\nggplot(dados, aes(x = ano, y = prodcons, fill = Legenda)) +\n  geom_bar(position = \"dodge\", stat = \"identity\") +\n  xlab(\"Ano\") + ylab(\"Petróleo (MMbbl/d)\") \n\n\n\n\n\n\n\nFigura 1.1: Produção e consumo de petróleo do Brasil nos períodos de 2007 a 2017.\n\n\n\n\n\nO gráfico nos revela que o Brasil produz petróleo abaixo do que necessitaria para o consumo, de tal modo que a produção é 27,71% a menos do que o consumo. Isso explica o porquê do Brasil como grande produtor de petróleo, ainda assim, necessita importar essa fonte de energia. Contudo, o gráfico não apresenta um resumo perfeito. Por exemplo, mesmo a produção de petróleo sendo mais baixa do que o consumo, o coeficiente de variação (assunto abordado no Capítulo 4 dessas dessas duas variáveis, são 12,99% e 10,93%, respectivamente, calculados de acordo com a Tabela 1.1. Isso implica, que as variações da produção de petróleo são maiores do que as do consumo, no Brasil. Observe que essas últimas informações não podem ser vistas facilmente na Figura 1.1, mas juntamente com o auxílio das medidas numéricas (medidas de posição e dispersão) e as medidas gráficas, podemos complementar as informações, e assim, obter uma melhor descrição sobre essas informações.\n\n\n\nTabela 1.1: Produção e consumo de petróleo do Brasil nos períodos de 2007 a 2017.\n\n\n\n\n\n\n\n(a) Dados de 2007 a 2012\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAno\n2007\n2008\n2009\n2010\n2011\n2012\n\n\n\n\nProdução\n1831\n1897\n2029\n2137\n2179\n2145\n\n\nConsumo\n2308\n2481\n2498\n2716\n2839\n2915\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b) Dados de 2013 a 2017\n\n\n\n\n\nAno\n2013\n2014\n2015\n2016\n2017\n\n\n\n\n\nProdução\n2110\n2341\n2525\n2608\n2734\n\n\n\nConsumo\n3124\n3242\n3181\n3013\n3017\n\n\n\n\n\n\n\n\n\n\n\n\nQuando precisamos estender as informações contidas em um subconjunto (amostra) de dados para todo o conjunto (população), necessitamos de técnicas específicas dentro da estatística para garantir que estas informações sejam o mais verossímil possível. Técnicas estas são chamadas de Estatística Inferencial, definida a seguir.\n\nDefinição 1.3: Estatística Inferencial ou Estatística IndutivaO estudo de técnicas que visam estender (extrapolar) a informação contida na amostra à população, chamamos de Estatística Inferencial ou Estatística Indutiva.\n\n\nAs técnicas abordadas na Estatística Inferencial estão relacionadas a determinar características (parâmetros) populacionais desconhecidas, ou até mesmo fazer afirmações sobre esses parâmetros.\nA determinação de parâmetros por meio de características amostrais (estimadores) que chamamos de Estimação será abordado no Capítulo 9. As afirmações realizadas sobre estes parâmetros, chamadas de hipóteses, e serão estudadas no Capítulo 10.\nA Definição 1.3 nos mostra que por meio da Estatística, podemos tomar decisões sobre uma população através da amostra. Isso se faz necessário muitas vezes em uma pesquisa, devido a duas coisas preciosas: tempo e dinheiro. Muito embora, se tivermos acesso a todos os elementos de uma população, não se faz necessário o uso de técnicas da inferência estatística, e daí realizamos o que chamamos de Censo.\nA forma de como se obter uma amostra é um dos passos mais importante em todo o processo da análise, uma vez que não adianta está com todo o aparato técnico se as informações contidas nessas amostra não são representativas da população. Para isso, temos uma área na estatística chamada Amostragem, que será responsável pelo desenvolvimento de métodos de como selecionar os elementos populacionais para compor a amostra de modo que as principais características contidas na população sejam preservadas na amostra. Esse assunto será estudado no Capítulo 7.\nContudo, sabemos que entender uma população por um subconjunto desta, gera-se uma incerteza ou erro. A estatística tenta minimizar esse erro o máximo possível, isto é, reduzir as incertezas das informações contidas na amostra e extrapolar essas informações para a população. Para isso, usamos a probabilidade como suporte, assunto estudado nos Capítulos 5, 6 e 8.\n\nDefinição 1.4: ProbabilidadeA teoria matemática que estuda a incerteza de fenômenos aleatórios é chamada de probabilidade.\n\n\nOs fenômenos aleatórios estão relacionados a situações que dificilmente saberemos com certeza do que pode acontecer. Por exemplo, se arremessarmos um dado de seis faces de tamanhos iguais e desejarmos saber a face superior desse dado antes do arremesso, não temos como afirmar com certeza qual o valor, se considerarmos as faces numerados de 1 a 6. Observe que, mesmo sabendo quais os valores das faces, não podemos afirmar com exatidão qual o valor da face superior antes do arremesso. Mas, por meio da probabilidade, podemos minimizar essa incerteza e dizer que há aproximadamete 17% de chance de um número escolhido ocorrer.\nEm nosso cotidiano, a probabilidade auxilia na decisão de um fabricante de cola de empreender uma grande publicidade no seu produto visando aumentar sua participação no mercado, ou na decisão de parar de imunizar pessoas com menos de vinte anos contra determinada doença, ou ainda na decisão de arriscar-se a atravessar uma rua no meio do quarteirão. Esses pequenos exemplos mostram a relação que a probabilidade tem com a inferência estatística, pois ela nos auxiliará a tomar decisões em procedimento inferencias tentando traduzir para a nossa linguagem do dia-a-dia.\nAo final dessas definições gerais, podemos mostrar uma ilustração, Figura 1.2, que facilitará a compreensão do que abordamos nessa seção. Por fim, um último assunto estudado nesse livro, Capítulo 11, será o estudo da correlação e regressão linear, quando estamos interessado em estudar a forma e o grau relação entre duas ou mais variáveis.\nTodos esses assuntos estudaremos nos capítulos seguintes com um certo detalhamento, dando ênfase a exemplos práticos estudados em nosso campo de trabalho. Alguns Capítulos poderão conter uma seção chamada Aprofundamento, com o intuito de apresentar uma maior profundidade sobre o tema estudado. Alguns apêndices serão criados nesse livro para dar suporte ao conteúdo.\n\n\n\n\n\n\nFigura 1.2: Ilustração animada sobre as disposições gerais da Estatística.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Definições Gerais da Estatística e técnicas de somatórios</span>"
    ]
  },
  {
    "objectID": "cap01.html#sec-estpesqcient",
    "href": "cap01.html#sec-estpesqcient",
    "title": "1  Definições Gerais da Estatística e técnicas de somatórios",
    "section": "1.3 Estatística na pesquisa científica",
    "text": "1.3 Estatística na pesquisa científica\nO trabalho estatístico é parte integrante do método científico. Segundo Silva (2007), definimos,\n\nDefinição 1.5: Método científicoUm conjunto de regras e procedimentos para a obtenção de resultados, isto é, uma conclusão, sobre um determinado problema de uma pesquisa científica, é denominado de Método científico.\n\n\nA pesquisa científica por sua vez, desenvolve conhecimentos para um saber mínimo de um determinado fenômeno estudado. A pesquisa científica se inicia a partir de um problema dentro da população em estudo. Por meio desse problema surgem diversas indagações.\n\nExemplo 1.1\nNo Estado de Minas Gerais houveram dois acidentes, de grandes proporções nos últimos anos, envolvendo barragens que armazenam rejeitos de mineração. Os acidentes ocorreram na cidade de Mariana e Brumadinho, vitimando centenas de pessoas e um impacto ambiental imenso com o arrombamentos dessas barragens. Indagamos:\n\nQuem são os responsáveis por essas duas tragédias?\nQuanto será o custo o impacto dessas tragédias?\nQuando começou esse problema trágico?\nQue medidas poderiam ter sido tomadas para que isso não acontecesse?\nOnde estão os órgãos de fiscalização para coibir esses acontecimentos, uma vez que no intervalo de três anos ocorreram duas catástrofes dessas?\n\n\n\nCom essas indagações lançadas para o estudo do problema, e definido a questão inicial dentre as citadas ou outras que possam surgir, o método científico se encarregará de estruturar a pesquisa de modo preciso e sistemático. A resposta a essas indagações resultam em um plano de pesquisa que consiste em:\n\nIdentificar o problema e o objetivo da pesquisa\nA identificação do problema é o norte da pesquisa. Por meio das perguntas iniciais, procuraremos entender as possíveis causas e efeitos da situação, formulando assim o problema. Nessa fase, devemos identificar a população e os elementos que a compõe, como também os demais procedimentos da pesquisa, inclusive o objetivo do trabalho, no qual se estipula a finalidade do presente estudo. Esse passo é o combustível que impulsiona a pesquisa científica.\nFormular a hipótese estudada\nA hipótese é uma afirmação atribuída pelo pesquisador sobre a população, com o intuito de responder a(s) indagação(ões) do problema, atingindo o objetivo da pesquisa. Essa afirmação pode ser sugerida pela literatura ou até mesmo construída pelo próprio pesquisador. De toda forma, a elaboração dessa hipótese deve ser bem formulada para que sua não rejeição ou rejeição consiga responder a indagação inicial e o objetivo seja atingido, ou desencadeie novas dúvidas e outras pesquisas possam surgir.\n\n\nExemplo 1.2Tentando inspecionar, como controle de qualidade, uma remessa de peças enviadas por um fornecedor de uma determinada fábrica de peças para indústria de automóveis, garante que essa remessa não há mais de 8% de peças com defeito. Dessa forma o problema foi lançado com a seguinte indagação: será que essa remessa não há mais de 8% de peças com defeito? Lancemos a hipótese a ser testada2: \\[\\begin{align*}\n      \\left\\{\\begin{array}{cl}\n      H_0: & \\textrm{A porcentagem de peças com defeito é igual}\\\\\n           & \\textrm{ou superior a 8\\%.}\\\\\n      \\end{array}\\right.\n\\end{align*}\\]\nPerguntamos aos leitores: essa indagação elucida a indagação do problema? A avaliação dessa hipótese será realizada na análise e interpretação de dados do qual aplicaremos técnicas específicas para refutar ou não a hipótese estudada \\(H_0\\). Supondo que não tenhamos evidências estatísticas para a rejeição dessa hipótese, e decidimos não rejeitá-la, a dúvida que fica é: será que a hipótese estudada foi não rejeitada porque a quantidade de peças é igual ou superior a 8%? Observe, se foi 8% a afirmação inicial do fornecedor das peças está correta. Entretanto, se o número de peças foi superior a 8%, o que o fornecedor afirmou está equivocado. Concluímos, que a hipótese não foi bem elaborada para responder a indagação inicial no problema levantado. A forma correta deveria ser:\n\\[\\begin{align*}\n      \\left\\{\\begin{array}{cl}\n      H_0: & \\textrm{A porcentagem de peças com defeito é menor }\\\\\n           & \\textrm{ou igual a 8\\%.}\\\\\n      \\end{array}\\right.\n\\end{align*}\\]\nA importância do desenvolvimento das hipóteses é muito importante, uma vez que podemos tomar decisões totalmente equivocadas, e assim, todo o trabalho estudado ser desperdiçado em vão.\n\n\n\nRevisão de literatura\nUm passo importante na pesquisa é a confirmação ou o não das respostas encontradas no estudo. É por meio dos trabalhos já publicados que embasamos nossas argumentações, corroborando-as ou refutando-as. Com isso, surge o progresso da ciência, não havendo uma verdade absoluta.\nFormular um Plano amostral e Identificar as variáveis de interesse para a pesquisa (Capítulo 7).\nColeta, crítica e tratamento dos dados\nApós definirmos cuidadosamente o problema que se quer pesquisar, elabora-se um delineamento e damos início á coleta dos dados necessários à sua descrição. Obtidos os dados, eles devem ser cuidadosamente criticados, à procura de possíveis falhas e imperfeições, a fim de não incorrermos em erros grosseiros, que possam influir sensivelmente os resultados. Por fim, tratamos os dados, que consiste no processamento das informações e a disposição mediante critérios de classificação, podendo ser manual ou eletrônico.\nApresentação dos dados\nPor mais diversa que seja a finalidade, os dados devem ser apresentados sob forma adequada (tabelas e gráficos) tornando mais fácil e simples a sua descrição.\nAnálise e interpretação dos resultados\nApós a apresentação dos dados devemos calcular as medidas típicas convenientes para fazermos uma análise dos resultados obtidos, através de métodos estatísticos (Estatística inferencial ou indutiva), e tirarmos desses resultados conclusões e previsões.\nConclusão e derivação da conclusão que poderá rejeitar ou não a hipótese estudada, gerando assim, uma confirmação ou indagações para outros problemas\nÉ de responsabilidade de um especialista no assunto que está sendo pesquisado, que não é necessariamente um estatístico, relatar as conclusões de maneira que sejam facilmente entendidas por quem as for usar na tomada de decisões.\nApresentação dos resultados por meio de trabalhos científicos para a propagação do conhecimento sobre o problema estudado.\n\nEsses pontos do plano de pesquisa podem sofrer alterações em algumas metodologias científicas. Contudo, elas estão envolvidas direta ou indiretamente nas metodologias estudadas, sendo que não necessariamente elas ocorrem em todas as pesquisas nessa ordem, e que podem ser ilustrados na Figura 1.3.\n\n\n\n\n\n\nFigura 1.3: Fases do plano da pesquisa científica.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Definições Gerais da Estatística e técnicas de somatórios</span>"
    ]
  },
  {
    "objectID": "cap01.html#definições-básicas",
    "href": "cap01.html#definições-básicas",
    "title": "1  Definições Gerais da Estatística e técnicas de somatórios",
    "section": "1.4 Definições básicas",
    "text": "1.4 Definições básicas\nAo ser discutido na seção anterior sobre as definições gerais da Estatística, iniciaremos agora ao que chamamos de definições básicas, que consiste em definir formalmente alguns termos tais como população e amostra, como também os termos variável, dado ou valor observado. Essas definições serão importantes para o desenvolvimento do conteúdo do livro.\nO conjunto de todos os elementos dos quais temos o interesse de suas informações, chamamos esse conjunto de população. A palavra população, em nosso cotidiano, está sempre relacionado a um conjunto de pessoas que habitam um determinado local (país, cidade, etc.). Contudo, na estatística ampliamos a definição de população da seguinte forma,\n\nDefinição 1.6: PopulaçãoO conjunto finito ou infinito de todos os elementos com pelo menos uma característica comum, dos quais é de interesse para a pesquisa, denominamos de População. O número de elementos é denominado tamanho da população, denotado por \\(N\\).\n\n\nPercebemos pela Definição 1.6 que a idéia sobre população é mais geral. Podemos dizer que o conjunto de peças com defeitos fabricados por uma determinada empresa constitui uma população. Um outro exemplo é a concentração de metais pesados no Rio, sendo que o rio constitui a população. No primeiro caso, a população constitui a empresa que fabrica essas peças com defeitos, que por sua vez, essas peças representam os elementos dos quais a característica em comum a todas as peças é que foi fabricada por essa empresa e apresenta defeito. No segundo caso, a especificação dos elementos poderá não ser muito claro, pois é um caso de população infinita. Daremos mais detalhes sobre isso no Capítulo 7.\nEssa(s) característica(s) comum(s) deve(m) delimitar inequivocamente quais elementos que pertencem ou não à população. A notação usual para o número de elementos da população é “\\(N\\)”. A população pode ser Finita (quando pode ser enumerada) ou Infinita (quando não pode ser enumerada).\n\nDefinição 1.7: AmostraUm subconjunto de elementos da população é denominado amostra. O número de elementos da amostra é chamado de tamanho da amostra, sendo denotado por “\\(n\\)”.\n\n\nA amostra é necessariamente finita, pois todos os seus elementos serão examinados para efeito da realização do estudo estatístico desejado. Esse estudo está baseado em características de interesse da população para tentar responder as indagações iniciais do problema da pesquisa (Ver seção 1.3). Definimos essa característica como variável.\n\nDefinição 1.8: VariávelA característica pela qual desejamos que a população seja descrita é denominada de variável.\n\n\nA variável representa o mecanismo pelo qual podemos atingir o objetivo da pesquisa. Será por meio dos dados observados, isto é, do valor observado dessa variável assumido por cada elemento da população (ou da amostra), que faremos as análises específicas para se chegar a uma conclusão. Muitas vezes não trabalhamos apenas com uma única variável, dependendo da complexidade da pesquisa, poderemos estudar diversas variáveis ao mesmo tempo.\nA variável pode assumir diferentes valores de elemento para elemento, chamado de dado ou valor observado, como foi apresentado na Definição 1.2. A notação usual para a variável é \\(X\\), \\(Y\\), \\(Z\\), ou \\(X_i\\), \\(Y_i\\), \\(Z_i\\) para um particular elemento amostral, em que \\(i\\) \\(=\\) \\(1\\), \\(2\\), \\(\\ldots\\), \\(n\\). Definimos a natureza das variáveis, a seguir.\n\nDefinição 1.9: Natureza de uma variável\nDefinimos o tipo de variável pela sua natureza, isto é, pelo valor assumido em cada elemento da população ou amostra como:\n\nVariável qualitativa: é a variável cujo valor observado assume um valor com natureza de atributo ou categoria. Esta ainda se subdivide:\n\nNominal: Quando os valores não são possíveis de ordenação;\nOrdinal: Quando os valores são possíveis de ordenação, segundo um critério quantitativo.\n\nVariável quantitativa: é a variável cujo valor observado assume um valor com natureza numérica (enumerável ou não). Ainda podem ser divididas:\n\nDiscreta: Quando os valores são dados de contagem, isto é, descrevem uma quantidade contável, cujos potenciais valores dessa variável podem ser enumerados em um conjunto de valores;\nContínua: Quando os valores resultam de uma medida (ou mensuração), podendo assumir qualquer valor real entre dois extremos, e dessa forma não podemos enumerar seus valores.\n\n\n\n\nVejamos o Exemplo 1.3, para elucidar todas essas definições mencionadas anteriormente.\n\nExemplo 1.3: Desmatamento da Amazônia LegalO Brasil vem passando por um processo de desmatamento na Amazônia legal, que o mundo vem acompanhando nesses últimos anos. O Instituto Nacional de Pesquisas Espaciais (INPE) desenvolveu o PRODES3 (Programa de Monitoramento do Desmatamento da Amazônia) que vem acompanhando desde 1988, as taxas de desmatamento na região. Apresentamos a seguir, a Tabela 1.2, que apresenta algumas informações sobre esse tema em cada estado do qual compreende a Amazônia Legal, em que os dados da taxa acumulada de desmatamento por estado, estão disponíveis na página do INPE, em Amazônia Legal. Podemos verificar que apresentamos diversas variáveis para um melhor detalhamento da taxa de desmatamento na Amazônia legal, em relação a algumas informações sobre os estados que compõe essa região. Observemos que, quanto a natureza das variáveis, Região, UF, e Classificação, são variáveis qualitativas, pois os valores observados representam uma categoria. Apesar de representar uma qualidade, percebamos que classificação apresenta um ordenamento, referente a quantidade de desmatamento acumulado de cada estado, em que, o estado do Pará está em primeiro lugar, por ter sido o estado que mais desmatou, desde 1988. No caso, as variáveis Região e UF representam apenas categorias que não apresentam qualquer forma de ordenamento. Muito embora, os valores de Classificação estejam representados por números, a natureza é qualitativa. Portanto, Região e UF são variáveis qualitativas nominais, e Classificação, variável qualitativa ordinal.\nAs demais variáveis são Número de cidades, Desmatamento acumulado, Área total e População estimada. Conseguimos observar que Número de cidades e População estimada apresentam dados de contagem, logo, essas variáveis são quantitativas discretas. Isso significa, que entre dois valores consecutivos, há uma discretização, ou seja, o estado do Amapá está dentro da região da Amazônia legal, e tem 14 município. Já o estado de Roraima apresenta 15 municípios dentro da Amazônia Legal. Dessa forma, não há um potencial valor para a variável Número de Cidades, entre esses dois valores, isto é, 14,5. De outro modo, podemos ordenar em um conjunto enumerável todos os valores de uma variável quantitativa discreta.\nAgora, para o caso das variáveis Desmatamento e Área total, percebemos que os valores assumidos por essas variáveis não são dados de contagem, mas de medição, isto significa que não contamos área ou taxa de Desmatamento acumulado, mas sim, medimos. De outro modo, teoricamente nós não conseguimos identificar os potenciais valores de uma variável quantitativa contínua em certo certo conjunto enumerável, porque observe o valor da área total do estado do Pará, \\(1.245.870,00~km^2\\), se tivéssemos instrumentos de medidas mais precisos, esse valor não seria exatamente esse, poderia ter sido \\(1.245.870,001~km^2\\), \\(1.245.870,0001~km^2\\), \\(1.245.870,00001~k\n  m^2\\), e assim por diante. Dessa forma, em uma determinada ordem nós não conseguiríamos saber qual o próximo valor ordenado para a área, após observarmos a área do estado do Pará.\n\n\n\n\n\nTabela 1.2: Taxa de desmatamento acumulado, por estado, na Amazônia Legal, compreendido desde 1988 a 07/12/2020.\n\n\n\n\n\nRegião\nUF\nNº de cidades4\nDesmat. acum. (km\\(^2\\))\nÁrea total (km\\(^2\\))\nClas.5\nPop. estimada6\n\n\n\n\nNorte\nPA\n144\n157.667,00\n1.245.870,00\n1º\n8.690.745\n\n\nCentro-Oeste\nMT\n141\n147.926,00\n903.207,02\n2º\n3.526.220\n\n\nNorte\nRO\n52\n62.936,00\n237.765,20\n3º\n1.796.460\n\n\nNorte\nAM\n62\n28.493,00\n1.559.167,89\n4º\n4.207.714\n\n\nNordeste\nMA\n181\n25.707,00\n276.419,84\n5º\n7.114.598\n\n\nNorte\nAC\n22\n15.725,00\n164.123,96\n6º\n894.470\n\n\nNorte\nTO\n139\n8.727,00\n277.466,76\n7º\n1.590.248\n\n\nNorte\nRO\n15\n8.597,00\n223.644,53\n8º\n631.181\n\n\nNorte\nAP\n14\n1.696,00\n142.470,76\n9º\n861.773\n\n\n\n\n\n\n\n\n\n\n\n\nPensando em uma variável\n\n\n\n\nUma variável originalmente quantitativa pode ser coletada de forma qualitativa. Por exemplo, a variável idade, medida em anos completos, é quantitativa (discreta). Porém, se considerarmos uma nova variável como faixa etária, do qual os valores possíveis são: “criança” (0 a 12 anos), “adolescente” (12 a 17 anos), “adulto” (18 a 60 anos) e “idoso” (acima de 60 anos), cujos valores foram originais da variável idade estão entre parênteses, a variável faixa etária passa é considerada uma variável qualitativa (ordinal). Outro exemplo é o peso dos lutadores de boxe, uma variável quantitativa (contínua) se trabalhamos com o valor obtido na balança, mas qualitativa (ordinal) se o classificarmos nas categorias do boxe (peso-pena, peso-leve, peso-pesado, etc.);\nOutro ponto importante é que nem sempre uma variável representada por números é quantitativa. O número do telefone de uma pessoa, o número da casa, o número de sua identidade. Às vezes o sexo do indivíduo é registrado na planilha de dados como 1 se macho e 2 se fêmea, por exemplo. Isto não significa que a variável sexo passou a ser quantitativa!\nÉ fato que a rigor, as variáveis quantitativas seriam todas discretizadas devido a limitação dos nossos instrumentos de medidas. Observe que o tamanho de uma pessoa não está limitado às escalas de metros, centímetros, milímetros, etc.. Porém, os instrumentos de medida que obtém essa informação, estão limitados a essas escalas. De toda forma, precisamos dessa limitação para que as análises sejam possíveis, e possamos tomar decisões a partir dos dados.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Definições Gerais da Estatística e técnicas de somatórios</span>"
    ]
  },
  {
    "objectID": "cap01.html#técnicas-de-somatório",
    "href": "cap01.html#técnicas-de-somatório",
    "title": "1  Definições Gerais da Estatística e técnicas de somatórios",
    "section": "1.5 Técnicas de Somatório",
    "text": "1.5 Técnicas de Somatório\nUm tipo de notação muito importante para a Estatística é o uso de técnicas de somatório, muito usado, por exemplo, na notação de medidas estatísticas. A ideia da técnica de somatório é simplificar a notação da soma de dados, de modo que possamos representar essas operações por meio de notação matemática de modo simplificado.\nComo já falado anteriormente, representamos por \\(X\\) uma determinada variável. Nesse caso, não fará sentido falar de variáveis qualitativas, uma vez que o objetivo nessa notação é a representação de operações matemáticas. Assim, estaremos restritos as variáveis quantitativas.\nBaseado nos dados da Tabela 1.2, supomos que \\(X\\) representa o número de cidades pertencentes a Amazônia legal de um terminado estado, então nesse caso, como temos a representação de todos os estados, estamos diante de dados populacionais. Assim, \\(N = 9\\), podemos representar a variável com um índice para se referir ao número de cidade de um determinado estado. Por exemplo, \\(X_1\\) representa a variável número de cidades do Pará, o seu valor observado \\(x_1 = 144\\) cidades. A variável \\(X\\) pode ser representada nos demais elementos da seguinte forma: \\(X_1\\), \\(X_2\\), \\(\\ldots\\), \\(X_9\\). Podemos nos interessar em saber o total de cidades na Amazônia legal. Em notação, podemos calcular esse total da seguinte forma: \\[\\begin{align*}\nx_1 + x_2 + x_3 + \\ldots + x_9 & = 144 + 141 + 52 + 62 + 181 + \\\\\n                                                    & \\quad 22 + 139 + 15 + 14\\\\\n                                                    & = 770~\\textrm{cidades.}\n\\end{align*}\\]\nPercebemos que com apenas nove observações, a notação para essa simples operação se torna extensa. E isso acaba aumentando à medida que o número de observações aumentam. Também, quando realizamos operações mais complexas, essa representação também se tornam mais complexas. Pensando nisso, surgem as técnicas de somatórios, para simplificar essas representações. Representaremos um somatório pela letra grega sigma maiúsculo (\\(\\Sigma\\)), que indica a soma de determinados valores. Agregado ao símbolo do somatório, usaremos uma (ou algumas) indexação(ões) para representar qual(is) os elementos fazem parte desta operação, seguido da(s) variável(is) de interesse, isto é, \\[\\begin{align*}\n\\sum_{i = 1}^{m} X_i & = X_1 + X_2 + \\ldots + X_m,\n\\end{align*}\\] sendo que \\(m\\) pode representar o tamanho amostral, \\(n\\), ou o tamanho populacional, \\(N\\). No caso da representação anterior, podemos simplicar a representação da soma de um conjunto de valores usando as técnicas de somatório, apresentadas a seguir, \\[\\begin{align*}\nX_1 + X_2 + X_3 + X_4 + X_5 + X_6 + X_7 + X_8 + X_9 & = \\sum_{i = 1}^{9} X_i.\n\\end{align*}\\] Tornamos a notação mais simples de ser representada. Isso será muito importante, quando formos definir medidas estatísticas, provas de teoremas, etc.\nDe modo similar, podemos realizar as mesmas alterações com transformações na(s) variável(is). Por exemplo, quando formos estudar medidas de dispersão, no Capítulo 4, será útil as seguintes operações, considerando uma amostra de tamanho \\(n\\), \\[\\begin{align*}\n\\sum_{i = 1}^{n} X_i^2 = X_1^2 + X_2^2 + \\ldots, X_n^2,\n\\end{align*}\\] isto é, a soma do quadrado da variável. Outra operação interessante, é o quadrado da soma, apresentado a seguir, \\[\n\\left(\\sum_{i = 1}^{n} X_i\\right)^2 = \\left(X_1 + X_2 + \\ldots, X_n\\right)^2.\n\\tag{1.1}\\] Uma técnica muito utilizada na Estatística é o estudo da Regressão linear, que estuda a relação entre duas ou mais variáveis, e será abordado no Capítulo 11. Assim, uma das operações utilizadas é a soma do produto entre duas variáveis, por exemplo, \\(X\\) e \\(Y\\), do qual podemos representar esta soma para um conjunto de pares \\((X_i, Y_i)\\), de tamanho \\(n\\), da seguinte forma, \\[\n\\sum_{i = 1}^{n} X_iY_i = X_1Y_1 + X_2Y_2 + \\ldots, X_nY_n.\n\\tag{1.2}\\] Outra forma é o produto das somas de variáveis, que nesse caso, nos limitaremos as duas variáveis \\(X\\) e \\(Y\\). Por exemplo, para um amostra de pares \\((X_i, Y_i)\\) de tamanho \\(n\\), pode ser representada por: \\[\n\\begin{align}\n\\left(\\sum_{i = 1}^{n} X_i\\right)\\times \\left(\\sum_{i = 1}^{n} Y_i \\right) & = \\left(X_1 + X_2 + \\ldots, X_n\\right)\\times \\nonumber\\\\\n& \\times \\left( Y_1 + Y_2 + \\ldots, Y_n \\right) \\nonumber\\\\\n& = \\sum_{i = 1}^{n} X_iY_i + \\mathop{\\sum_{i = 1}^{n}\\sum_{j = 1}^{n}}_{i\\neq j}X_iY_j,\n\\end{align}\n\\tag{1.3}\\] em que o primeiro dessa último resultado é dado pela notação expressa em (1.2). O segundo termo, apresenta uma nova notação que é o duplo somatório. A ideia dessa notação é simples, fixaremos o índice no primeiro somatório e percorremos a soma dos valores usando o segundo índice. Após ter realizado toda a operação, passaremos para o próximo índice no primeiro somatório e realizamos o mesmo procedimento para o índice no segundo somatório. Toda a operação será finalizada, quando tivermos percorrido a soma em todos os valores. Vejamos para um caso de duplo somatório, com um par de variáveis \\((X_i, Y_i)\\), para \\(n = 3\\), \\[\\begin{align*}\n\\sum_{i = 1}^{3}\\sum_{j = 1}^{3}X_iY_j & = \\sum_{j = 1}^{3}X_1Y_j + \\sum_{j = 1}^{3}X_2Y_j + \\sum_{j = 1}^{3}X_3Y_j\\\\\n                                       & = (X_1Y_1 + X_1Y_2 + X_1Y_3) + (X_2Y_1 + X_2Y_2 + X_2Y_3) + \\\\\n                                       & \\quad + (X_3Y_1 + X_3Y_2 + X_3Y_3).\n\\end{align*}\\] Para uma amostra de tamanho \\(n\\), podemos generalizar essa notação da seguinte forma, \\[\n\\begin{align}\n\\sum_{i = 1}^{n}\\sum_{j = 1}^{n}X_iY_j & = \\sum_{j = 1}^{n}X_1Y_j + \\sum_{j = 1}^{n}X_2Y_j + \\ldots + \\sum_{j = 1}^{n}X_nY_j \\nonumber\\\\\n& = (X_1Y_1 + X_1Y_2 + \\ldots + X_1Y_n) +\\\\\n&\\quad + (X_2Y_1 + X_2Y_2+ \\ldots + X_2Y_n) + \\nonumber\\\\\n&\\quad \\ldots + (X_nY_1 + X_nY_2 + \\ldots + X_nY_n).\n\\end{align}\n\\tag{1.4}\\]\nPorém, observe que o resultado em (1.4), soma todos os produtos \\(X\\) e \\(Y\\). Como desejamos fazer uma relação entre a expressão (1.3) e a expressão (1.2), separamos a soma de produtos \\(X\\) e \\(Y\\) com índices iguais das demais situações. Para isso, impomos a restrição no segundo termo, depois da igualdade na expressão (1.4), para enfatizar que somaremos o produto de todos os \\(X_i \\times Y_i\\), tais que \\(i \\neq j\\), resultando na expressão (1.3).\nPodemos também representar a notação \\(\\sum_{i = 1}^{n}\\sum_{j = 1}^{n}X_iY_j\\) da seguinte forma, \\[\\begin{align}\n\\sum_{i = 1}^{n}\\sum_{j = 1}^{n}X_iY_j & = \\mathop{\\sum_{i = 1}^{n}}_{j = 1}X_iY_j.\n\\end{align}\\]\nUma outra notação que pode ser apresentada para o duplo somatório é abrindo o quadrado da soma no resultado da expressão (1.1), dada da seguinte forma, \\[\n\\begin{align}\n\\left(X_1 + X_2 + \\ldots, X_n\\right)^2 & = (X_1 + X_2 + \\ldots + X_n) \\times\\\\\n& \\quad \\times (X_1 + X_2 + \\ldots + X_n) \\nonumber\\\\\n                                       & = X_1X_1 + X_1X_2 + \\ldots + X_1X_n + \\nonumber\\\\\n                                       & \\quad + X_2X_1 + X_2X_2 + \\ldots + X_2X_n + \\ldots \\nonumber\\\\\n                                       & \\quad \\ldots + X_nX_1 + X_nX_2 + \\ldots + X_nX_n \\nonumber\\\\\n                                       & = \\sum_{i = 1}^{n} X_i^2 + 2\\sum_{j &gt; i = 1}^{n}X_iX_j.\n\\end{align}\n\\tag{1.5}\\]\nNesse caso, impomos também uma outra restrição no somatório do segundo termo após a igualdade, que foi somar todos os produtos \\(X_i\\times X_j\\)s, exceto aqueles com ele mesmo. Assim, observamos que situações do tipo \\(X_1 \\times X_2 = X_2 \\times X_1\\), e desse modo, podemos representar \\(X_1 \\times X_2 + X_2 \\times X_1 = 2X_1X_2\\) que o resultado será o mesmo, e simplifica a notação. Generalizando a soma para os demais casos, temos \\(2\\sum_{j &gt; i = 1}^{n}X_iX_j\\), como verificado na expressão (1.5).\nPor fim, queremos enfatizar uma última situação que é usar um indexador não como a identificação da variável para um determinado elemento da população ou amostra, mas como valor observado. Essas situações serão muito utilizadas em notações no Capítulo 5 e Capítulo 6, do qual somaremos as probabilidades da variável assumir valores em um determinado conjunto. A ideia de variável nesses capítulos será entendida como uma função, mas isso é assunto mais para frente. Nesse caso, vamos entender que \\(P(.)\\) é uma função que mede a chance de determinado \\(X\\) assumir um determinado valor, isto é, \\(P(.)\\) assume um valor entre \\(0\\) e \\(1\\). Essa função será chamada mais a frente de probabilidade. Assuma também que os valores possíveis de \\(X\\) assumam valores em um conjunto \\(A = \\{1, 2, 3, 4, 5\\}\\), e estamos interessados em representar a chance de \\(X\\) assumir valor \\(3\\). Nesse caso, usamos \\(P(X = 3)\\). Agora desejarmos representar a chance de \\(X\\) assumir valores, no mínimo, igual a 3. Dessa forma, representamos essa chance da seguinte forma, \\[\n\\begin{align}\n  P(X \\geq 3)  & = \\sum_{x = 3}^{5}P(X = x) \\nonumber\\\\\n               & = \\quad P(X = 3) + P(X = 4) + P(X = 5).\n\\end{align}\n\\tag{1.6}\\]\nObservamos que o indexador no somatório agora é o valor assumido pela variável, e não a identificação da variável a um deteminado elemento da amostra ou população. Se desejarmos somar todas as chances que \\(X\\) assume, podemos apresentar duas notações diferentes, apresentadas na sequência, \\[\n\\begin{align}\n\\sum_{x = 1}^{5}P(X = x) & = \\sum_{x \\in A}P(X = x) .\n\\end{align}\n\\tag{1.7}\\] O índice no somatório indica agora que iremos somar as chances de \\(X\\) assumir todos os valores pertencentes ao conjunto \\(A\\). Claro que, muitas outras formas de apresentar as técnicas de somatório podem ocorrer ao longo do texto, uma vez que outras formas podem ser abordadas, dependendo do assunto, como também da área estudada. De todo modo, tentamos passar parte da notação que será utilizada ao longo do livro, para que o leitor possa se ambientar nesse tipo de representação matemática.\nPara complementar essas informações, o Teorema 1.12 apresenta algumas propriedades sobre técnicas de somatório que serão importantes para os próximos capítulos.\n\nTeorema 1.1: Propriedades de somatório\nConsidere \\(a\\), \\(b\\) e \\(k\\) constantes, e que \\(X\\) e \\(Y\\) são variáveis quantitativas, então as seguintes propriedades envolvendo somatório são válidas:\n\n\\(\\sum\\limits_{i = 1}^n {aX_i }  = a\\sum\\limits_{i = 1}^n {X_i }\\)\n\\(\\sum\\limits_{i = 1}^n X_i Y_i  \\leq \\sum\\limits_{i = 1}^n {X_i } \\sum\\limits_{i = 1}^n {Y_i }\\);\n\\(\\sum\\limits_{i = 1}^n {(aX_i  \\pm b} Y_i ) = a\\sum\\limits_{i = 1}^n {X_i  \\pm b} \\sum\\limits_{i = 1}^n {Y_i }\\);\n\\(\\sum\\limits_{i = 1}^n {k = \\,nk}\\);\n\\(\\sum\\limits_{i = 1}^n {\\left( {X_i  - \\bar X} \\right)}  = 0\\), em que \\(\\bar X = \\frac{1}{n}\\sum\\limits_{i = 1}^n {X_i }\\);\n\\(\\displaystyle\\sum_{i = 1}^n X_i^2 \\leq \\left(\\displaystyle\\sum_{i = 1}^n X_i\\right)^2\\);\n\\(n\\bar{X}^2 = \\frac{(\\sum_{i = 1}^{n}X_i)^2}{n}\\), em que \\(\\bar X = \\frac{1}{n}\\sum\\limits_{i = 1}^n {X_i }\\);\n\\(\\displaystyle\\sum_{i = 1}^n \\left( {X_i  - \\bar X} \\right)^2 = \\displaystyle\\sum_{i = 1}^{n}X_i^2 - \\frac{1}{n} \\left(\\sum_{i = 1}^{n}X_i\\right)^2\\);\n\\(\\displaystyle\\sum_{i = 1}^{n}Y_i(X_i - \\bar{X}) = \\displaystyle\\sum_{i = 1}^{n}\\left( {Y_i  - \\bar Y} \\right)\\left( {X_i  - \\bar X} \\right)\\).\n\n\n\n\nProva\n\nSegue que: \\[\\begin{align*}\n\\sum_{i = 1}^n {aX_i }  & = aX_1  + aX_2  +  \\ldots  + aX_n\\\\\n& = a\\left( {X_1  +  \\ldots  + X_n } \\right)\\\\\n& = a\\sum_{i = 1}^n {X_i };\n\\end{align*}\\]\nObservando as expressões (1.2) e (1.3), claramente que \\(\\sum\\limits_{i = 1}^n X_i Y_i  &lt; \\sum\\limits_{i = 1}^n {X_i } \\sum\\limits_{i = 1}^n {Y_i }\\). A única condição de igualdade acontece se \\(n = 1\\). Porém, em termos práticos para contexto estatístico, essa informação é inútil, uma vez que com apenas uma observação na amostra ou população não haverá condições apresentarmos alguma informação sobre a mesma.\nSegue, \\[\\begin{align*}\n    \\sum\\limits_{i = 1}^n {(aX_i  + b} Y_i ) & = aX_1  + bY_1  + aX_2  + bY_2  +  \\ldots  + aX_n  + bY_n  \\\\\n    & = aX_1  + aX_2  + aX_n  + bY_2  + bY_1  +  \\ldots  + bY_n  \\\\\n    & = a\\left( {X_1  +  \\ldots  + X_n } \\right) + b\\left( {Y_1  +  \\ldots  + Y_n } \\right)\\\\ & = a\\sum\\limits_{i = 1}^n {X_i }  + b\\sum\\limits_{i = 1}^n {Y_i }\n  \\end{align*}\\]\n\\(\\sum_{i = 1}^n k  = \\underbrace {k + k +  \\ldots  + k}_{n\\,vezes} = nk\\);\nSegue, \\[\\begin{align*}\n\\sum\\limits_{i = 1}^n {\\left( {X_i  - \\bar X} \\right)}  & = \\sum\\limits_{i = 1}^n {X_i }  - \\sum\\limits_{i = 1}^n {\\bar X}  = \\sum\\limits_{i = 1}^n {X_i }  - n\\left( {\\frac{1}{n}\\sum\\limits_{i = 1}^n {X_i } } \\right) \\\\\n& = \\sum\\limits_{i = 1}^n {X_i }  - \\sum\\limits_{i = 1}^n {X_i }  = 0.\n  \\end{align*}\\]\nVerificando a expressão (1.5), percebemos claramente que \\(\\displaystyle\\sum_{i = 1}^n X_i^2 &lt; \\left(\\displaystyle\\sum_{i = 1}^n X_i\\right)^2\\). A única condição de igualdade acontece se \\(n = 1\\), e em termos práticos para uso estatístico, usamos a mesma justificativa dada na propriedade (I);\n\\(n\\bar{X}^2 = n\\displaystyle\\left( \\frac{\\sum_{i = 1}^{n}X_i}{n}\\right)^2 = \\frac{(\\sum_{i = 1}^{n}X_i)^2}{n}\\);\nVejamos a seguinte dedução, \\[\\begin{align*}\n    \\displaystyle\\sum_{i = 1}^n \\left( {X_i  - \\bar X} \\right)^2 & = \\displaystyle\\sum_{i = 1}^n \\left(X_i^2  - 2X_i\\bar X + {\\bar X}^2 \\right)\\\\\n    & = \\displaystyle\\sum_{i = 1}^n X_i^2 - 2\\bar X\\displaystyle\\sum_{i = 1}^n X_i + \\displaystyle\\sum_{i = 1}^n {\\bar X}^2\\\\\n    & = \\displaystyle\\sum_{i = 1}^n X_i^2 - 2\\frac{1}{n}\\displaystyle\\sum_{i = 1}^{n}X_i \\times \\displaystyle\\sum_{i = 1}^n X_i + n {\\bar X}^2\\\\\n    & = \\displaystyle\\sum_{i = 1}^n X_i^2 - 2\\frac{\\left(\\sum_{i = 1}^{n}X_i\\right)^2}{n} + n \\frac{\\left(\\sum_{i = 1}^{n}X_i\\right)^2}{n^2}\\\\\n    & = \\displaystyle\\sum_{i = 1}^n X_i^2 - 2\\frac{\\left(\\sum_{i = 1}^{n}X_i\\right)^2}{n} + \\frac{\\left(\\sum_{i = 1}^{n}X_i\\right)^2}{n}\\\\\n    & = \\displaystyle\\sum_{i = 1}^n X_i^2 - \\frac{\\left(\\sum_{i = 1}^{n}X_i\\right)^2}{n};\n  \\end{align*}\\]\nAntes de mostrarmos a prova da propriedade (IX), vejamos que \\[\\begin{align*}\n\\displaystyle\\sum_{i = 1}^{n}\\bar{Y}(X_i - \\bar{X}) & = \\bar{Y}\\underbrace{\\displaystyle\\sum_{i = 1}^{n}(X_i - \\bar{X})}_{=0,~\\textrm{Propriedade (V)}} = 0.\n  \\end{align*}\\] Desse modo, temos que \\[\\begin{align*}\n\\displaystyle\\sum_{i = 1}^{n}Y_i(X_i - \\bar{X}) & = \\displaystyle\\sum_{i = 1}^{n}Y_i(X_i - \\bar{X}) - \\underbrace{\\displaystyle\\sum_{i = 1}^{n}\\bar{Y}(X_i - \\bar{X})}_{=0,~\\textrm{Propriedade (VIII)}},\n  \\end{align*}\\] logo, \\[\\begin{align*}\n\\displaystyle\\sum_{i = 1}^{n}Y_i(X_i - \\bar{X}) = \\displaystyle\\sum_{i = 1}^{n}\\left( {Y_i  - \\bar Y} \\right)\\left( {X_i  - \\bar X} \\right).\n  \\end{align*}\\]",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Definições Gerais da Estatística e técnicas de somatórios</span>"
    ]
  },
  {
    "objectID": "cap01.html#exercícios-propostos",
    "href": "cap01.html#exercícios-propostos",
    "title": "1  Definições Gerais da Estatística e técnicas de somatórios",
    "section": "Exercícios propostos",
    "text": "Exercícios propostos\n\nExercício 1.1Baseado no Exemplo 1.1, identifique um problema para essa pesquisa bem como um objetivo, e desenvolva hipóteses a serem estudadas, de modo que estas possam responder as indagações do problema e atinja o objetivo proposto.\n\n\n\nSolução\n\nSabemos que no Brasil as barragens de mineração apresentam três tipos: barragem a montante, barragem a jusante e barragem linha de centro, dos quais esses tipos levam o custo e a segurança da barragem, porém todos eles depositam água juntamente com os rejeitos, e isto proporciona uma certa instabilidade para a barragem. Desse modo, podemos ter como problema inicial que a instabilidade das barragens podem estar relacionados aos tipos de barragens desenvolvidas no Brasil. Existe um outro tipo de barragem que pode ser desenvolvido a seco, porém pouco conhecido no Brasil, do qual o material acumulado é drenado e acumulado em pilhas, de modo a ficarem expostos à secagem do sol.\nAssim, como estudo inicial sobre essa alternativa de construção de barragem, poderíamos nortear a pesquisa sob duas hipóteses a serem estudadas:\n\nPesquisa 1: \\(H_0:\\) Barragens do tipo depósito de rejeito a seco são mais baratas que as existentes no Brasil;\nPesquisa 2: \\(H_0:\\) Barragens do tipo depósito de rejeito a seco são mais seguras que as existentes no Brasil;\n\n\n\n\nExercício 1.2Usando os resultados do Teorema 1.1, mostre em quais aplicações na estatística poderemos utilizar esses resultados.\n\n\n\nExercício 1.3Baseado em Devore (2006), um famoso experimento executado em 1882, Michelson e Newcomb fizeram 66 observações do tempo levado pela luz para percorrer a distância entre dois locais em Washington, D.C. Algumas das medidas (codificadas de certa forma) foram 31, 23, 32, 36, -2, 26, 27 e 31. Por que essas medidas não são idênticas?\n\n\n\nSoluçãoEssas medidas não são iguais por diversos fatores, dentre elas, a imprecisão dos instrumentos de medida. Isso é o que define chamarmos essa característica de interesse no estudo de variável, pois de elemento a elemento, o valor assumido dessa característica varia. Outros aspectos dessa variação podem ser as diferentes condições ambientais referentes ao tempo de medida, dentre outros.\n\n\n\nExercício 1.4\nSejam as amostras de tamanho n = 5 de duas variáveis, dadas por:\n\n\\(X = \\{2,4,5,1,2\\}\\), \\(Y = \\{1,2,3,5,8\\}\\).\n\nObtenha:\n\n\\(\\sum_{i = 1}^{4}X_i\\);\n\\(\\sum_{i = 1}^{5}4\\times X_i^2\\);\n\\(\\sum_{i = 2}^{n}X_i\\);\n\\(\\sum_{i = 1}^{n}X_i\\times Y_i\\);\n\\(\\sum_{i = 1}^{n}(3X_i + 2Y_i)\\);\n\\(\\sum_{i = 1}^{n}X_iY_i + \\sum_{i = 1}^{n}Y_i^2\\);\n\\(\\sum_{i = 1}^{n} X_i\\);\n\\(\\sum_{i = 1}^{n} Y_i\\);\n\\(\\sum_{i = 1}^{n} X_i^2\\);\n\\(\\sum_{i = 1}^{n} Y_i^2\\);\n\\(\\sum_{i = 1}^{n} (Y_iX_i)\\);\n\\((\\sum_{i = 1}^{n} Y_i)^2\\);\n\\((\\sum_{i = 1}^{n} X_i)^2\\);\n\\(\\sum_{i = 1}^{n} (X_i - \\frac{\\sum_{i = 1}^{n}X_i}{n})^2\\);\n\\(\\sum_{i = 1}^{n} (Y_i - \\frac{\\sum_{i = 1}^{n}Y_i}{n})^2\\);\n\\(\\sum_{i = 1}^{n}X_i^2 - \\frac{\\left(\\sum_{i = 1}^{n}X_i\\right)^2}{n}\\);\n\\(\\sum_{i = 1}^{n}Y_i^2 - \\frac{\\left(\\sum_{i = 1}^{n}Y_i\\right)^2}{n}\\);\nQual conclusão se pode chegar sobre os itens (n) e (p), bem como (o) e (q)?\n\n\n\n\nExercício 1.5\nForneça uma amostra possível, de tamanho 5, de cada uma das populações a seguir:\n\ntodos os jornais publicados no Brasil;\ntodas as empresas na área de telecomunicações;\ntodos os alunos da Universidade Federal de São João del-Rei;\ntodas as notas, pontuados de 0 a 100, dos alunos da disciplina de Estatística e Probabilidade;\n\n\n\n\nSolução\n\nO Globo (Rio de Janeiro), Folha de São Paulo (São Paulo), Tribuna do Norte (Rio Grande do Norte), A crítica (Manaus), A Gazeta (São Paulo);\nNET, TIM, Brisanet, Vivo, Oi;\nSamara, Diego, Anna Albuquerque, Matheus, Giliwiline;\n85, 75, 65, 42, 57.\n\n\n\n\nExercício 1.6\nObservou-se o tempo, em minutos, que \\(10\\) atendimentos de clientes de uma determinada empresa telefônica demoraram para serem atendidos, que seguem: \\(5\\), \\(10\\), \\(2\\), \\(13\\), \\(7\\), \\(15\\), \\(8\\), \\(12\\), \\(6\\) e \\(5\\). O objetivo do estudo foi verificar se o tempo médio, em minutos, do atendimento era superior a 10 minutos. Pergunta-se:\n\nQual a população em estudo?\nQual o problema indagado?\nQual(is) a(s) variável(is) em estudo do trabalho, como também a natureza dessa(s) variável(is)?\nPodemos identificar o tamanho da população e da amostra, com essas informações?\n\n\n\n\nExercício 1.7Como podemos relacionar os ramos da Estatística com os itens do plano de pesquisa científica, presentes nesse capítulo?\n\n\n\nSolução\n\n\n\n\n\n\n\nPesquisa científica\nRamos da Estatística\n\n\n\n\nIdentificar o problema e o objetivo da pesquisa\n-\n\n\nFormular a hipótese estudada\nEstatística Inferencial\n\n\nRevisão de literatura\n-\n\n\nFormular um plano amostral e identificar as variáveis de interesse para a pesquisa\nAmostragem (Não o classificamos com um ramo da estatística)\n\n\nColeta, crítica e tratamento dos dados\nEstatística descritiva\n\n\nApresentação dos dados\nEstatística descritiva\n\n\nAnálise e interpretação dos dados\nEstatística inferencial e Probabilidade\n\n\nConclusão e derivação da conclusão que poderá rejeitar ou não a hipótese estudada, gerando assim, uma confirmação ou indagações para outros problemas\nEstatística inferencial e Probabilidade\n\n\nApresentação dos dados por meio de trabalhos científicos para a propagação do conhecimento sobre o problema estudado\nEstatística descritiva\n\n\n\n\n\n\nExercício 1.8\nOs dados retirados de Tavares e Anjos (1999), representam a distribuição percentual do estado nutricional em homens idosos brasileiros (idade \\(\\geq\\) 60 anos), segundo Índice de Massa Corporal (IMC7), por macrorregião e situação de domicílio, Pesquisa Nacional sobre Saúde e Nutrição, 1989, que seguem abaixo. Como poderíamos, em notação usando as técnicas de somatório, representar a soma de todos os valores de IMC do Brasil, levando em consideração as demais variáveis? Se desejássemos, calcular o total dos valores observados de IMC dos homens do nordeste, considerando as demais condições? E se fosse do nordeste e da zona urbana, como representaríamos esse somatório?\n\n\n\n\n\n\nRegiões\n\n\nNúmero\n\n\nEstado Nutricional (%)\n\n\n\n\nM\n\n\nA\n\n\nSI\n\n\nSII e SIII\n\n\n\n\n\n\nNorte\n\n\n223\n\n\n4,4\n\n\n60,6\n\n\n29,4\n\n\n5,6\n\n\n\n\nNordeste\n\n\n586\n\n\n8,8\n\n\n68,3\n\n\n19,8\n\n\n3,1\n\n\n\n\nUrbano\n\n\n267\n\n\n7,1\n\n\n62,3\n\n\n26,6\n\n\n4,0\n\n\n\n\nRural\n\n\n319\n\n\n10,7\n\n\n74,6\n\n\n12,5\n\n\n2,2\n\n\n\n\nSudeste\n\n\n463\n\n\n7,9\n\n\n59,0\n\n\n26,7\n\n\n6,4\n\n\n\n\nUrbano\n\n\n197\n\n\n5,6\n\n\n56,4\n\n\n30,2\n\n\n7,8\n\n\n\n\nRural\n\n\n266\n\n\n17,3\n\n\n69,5\n\n\n12,4\n\n\n0,8\n\n\n\n\nSul\n\n\n429\n\n\n5,1\n\n\n56,5\n\n\n29,2\n\n\n9,2\n\n\n\n\nUrbano\n\n\n197\n\n\n4,5\n\n\n51,2\n\n\n33,0\n\n\n11,3\n\n\n\n\nRural\n\n\n232\n\n\n6,4\n\n\n66,4\n\n\n22,0\n\n\n5,2\n\n\n\n\nCentro-Oeste\n\n\n327\n\n\n10,7\n\n\n60,6\n\n\n22,8\n\n\n5,9\n\n\n\n\nUrbano\n\n\n154\n\n\n10,6\n\n\n55,2\n\n\n27,3\n\n\n6,9\n\n\n\n\nRural\n\n\n173\n\n\n11,0\n\n\n71,4\n\n\n13,7\n\n\n3,9\n\n\n\n\nBrasil\n\n\n2.028\n\n\n7,8\n\n\n61,8\n\n\n24,7\n\n\n5,7\n\n\n\n\nUrbano\n\n\n1.038\n\n\n6,0\n\n\n57,2\n\n\n29,5\n\n\n7,3\n\n\n\n\nRural\n\n\n990\n\n\n11,7\n\n\n71,7\n\n\n14,2\n\n\n2,4\n\n\n\n\n\n\n\n\nSolução\nDevemos observar nessa tabela, a presença de algumas variáveis como: Região (Norte, Nordeste, Sudeste, Sul, Centro-Oeste e Brasil), Zona (Urbano e Rural), Estado Nutricional (Magreza, Adequado, Sobrepeso I e Sobrepeso II e III) e Número.\nVale lembrar que os valores internos da tabela representam a distribuição percentual de pessoas que se enquadram em um determinado estado nutricional, separados por região. Assim, considerando que temos todos os valores de IMC das pessoas entrevistadas (2.028 pessoas), e que esta é representada pela variável \\(X\\), (a) a soma de todos os IMCs do Brasil, levando em consideração a todas as outras variáveis, pode ser representada por: \\[\\begin{align*}\n  \\sum_{i = 1}^{2.028}X_i.\n\\end{align*}\\]\n\nAgora o total do IMC de homens do nordeste (586 pessoas), e que estes são representados pela variável \\(Y\\), então \\[\n\\begin{align}\n  \\sum_{j = 1}^{586}Y_j\n\\end{align}\n\\tag{1.8}\\]\nPor fim, considerando o total do IMC de homens da zona urbana, podemos aproveitar a notação anterior, e complementar com um outro indexador, \\(k = 1, 2\\); se \\(k = 1\\) teremos uma pessoa da zona urbana, e se \\(k = 2\\), teremos uma pessoa da zona rural, então como representação de soma geral teríamos \\[\n\\begin{align}\n  \\sum_{j = 1}^{586}Y_{jk}, \\quad k = 1, 2.\n\\end{align}\n\\tag{1.9}\\] As expressões (1.8) e (1.9) são equivalentes. Restringindo a soma apenas para homens da zona urbana, temos \\[\\begin{align*}\n  \\sum_{j = 1}^{586}Y_{j1}.\n\\end{align*}\\] Este último resultado significa que alguns valores de \\(Y_{j1}\\) serão iguais a 0, pois sabemos pela tabela que há apenas 267 homens da zona urbana.\n\n\n\n\nExercício 1.9Considere a expressão \\(\\displaystyle \\sum_{i = 1}^{n}(X_i - A)^2\\). Qual o valor de \\(A\\) para que essa expressão seja minizada?\n\n\n\nExercício 1.10Os famosos estudos sobre o tempo de oscilação de um pêndulo, do qual se afirmava que este tempo não dependia do peso do corpo suspenso na extremidade do fio, motivou Galileu a realizar diversos experimentos, que levou a fazer determinadas afirmações, como por exemplo: se dois objetos com pesos diferentes caíssem da mesma altura ao mesmo tempo no vácuo chegariam ao chão ao mesmo tempo. Esses estudos foram muito importantes para a criação das leis da queda dos corpos, para enunciar a base do princípio da inércia e a lei da composição das velocidades. Baseado na afirmação de Galileu anteriormente, como poderíamos relacionar o método científico e as suas fases diante dessa situação?\n\n\n\n\n\n\nCOMPANY, B. P. BP statistical review of world energy. London: British Petroleum Company, 2018.\n\n\nDEVORE, J. L. Probabilidade e Estatística para Engenharia e Ciências. 6. ed. São Paulo: Cengage Learning, 2006. p. 692\n\n\nSILVA, J. G. C. DA. Planejamento da Pesquisa Experimental: Base Conceitual e Metodológica. Pelotas: Instituto de Física e Matemática, 2007. p. 509\n\n\nTAVARES, E. L.; ANJOS, L. A. DO. Perfil antropométrico da população idosa brasileira. Resultados da Pesquisa Nacional sobre saúde e Nutrição. Cad. Saúde Pública, v. 15, n. 4, p. 759–768, 1999.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Definições Gerais da Estatística e técnicas de somatórios</span>"
    ]
  },
  {
    "objectID": "cap01.html#footnotes",
    "href": "cap01.html#footnotes",
    "title": "1  Definições Gerais da Estatística e técnicas de somatórios",
    "section": "",
    "text": "Ver Definição 1.6.↩︎\nA forma de como construir as hipóteses de uma pesquisa científica será abordada no Capítulo 10, do qual dissertaremos sobre a Teoria da decisão.↩︎\nPara quem desejar entender com detalhes a metodologia baseada para o programa, acesse: PRODES.↩︎\nDados coletados da página do IBGE, edição 2019, https://geoftp.ibge.gov.br/organizacao_do_territorio/estrutura_territorial/amazonia_legal/2019/lista_de_municipios_da_amazonia_legal_2019.ods↩︎\nEssa variável se refere a classificação do estado que obteve maior taxa de desmatamento acumulado, desde 1988 a 2020.↩︎\nEssa variável se refere a população estimada de cada estado, e os dados foram retirados do IBGE, disponível em https://www.ibge.gov.br/cidades-e-estados**↩︎\nA unidade de IMC em \\(kg/m^2\\).↩︎",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Definições Gerais da Estatística e técnicas de somatórios</span>"
    ]
  },
  {
    "objectID": "cap02.html",
    "href": "cap02.html",
    "title": "2  Coleta, organização e apresentação dos dados",
    "section": "",
    "text": "2.1 Introdução\nApós selecionado a população de interesse, definindo os elementos que a compõe, bem como as variáveis que serão estudadas, fazemos o processo de coleta dos dados. Os dados são os valores assumidos de uma variável em um determinado elemento da população, que pode está sendo estudado por meio de uma amostra ou coletado diretamente da população. Neste último caso, a pesquisa realizada é um Censo.\nAo termos um primeiro contato com os dados, percebemos que algumas informações prévias podem não ser facilmente obtidas, devido a desorganização dessas observações, Isso ocorre principalmente quando temos um grande número de dados.\nOs dados da Tabela 2.1, retirado de Montgomery e Runger (2016, p. 188), representam o número de erros em um conjunto de caracteres (strings) de 1.000 bits, que foram monitorados por um canal de comunicação. No total, foram coletados dados de 20 conjuntos de caracteres.\nPodemos observar pela Tabela 2.1 que estes representam um tipo de dados brutos, pois não há qualquer ordenamento sobre os seus valores, e que a interpretação desses dados poderá se complicar à medida que o tamanho da amostra aumenta. Quando ordenamos os dados brutos podemos obter algumas informações mais facilmente, como por exemplo, valores mínimos e máximos desses conjunto de dados.\nAgora, podemos transformar os dados brutos da Tabela 2.1, em dados elaborados (em Rol), apresentados na Tabela 2.2. Em termos de notação, iremos representar um conjunto de variáveis ordenadas dessa forma, \\(X_1\\), \\(X_2\\), \\(\\ldots\\), \\(X_n\\), de tamanho \\(n\\). Com o ordenamento, usaremos um parêntese no índice, \\(X_{(1)}\\), \\(X_{(2)}\\), \\(\\ldots\\), \\(X_{(n)}\\), de modo que, \\(X_{(1)} = \\min_i(X_i)\\) e \\(X_{(n)} = \\max_i(X_i)\\) para \\(i\\) \\(=\\) \\(1\\), \\(2\\), \\(\\ldots\\), \\(n\\). Da mesma forma, vale para a representação dos valores observados dessas respectivas variáveis, isto é, valores observados sem ordenação denotados por \\(x_{(1)}\\), \\(x_{(2)}\\), \\(\\ldots\\), \\(x_{(n)}\\), e valores observados ordenados \\(x_{(1)} = \\min_i(x_i)\\) e \\(x_{(n)} = \\max_i(x_i)\\). Este último é a representação, em notação, dos dados elaborados.\nPercebemos, com os dados elaborados, que os valores extremos representam, respectivamente, os valores mínimo e máximo do conjunto de dados, independente do número de elementos. Isso facilita a percepção de algumas informações, porém ainda limitado, uma vez que a quantidade de valores pode ser simplicada, sem perda de informações, por meio de tabulações agrupadas em distribuição de frequências. Além de simplificar, podemos obter mais informações do que se estes dados tivessem expressos sem tabulação, do qual, trataremos na próxima seção.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Coleta, organização e apresentação dos dados</span>"
    ]
  },
  {
    "objectID": "cap02.html#introdução",
    "href": "cap02.html#introdução",
    "title": "2  Coleta, organização e apresentação dos dados",
    "section": "",
    "text": "Definição 2.1: Dados brutosOs dados coletados numa forma sem ordenação e sem nenhum tipo de arranjo sistemático são chamados dados brutos.\n\n\n\n\n\n\nTabela 2.1: Dados brutos sobre o número de erros encontrados em 20 conjuntos de caracteres monitorado em um canal de comunicação.\n\n\n\n\n\n3\n1\n0\n1\n3\n2\n4\n1\n3\n1\n\n\n1\n1\n2\n3\n3\n2\n0\n2\n0\n1\n\n\n\n\n\n\n\n\nDefinição 2.2: Dados em rol ou elaboradosOs dados brutos, Definição 2.1, ordenados de modo crescente ou decrescente alfanumericamente, são chamados de dados em rol ou elaborados.\n\n\n\n\n\n\nTabela 2.2: Dados elaborados sobre o número de erros encontrados em 20 conjunto de caracteres monitorado em um canal de comunicação.\n\n\n\n\n\n0\n0\n0\n1\n1\n1\n1\n1\n1\n1\n\n\n2\n2\n2\n2\n3\n3\n3\n3\n3\n4",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Coleta, organização e apresentação dos dados</span>"
    ]
  },
  {
    "objectID": "cap02.html#sec-reptabular",
    "href": "cap02.html#sec-reptabular",
    "title": "2  Coleta, organização e apresentação dos dados",
    "section": "2.2 Representação tabular",
    "text": "2.2 Representação tabular\nA frequência simples ou frequência absoluta, representa o número de vezes que determinado valor foi observado, que em notação, denotaremos por \\(F_i\\) i-ésima frequência de determinada variável, em que a frequência observada será denotada por \\(f_i\\). Vejamos o agrupamento dos dados da Tabela 2.2, em distribuição de frequência, a seguir.\n\n\n\nTabela 2.3: Distribuição de frequência do número de erros encontrados em 20 conjunto de caracteres monitorado em um canal de comunicação .\n\n\n\n\n\n\n\n\n\nNúmero de erros \\(\\mathbf{(x_i)}\\)\nFrequência simples \\(\\mathbf{(f_i)}\\)\n\n\n\n\n0\n3\n\n\n1\n7\n\n\n2\n4\n\n\n3\n5\n\n\n4\n1\n\n\nTotal\n20\n\n\n\n\n\n\nDe forma mais fácil, podemos por meio da Tabela 2.3 saber quantas vezes um determinado valor foi observado, sem grandes esforços, bastando apenas olhar para a coluna de frequências absolutas. Se desejarmos, apresentar uma forma relativa dessa frequência em relação ao número total de observações, podemos utilizar a frequência relativa, denotada por \\(F_r\\), em que \\(f_r\\) representa o seu respectivo valor observado, e que essa frequência será um valor entre \\(0\\) e \\(1\\). Calculamos a frequência relativa, de acordo com a expressão (2.1), \\[\n\\begin{align}\n  F_{r_i} & = \\frac{F_i}{\\sum_{i = 1}^{k}F_i}, \\quad i = 1, 2, \\ldots, k,\n\\end{align}\n\\tag{2.1}\\] sendo \\(k\\) o número de grupos ou classes. No caso, o cálculo da frequência relativa baseado na Tabela 2.3, a representação de \\(k\\) se refere ao número de grupos, uma vez que os dados são discretizados. Portanto, esse tipo de agrupamento é válido tanto para as variáveis qualitativas quanto para a variável quantitativa discreta. No caso da variável quantitativa contínua, agrupamos os seus valores em classes, uma vez que sua natureza não é discretizada. O modo de como criar essas classes, aprenderemos mais a frente. Desse modo, a Tabela 2.4 apresenta o agrupamento dos dados do número de erros encontrados em 20 conjunto de caracteres monitorado em um canal de comunicação, juntamente com a frequência relativa de seus valores.\n\n\n\nTabela 2.4: Frequência relativa do número de erros encontrados em 20 conjunto de caracteres monitorado em um canal de comunicação.\n\n\n\n\n\n\n\n\n\n\nNúmero de erros \\(\\mathbf{(x_i)}\\)\nFrequência simples \\(\\mathbf{(f_i)}\\)\nFrequência relativa \\(\\mathbf{(f_{r_i})}\\)\n\n\n\n\n\\(0\\)\n\\(3\\)\n\\(3 / 20 = 0,15\\)\n\n\n\\(1\\)\n\\(7\\)\n\\(7 / 20 = 0,35\\)\n\n\n\\(2\\)\n\\(4\\)\n\\(4 / 20 = 0,20\\)\n\n\n\\(3\\)\n\\(5\\)\n\\(5 / 20 = 0,25\\)\n\n\n\\(4\\)\n\\(1\\)\n\\(1 / 20 = 0,05\\)\n\n\nTotal\n\\(20\\)\n\\(1\\)\n\n\n\n\n\n\nPercebemos que \\(\\sum_{i = 1}^{k}f_i = n\\), uma vez que os dados são amostrais. A frequência relativa passa a ter sentido prático quando usamos o resultado em porcentagem, surgindo então, a frequência percentual, denotada por \\(F_\\%\\), cujo valor observado é dado por \\(f_\\%\\), de modo que essa frequência é calculada pela expressão (2.2).\n\\[\n\\begin{align}\n  F_{\\%_i} & = F_{r_i} \\times 100, \\quad i = 1, 2, \\ldots, k,\n\\end{align}\n\\tag{2.2}\\] em que \\(F_{r_i}\\) é dado pela expressão (2.1), e \\(k\\) é igual ao número de grupos ou classes.\nAssim, podemos acrescentar a frequência percentual aos dados da Tabela 2.4, que pode ser apresentado na Tabela 2.5.\n\n\n\nTabela 2.5: Frequência percentual do número de erros encontrados em 20 conjunto de caracteres monitorado em um canal de comunicação.\n\n\n\n\n\n\n\n\n\n\n\nNúmero de erros \\(\\mathbf{(x_i)}\\)\nFrequência simples \\(\\mathbf{(f_i)}\\)\nFrequência relativa \\(\\mathbf{(f_{r_i})}\\)\nFreq. percentual \\(\\mathbf{(f_{\\%_i})}\\)\n\n\n\n\n\\(0\\)\n\\(3\\)\n\\(0,15\\)\n\\(0,15 \\times 100 = 15\\%\\)\n\n\n\\(1\\)\n\\(7\\)\n\\(0,35\\)\n\\(0,35 \\times 100 = 35\\%\\)\n\n\n\\(2\\)\n\\(4\\)\n\\(0,20\\)\n\\(0,20 \\times 100 = 20\\%\\)\n\n\n\\(3\\)\n\\(5\\)\n\\(0,25\\)\n\\(0,25 \\times 100 = 25\\%\\)\n\n\n\\(4\\)\n\\(1\\)\n\\(0,05\\)\n\\(0,05 \\times 100 = 5\\%\\)\n\n\nTotal\n\\(20\\)\n\\(1\\)\n\\(100\\%\\)\n\n\n\n\n\n\nPodemos observar que, \\(35\\%\\) do grupo de caracteres apresentava apenas \\(1\\) erro, \\(15\\%\\) dos grupos não apresentaram erros. Porém, se perguntássemos, no mínimo, quantos grupos apresentaram \\(2\\) erros? Em quantos grupos tivemos, no máximo, \\(3\\) erros? A primeira pergunta, seria respondida somando as frequências simples (ou absolutas) \\(4\\) \\(+\\) \\(5\\) \\(+\\) \\(1\\) \\(=\\) \\(10\\) grupos. Para a segunda pergunta, responderíamos \\(3\\) \\(+\\) \\(7\\) \\(+\\) \\(4\\) \\(+\\) \\(5\\) \\(+\\) \\(1\\) \\(=\\) \\(19\\) grupos. Isso poderia tornar mais oneroso, à medida que o nome de grupos fosse aumentando. Ao invés, usaremos as frequências acumuladas, para auxiliar indagações desse tipo aos dados.\nTemos dois tipos de frequências acumuladas, a frequência acumulada abaixo de, denotada por \\(F_{ac\\downarrow}\\), cujo valor calculado é denotado por \\(f_{ac\\downarrow}\\), dado pela expressão (2.3),\n\\[\n\\begin{align}\n  F_{ac\\downarrow_i} & = \\sum_{j = 1}^{i}F_j, \\quad i = 1, 2, \\ldots, k,\n\\end{align}\n\\tag{2.3}\\] sendo \\(k\\) o número de grupos ou classes, e \\(F_j\\) representando \\(j\\)-ésima frequência absoluta.\nA outra é a frequência acumulada acima de, denotada por \\(F_{ac\\uparrow}\\), cujo valor calculado é denotado por \\(f_{ac\\uparrow}\\), dado pela expressão (2.4), \\[\n\\begin{align}\n  F_{ac\\uparrow_i} & = \\sum_{j = i}^{k}F_j, \\quad i = 1, 2, \\ldots, k,\n\\end{align}\n\\tag{2.4}\\] sendo \\(k\\) o número de grupos ou classes, e \\(F_j\\) representando \\(j\\)-ésima frequência absoluta. Na Tabela 2.6, complementamos as informações com as frequências acumuladas os dados apresentados da Tabela 2.5.\n\n\n\nTabela 2.6: Frequência percentual do número de erros encontrados (\\(x_i\\)) em 20 conjunto de caracteres monitorado em um canal de comunicação.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(\\mathbf{x_i}\\)\n\\(\\mathbf{f_i}\\)\n\\(\\mathbf{f_{r_i}}\\)\n\\(\\mathbf{f_{\\%_i}}\\)\nFreq. acum. \\(\\mathbf{(f_{ac\\downarrow_i})}\\)\nFreq. acum. \\(\\mathbf{(f_{ac\\uparrow_i})}\\)\n\n\n\n\n\\(0\\)\n\\(3\\)\n\\(0,15\\)\n\\(15\\%\\)\n\\(3\\)\n\\(3 + 7 + 4 + 5 + 1 = 20\\)\n\n\n\\(1\\)\n\\(7\\)\n\\(0,35\\)\n\\(35\\%\\)\n\\(3 + 7 = 10\\)\n\\(7 + 4 + 5 + 1 = 20 - 3 = 17\\)\n\n\n\\(2\\)\n\\(4\\)\n\\(0,20\\)\n\\(20\\%\\)\n\\(3 + 7 + 4 = 14\\)\n\\(4 + 5 + 1 = 17 -  7 = 10\\)\n\n\n\\(3\\)\n\\(5\\)\n\\(0,25\\)\n\\(25\\%\\)\n\\(3 + 7 + 4 + 5 = 19\\)\n\\(5 + 1 = 10 - 4 = 6\\)\n\n\n\\(4\\)\n\\(1\\)\n\\(0,05\\)\n\\(5\\%\\)\n\\(3 + 7 + 4 + 5 + 1 = 20\\)\n\\(1 = 6 - 5 = 1\\)\n\n\nTotal\n\\(20\\)\n\\(1\\)\n\\(100\\)\n-\n-\n\n\n\n\n\n\nÉ importante notar que sempre o último valor da coluna da frequência acumulada abaixo de é o número total de elementos, e que o último valor da frequência acumulada acima de coincide com o seu respectivo valor da frequência simples (\\(f_i\\)), como pode ser observado na Tabela 2.6. Uma outra coisa interessante, é que podemos ter uma forma alternativa de calcular a frequência acumulada acima de, dado pela expressão (2.5),\n\\[\n\\begin{align}\n  F_{ac\\uparrow_i} & = \\left\\{\\begin{array}{ll}\n                         \\sum_{i = 1}^{k}F_i, & i = 1,  \\\\\n                         F_{ac_{\\uparrow_{i - 1}}} - F_{i-1}, & \\textrm{demais casos,}\n                       \\end{array}\\right.\n\\end{align}\n\\tag{2.5}\\] sendo \\(k\\) o número de grupos ou classes. Vamos tentar entender as equivalências entre as expressões (2.4) e (2.5). Indagamos, quantos grupos apresentam, no mínimo, \\(1\\) erro? Observe que \\(x_2 = 1\\), isto é, os valores observados iguais a \\(1\\), estão no segundo grupo. Assim, pela expressão (2.4), temos que a frequência acumulada (abaixo de) observada para o segundo grupo é\n\\[\\begin{align*}\n  f_{ac\\uparrow_2} &  = \\sum_{j = 2}^{5}f_j = 7 + 4 + 5 + 1 = 17.\n\\end{align*}\\] Da mesma forma, podemos utilizar a expressão (2.5), e de modo equivalente, temos \\[\\begin{align*}\n  f_{ac\\uparrow_2} &  = f_{ac_{\\uparrow_{2 - 1}}} - f_{2 - 1}\\\\\n                   &  = f_{ac_{\\uparrow_{1}}} - f_1\\\\\n                   &  = 20 - 3 = 17.\n\\end{align*}\\]\nA expressão (2.5) pode parecer no primeiro momento mais trabalhoso o cálculo. Porém, perceberemos com a prática de exercícios que esse processo é mais rápido do que calcular usando a expressão (2.4).\nPor fim, podemos apresentar a forma relativa e percentual das fre-quências acumuladas, usando de modo similar, quando calculamos as frequências relativas e percentuais, dadas nas expressões (2.1) e (2.2), respectivamente. Denotaremos a frequência relativa acumulada “abaixo de”, por \\(Fr_{ac\\downarrow_{i}}\\), e a frequência relativa acumulada “acima de”, por \\(Fr_{ac\\uparrow_{i}}\\), para o \\(i\\)-ésimo grupo ou classe. As expressões dessas duas frequências são dadas, respectivamente, por \\[\n\\begin{align}\n  Fr_{ac\\downarrow_{i}} & = \\frac{F_{ac\\downarrow_i}}{\\sum_{i = 1}^{k}F_i} \\quad i = 1, 2, \\ldots, k,\n\\end{align}\n\\tag{2.6}\\] e \\[\n\\begin{align}\n  Fr_{ac\\uparrow_{i}} & = \\frac{F_{ac\\uparrow_i}}{\\sum_{i = 1}^{k}F_i} \\quad i = 1, 2, \\ldots, k,\n\\end{align}\n\\tag{2.7}\\] em que \\(F_{ac\\downarrow_i}\\) expresso em (2.3), \\(F_{ac\\uparrow_i}\\) expresso em (2.4), e \\(k\\) é igual ao número de grupos ou classes. Já para as frequências percentuais acumuladas abaixo de e acima de, denotando-as por \\(F_{ac\\downarrow_i\\%}\\) e \\(F_{ac\\uparrow_i\\%}\\), respectivamente, e sendo expressas por \\[\n\\begin{align}\nF_{ac\\downarrow_{i}\\%}  & = Fr_{ac\\downarrow_{i}} \\times 100 \\quad i = 1, 2, \\ldots, k,\n\\end{align}\n\\tag{2.8}\\] e \\[\n\\begin{align}\nF_{ac\\uparrow_{i}\\%} & = Fr_{ac\\uparrow_{i}} \\times 100 \\quad i = 1, 2, \\ldots, k,\n\\end{align}\n\\tag{2.9}\\] respectivamente, em que \\(k\\) é o número de grupos ou classes.\nVoltando ao conjunto de dados iniciado na Tabela 2.1, podemos finalizar a sua tabulação com todas as frequências mencionadas anterioremente, em um quadro resumo na Tabela 2.7.\n\n\n\nTabela 2.7: Distribuição de frequências do número de erros encontrados em 20 conjunto de caracteres monitorado em um canal de comunicação.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNº de erros \\(\\mathbf{(x_i)}\\)\n\\(\\mathbf{f_i}\\)\n\\(\\mathbf{f_{r_i}}\\)\n\\(\\mathbf{f_{\\%_i}}\\)\n\\(\\mathbf{f_{ac\\downarrow_i}}\\)\n\\(\\mathbf{f_{ac\\uparrow_i}}\\)\n\\(\\mathbf{fr_{ac_{\\downarrow}}}\\)\n\\(\\mathbf{fr_{ac_{\\uparrow}}}\\)\n\\(\\mathbf{f_{ac_{\\downarrow}\\%}}\\)\n\\(\\mathbf{f_{ac_{\\uparrow}\\%}}\\)\n\n\n\n\n\\(0\\)\n\\(3\\)\n\\(0,15\\)\n\\(15\\)\n\\(3\\)\n\\(20\\)\n\\(0,15\\)\n\\(1\\)\n\\(15\\)\n\\(100\\)\n\n\n\\(1\\)\n\\(7\\)\n\\(0,35\\)\n\\(35\\)\n\\(10\\)\n\\(17\\)\n\\(0,50\\)\n\\(0,85\\)\n\\(50\\)\n\\(85\\)\n\n\n\\(2\\)\n\\(4\\)\n\\(0,20\\)\n\\(35\\)\n\\(14\\)\n\\(10\\)\n\\(0,70\\)\n\\(0,50\\)\n\\(70\\)\n\\(50\\)\n\n\n\\(3\\)\n\\(5\\)\n\\(0,25\\)\n\\(25\\)\n\\(19\\)\n\\(6\\)\n\\(0,95\\)\n\\(0,20\\)\n\\(95\\)\n\\(20\\)\n\n\n\\(4\\)\n\\(1\\)\n\\(0,05\\)\n\\(5\\)\n\\(20\\)\n\\(1\\)\n\\(1\\)\n\\(0,05\\)\n\\(100\\)\n\\(5\\)\n\n\nTotal\n\\(20\\)\n\\(1\\)\n\\(100\\)\n-\n-\n\\(1\\)\n\\(1\\)\n-\n-\n\n\n\n\n\n\nEssa representação tabular como falado anteriormente, pode ser usado para todas as variáveis discretizadas, como as variáveis qualitativas quanto a variável quantitativa discreta. Porém, para o caso da variável qualitativa nominal, não faz sentido o uso da frequência acumulada, uma vez que esse tipo de variável não tem ordenamento no sentido quantitativo.\nPor meio do pacote leem, podemos tabular esses dados. Inicialmente podemos realizar a instalação do pacote usando o Código R 2.1.\n\n\n\n\nCódigo R 2.1: Instalando o pacote leem.\n\n\n# Instalando o pacote 'leem' (via CRAN)\n# install.packages(\"leem\")\n# (ou) Instalando via github\npkgs &lt;- c(\"manipulate\", \"tkRplotR\",\n         \"tkrplot\", \"crayon\")\ninstall.packages(pkgs)\n# Instalando o pacote 'devtools'\ninstall.packages(\"devtools\")\n# Instalando o pacote 'leem'\ndevtools::install_github(\"bendeivide/leem\")\n\n\n\n\nAgora, tabular os dados de acordo com a Tabela 2.7 usando o leem é apresentado no Código R 2.2.\n\n\n\n\nCódigo R 2.2: Tabulando dados discretos.\n\n\n# Anexando o pacote leem\nlibrary(leem)\n# Importando o banco de dados\ncon &lt;- url(\"https://raw.githubusercontent.com/bendeivide/book-epaec/master/dados/cap02/challenger.RData\")\nload(con); close(con)\n\n# Tabulando os dados\nchallenger |&gt;\nnew_leem(variable = 2) |&gt;\ntabfreq()\n\n\n\n\n\nTabela de frequência \nTipo de variável: continuous\n\n          Classes Fi   PM   Fr Fac1 Fac2 Fp  Fac1p  Fac2p\n1 25.7 |---  36.3  1 31.0 0.03    1   36  3   2.78 100.00\n2 36.3 |---  46.9  2 41.6 0.06    3   35  6   8.33  97.22\n3 46.9 |---  57.5  4 52.2 0.11    7   33 11  19.44  91.67\n4 57.5 |---  68.1 12 62.8 0.33   19   29 33  52.78  80.56\n5 68.1 |---  78.7 12 73.4 0.33   31   17 33  86.11  47.22\n6 78.7 |---  89.3  5 84.0 0.14   36    5 14 100.00  13.89\n\n============================================== \nClasses: Agrupamento de classes \nFi: Frequência absoluta \nPM: Ponto médio \nFr: Frequência relativa \nFac1: Frequência acumulada (abaixo de) \nFac2: Frequência acumulada (acima de) \nFp: Frequência percentual \nFac1p: Frequência acumulada percentual (abaixo de) \nFac2p: Frequência acumulada percentual (acima de) \n\n\nPara o caso da variável quantitativa contínua, precisamos agrupar os valores observados em intervalos de classe, isso porque a discretização de seus valores se devem aos instrumentos de medida, e não a natureza da variável. Por exemplo, quando medimos uma altura, \\(1,78m\\), de fato a altura real não está limitado a segunda casa decimal. Então, a melhor forma será criar regiões (intervalos), de modo que possamos contemplar determinados valores.\nExistem diversas formas de como agrupar as variáveis quantitativas contínuas, isto é, metodologias de como desenvolver a criação de classes. Contudo, iremos nos restringir a um critério empírico, que se baseia no número de elementos, seja na amostra ou população. A primeira indagação que surge é, qual o número de classes para agrupar esses dados? Denotaremos por \\(k\\) o número de classes, cuja expressão é dada por: \\[\n\\begin{align}\n  k & \\approx \\left\\{\\begin{array}{ll}\n          \\sqrt{m}, & m \\leq 100; \\\\\n          5log_{10}(m), & m &gt; 100,\n        \\end{array}\\right.\n\\end{align}\n\\tag{2.10}\\] em que \\(m\\) representa o número de elementos.\nNesse caso, o cálculo de \\(k\\) é uma aproximação, e devemos aproximar a um número inteiro mais próximo. Pode ocorrer situações em que o número de classes resulte em um agrupamento em que tenhamos classes com frequência \\(0\\), isto é, com nenhum elemento dentro dessa classe. Não faz sentido criar uma classe sem elementos. Dessa forma, ao final do processo da criação de tabelas com intervalos de classes e verificado classes sem elementos, o processo deve ser reiniciado e alterado o valor de \\(k\\), ou um número inteiro para baixo ou para cima. Após isso, todo o processo que será apresentado na sequência, deverá seguir. Caso esse problema se repita, novamente, voltaremos a fase de determinação de \\(k\\) até encontrar um inteiro, do qual se obtenha agrupamento de dados com intervalo de classes, com frequência em suas classes superior a 0. Em todo esses processo, devemos evitar que o número de classes seja inferior a 3, uma vez que para \\(k &lt; 3\\) não será necessário um agrupamento de dados em tabela, para uma quantidade tão pequena de valores.\nDando sequência, após a determinação do número de classes, determinaremos a amplitude total, denotada por \\(A_t\\), sendo definida pela expressão (2.11), \\[\n\\begin{align}\n  A_t & = \\max_i(X_i) - \\min_i(X_i),\n\\end{align}\n\\tag{2.11}\\] para \\(i \\in \\mathbb{N}^{+}\\).\nPosteriormente, deveremos determinar a amplitude da classe, denotada por \\(c\\) e expressa como: \\[\n\\begin{align}\n  c & = \\left\\{\\begin{array}{ll}\n           \\frac{A_t}{k - 1}, & \\textrm{Amostra} \\\\\n           \\frac{A_t}{k}, & \\textrm{População}.\n        \\end{array}\\right.\n\\end{align}\n\\tag{2.12}\\] em \\(A_t\\) é expresso em (2.11) e \\(k\\) dada pela expressão (2.10). O fato de o denominado ter o valor de \\(k\\) subtraído de 1, ao invés de \\(k\\) para o caso dos dados amostrais, é devido a uma correção realizada no cálculo do limite inferior da primeira classe, que será apresentada a seguir. Segundo Ferreira (2009, p. 13) a justificativa se deve a suposição de que uma amostra de tamanho \\(n\\) tem grande chance de não conter o valor mínimo da população, isto é, à medida que o tamanho da amostra aumenta, temos uma maior chance de obter elementos menores que o valor mínimo que foi encontrado para uma amostra de tamanho menor.\nPor fim, apresentamos o cálculo para se obter o limite inferior da primeira, denotado por \\(Li_{1a}\\), sendo dado pela expressão (2.13), \\[\n\\begin{align}\nLi_{1a} & = \\left\\{\\begin{array}{ll}\n           X_{(1)} - c / 2, & \\textrm{Amostra} \\\\\n           X_{(1)}, & \\textrm{População}.\n        \\end{array}\\right.\n\\end{align}\n\\tag{2.13}\\] Realizando esses quatro passos, iremos criar as classes, iniciando pelo limite inferior da primeira classe, e para essa mesma classe, o seu limite superior será denotado por \\(Ls_{1a}\\), cujo cálculo é dado por \\(Ls_{1a} = Li_{1a} + c\\). Representaremos em notação a primeia classe da seguinte forma:\n\n\n\nClasse\n\n\n\\(Li_{1a}\\) \\(|\\)— \\(Ls_{1a}\\)\n\n\n\nEm termos de conjunto, diremos que \\(\\textrm{Classe 1} = \\{x \\in \\mathbb{R}~:~Li_{1a} \\leq x &lt; Ls_{1a}\\}\\), isto é, os valores observados pertencerão a essa classe se forem iguais ou superiores a \\(Li_{1a}\\) e inferiores a \\(Ls_{1a}\\). Como o valor do limite superior não pertence a essa classe, será contabilizado para a próxima classe. Nesse caso, o limite inferior da segunda classe será dado por \\(Li_{2a} = Ls_{1a}\\) e seu limite superior \\(Ls_{2a} = L1_{1a} + c\\), em que \\(c\\) é a amplitude da classe. Inserindo agora a segunda classe na tabela, temos:\n\n\n\nClasse\n\n\n\\(Li_{1a}\\) \\(|\\)— \\(Ls_{1a}\\)\n\n\n\\(Li_{2a}\\) \\(|\\)— \\(Ls_{2a}\\)\n\n\n\nMais uma vez, o valor do limite superior dessa classe não pertence, mas pertencerá a próxima classe. Esse processo continua, até chegar a \\(k\\)-ésima classe, que ao final teremos uma tabela da seguinte forma,\n\n\n\nClasse\n\n\n\\(Li_{1a}\\) \\(|\\)— \\(Ls_{1a}\\)\n\n\n\\(Li_{2a}\\) \\(|\\)— \\(Ls_{2a}\\)\n\n\n\\(\\vdots\\)\n\n\n\\(Li_{ka}\\) \\(|\\)—\\(|\\) \\(Ls_{ka}\\)\n\n\n\nNo caso da última classe, nós contemplamos os valores dos limites a essas classes, caso existam no banco de dados. Assim, a frequência absoluta é calculada verificando os valores que estão dentro da amplitude dos intervalos, e as demais frequências seguem o mesmo raciocínio falado anteriormente. Algumas notações vistas na literatura não contemplam o limite superior da última classe, e assim, essa classe pode ser também representada da forma \\(Li_{ka}\\) \\(|\\)— \\(Ls_{ka}\\). Um problema surge com os dados, porque ao serem agrupados nas classes nós perdemos essa informação. Vejamos a representação de uma classe com a sua frequência absoluta,\n\n\n\nClasse\n\\(\\mathbf{f_i}\\)\n\n\n\\(Li_{1a}\\) \\(|\\)— \\(Ls_{1a}\\)\n\\(f_1\\)\n\n\n\\(Li_{2a}\\) \\(|\\)— \\(Ls_{2a}\\)\n\\(f_2\\)\n\n\n\\(\\vdots\\)\n\n\n\n\\(Li_{ka}\\) \\(|\\)—\\(|\\) \\(Ls_{ka}\\)\n\\(f_k\\)\n\n\n\nObserve que sabemos quantos valores existem em cada classe, mas sem a informação dos dados brutos ou elaborados, nós não sabemos quais são os valores pertencentes a cada classe. Assim, uma alternativa de valor para representar as \\(f_i\\), para \\(i\\) \\(=\\) \\(1\\), \\(2\\), \\(\\ldots\\), \\(k\\), em cada classe é usa o ponto médio. Esse critério é chamado hipótese tabular básica. Essa hipótese sugere que assumir o ponto médio como um potencial representante dos valores de uma determinada classe, assume um menor erro do que escolher qualquer outro valor dentro desse intervalo para representar essas observações. O ponto médio, denotado por \\(\\tilde{X}_i\\), será dado por: \\[\n\\begin{align}\n  \\tilde{X}_i & = \\frac{Li_{ia} + Ls_{ia}}{2}, \\quad i = 1, 2, \\ldots, k.\n\\end{align}\n\\tag{2.14}\\] Percebemos, que ocorre uma perda de precisão nos dados quando agrupamos em intervalo de classes, uma vez que o ponto médio passa a representar esses valores em cada classe. De todo modo, se observa que essa perda de informação é pequena para o ganho que se obtém ao representar esses dados em tabulação com intervalo de classe, no sentido não só de organização, mas de entendimento das informações. Em resumo, podemos dizer que o algoritmo para criar um agrupamento de dados em intervalo de classes pode ser dados em sete passos:\n\nCalcular \\(k\\),\nCalcular \\(A_t\\),\nCalcular \\(c\\),\nCalcular \\(Li_{1a}\\),\nDeterminar as classes,\nCalcular o ponto médio, e\nCalcular as frequências como apresentadas no início dessa seção.\n\nOs dados do Exemplo 2.1 foram retirados de Presidential Comission (1986, p. 129–131), e apresentados a seguir.\n\nExemplo 2.1Os dados representam a temperatura (ºF) do anel de vedação de cada teste de acionamento ou lançamento real do motor do foguete Challenger, isso porque, em 1986, houve nos Estados Unidos um dos maiores acidentes com ônibus espaciais, vitimando em 8 astronautas que estavam na tripulação. Foram realizados diversos estudos pela NASA para identificar as causas da falha. A primeira atenção se voltou para a temperatura do anel de vedação, que é apresentado a seguir.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n84\n49\n61\n40\n83\n67\n45\n66\n70\n69\n80\n58\n\n\n68\n60\n67\n72\n73\n70\n57\n63\n70\n78\n52\n67\n\n\n53\n67\n75\n61\n70\n81\n76\n79\n75\n76\n58\n31\n\n\n\nDiante dessas informações, para melhor apresentar essas informações, vamos agrupar esses dados em uma tabela com intervalo de classes, uma vez que a temperatura do anel de vedação é uma variável quantitativa contínua. Inicialmente, vamos calcular o número de classes, \\(k = \\sqrt{36} = 6\\) classes. Observando os valores, percebemos que \\(x_{(1)} = 31^oF\\) e \\(x_{(36)} = 84^oF\\), logo a amplitude total é \\(A_t = 53^oF\\). Na sequência, calculamos amplitude da classe, \\(c = 53 / (6 - 1) = 10,6^oF\\), por fim, o limite inferior da primeira classe, \\(Li_{1a} = 31 - 10,6 / 2 = 25,7^oF\\). Assim, começaremos pela primeira classe, em que já temos o limite inferior dela e seu limite superior será \\(Li_{1a} = 25,7 + 10,6 = 36,3^oF\\). As demais classes, segue o procedimento descrito anteriormente. Por fim, verificaremos quais o valores pertencentes em cada classe para computar a frequência absoluta, o cálculo do ponto médio de acordo com a expressão (2.14) e as demais frequências calculadas como descritas no início dessa seção. Assim, temos o quadro geral de uma tabela com intervalo de classes para esses dados, apresentados a seguir.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClasse\n\\(\\mathbf{f_i}\\)\n\\(\\mathbf{\\tilde{x}_i}\\)\n\\(\\mathbf{f_{r_i}}\\)\n\\(\\mathbf{f_{ac\\downarrow_i}}\\)\n\\(\\mathbf{f_{ac\\uparrow_i}}\\)\n\\(\\mathbf{f_{\\%_i}}\\)\n\\(\\mathbf{f_{ac_{\\downarrow}\\%}}\\)\n\\(\\mathbf{f_{ac_{\\uparrow}\\%}}\\)\n\n\n\n\n25,7 \\(|\\)— 36,3\n1,00\n31,00\n0,03\n1,00\n36,00\n3,00\n2,78\n100,00\n\n\n36,3 \\(|\\)— 46,9\n2,00\n41,60\n0,06\n3,00\n35,00\n6,00\n8,33\n97,22\n\n\n46,9 \\(|\\)— 57,5\n4,00\n52,20\n0,11\n7,00\n33,00\n11,00\n19,44\n91,67\n\n\n57,5 \\(|\\)— 68,1\n12,00\n62,80\n0,33\n19,00\n29,00\n33,00\n52,78\n80,56\n\n\n68,1 \\(|\\)— 78,7\n12,00\n73,40\n0,33\n31,00\n17,00\n33,00\n86,11\n47,22\n\n\n78,7 \\(|\\)—\\(|\\) 89,3\n5,00\n84,00\n0,14\n36,00\n5,00\n14,00\n100,00\n13,89\n\n\n\n\n\n\nPor meio do pacote leem, Código R 2.3, podemos tabular os dados agrupados em intervalo de classes, para variáveis quantitativas contínuas, o mesmo conjunto de dados apresentado no Exemplo 2.1.\n\n\n\n\nCódigo R 2.3: Tabulando dados contínuos.\n\n\n# Anexando o pacote leem\nlibrary(leem)\n# Importando o banco de dados\ncon &lt;- url(\"https://raw.githubusercontent.com/bendeivide/book-epaec/master/dados/cap02/challenger.RData\")\nload(con); close(con)\n\n# Tabulando os dados\nchallenger |&gt;\nnew_leem(variable = 2) |&gt;\ntabfreq()\n\n\n\n\n\nTabela de frequência \nTipo de variável: continuous\n\n          Classes Fi   PM   Fr Fac1 Fac2 Fp  Fac1p  Fac2p\n1 25.7 |---  36.3  1 31.0 0.03    1   36  3   2.78 100.00\n2 36.3 |---  46.9  2 41.6 0.06    3   35  6   8.33  97.22\n3 46.9 |---  57.5  4 52.2 0.11    7   33 11  19.44  91.67\n4 57.5 |---  68.1 12 62.8 0.33   19   29 33  52.78  80.56\n5 68.1 |---  78.7 12 73.4 0.33   31   17 33  86.11  47.22\n6 78.7 |---  89.3  5 84.0 0.14   36    5 14 100.00  13.89\n\n============================================== \nClasses: Agrupamento de classes \nFi: Frequência absoluta \nPM: Ponto médio \nFr: Frequência relativa \nFac1: Frequência acumulada (abaixo de) \nFac2: Frequência acumulada (acima de) \nFp: Frequência percentual \nFac1p: Frequência acumulada percentual (abaixo de) \nFac2p: Frequência acumulada percentual (acima de)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Coleta, organização e apresentação dos dados</span>"
    ]
  },
  {
    "objectID": "cap02.html#sec-repgraficas",
    "href": "cap02.html#sec-repgraficas",
    "title": "2  Coleta, organização e apresentação dos dados",
    "section": "2.3 Representação gráfica",
    "text": "2.3 Representação gráfica\nAo final do que foi apresentado no Exemplo 2.1, percebemos uma simplificação da apresentação dos dados. Mesmo assim, esse tipo de apresentação pode não ser satisfatório para que visualiza, seja pela complexidade que a disposição dessas informações ainda exige ou a sua própria limitação de conhecimento. Um apelo mais simples e rápido de ser entendido é a representação gráfica dos dados.\nA disposição gráfica de dados evolui bastante ao longo do tempo, e muitos recursos estão disponíveis hoje. Por exemplo, no ambiente R existe alguns pacotes nativos, mas em especial o pacote graphics. Este pacote apresenta recursos para desenvolvimento de gráficos, apresentando funções de nível superior (nível de usuário) até funções específicas para a criação de nossos próprios gráficos. As funções de nível superior já nos dão suporte a criação de diversos tipos de gráficos, tais como: gráfico de barras, histogramas, gráfico de linhas, gráfico de dispersão, dentre outros. Não satisfeitos com estes, podemos criar também os nossos próprios gráficos com este pacote.\nCom o apoio de toda a comunidade científica ao ambiente R, um outro pacote que apresenta destaque hoje na apresentação gráfica de dados é o ggplot2 (Wickham, 2016). Este pacote apresenta uma série de recursos gráficos para serem utilizados, mas não sendo objeto de estudo deste material.\nPretendemos para esta seção apresentar apenas alguns tipos de gráficos com o intuito de motivar esse tipo de apresentação de dados, usando o pacote leem. Os gráficos são:\n\nGráfico de hastes ou bastão;\nGráfico de barras;\nGráfico de Pizzas;\nHistograma de frequências;\nPolígono de frequências;\nGráfico de Ogivas;\n\n\n2.3.1 Gráfico de hastes ou bastão\nO gráfico de hastes ou bastão é utilizado para variáveis discretizadas, isto é, as variáveis qualitativas e a variável quantitativa discreta. Consiste em um gráfico no plano cartesiano do qual usamos os valores observados no eixo \\(X\\) e a frequência dessas observações é verificada no eixo \\(Y\\). Para esta representação são usados as hastes ou bastões. Retornando ao exemplo dos dados da Tabela 2.3, podemos representá-lo pelo gráfico de hastes ou bastão usando o Código R 2.4.1\n\n\n\n\nCódigo R 2.4: Gráfico de hastes ou bastão.\n\n\n# Anexando o pacote leem\nlibrary(leem)\n# Importando o banco de dados\ncon &lt;- url(\"https://raw.githubusercontent.com/bendeivide/book-epaec/master/dados/cap02/nerros.RData\")\nload(con); close(con)\n# Tabulando os dados\nnerros |&gt;\n  new_leem(variable = 1) |&gt;\n  tabfreq() |&gt;\n  stickchart()\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.3.2 Gráfico de barras\nO gráfico de barras tem a mesma ideia que o gráfico de hastes, substituindo as hastes pelas barras, em que a largura das barras não apresenta interpretação prática. Lembrando que da mesma forma que a representação anterior, este tipo de gráfico pode ser utilizado para variáveis qualitativas e quantitativas discretizadas. Para ilustrar, retornemos ao Exemplo 1.3, e vamos representar por meio do gráfico de barras os 9 estados que representam a Amazônia Legal quanto a variável “região”, apresentado no Código R 2.5.\nPoderemos representar esse mesmo conjunto de dados por meio de um gráfico de pizzas ou gráfico de setores. Este gráfico consiste em representar as observações com que os valores se repetem em setores de um círculo. A área de cada setor é uma relação da frequência percentual dos dados e a área do círculo. Para a construção do gráfico de pizzas tomaremos por base o Exemplo 1.3, referente aos dados da variável “região”, apresentada na Tabela 2.8.\n\n\n\n\nCódigo R 2.5: Gráfico de barras.\n\n\n# Anexando o pacote leem\nlibrary(leem)\n# Regiao (Estados a amazonia legal)\nregiao &lt;- c(rep(\"Norte\", 7), \"Centro-Oeste\",\n   \"Nordeste\")\n# Tabulando os dados\nregiao |&gt;\n  new_leem(variable = 1) |&gt;\n  tabfreq(namereduction = FALSE) |&gt;\n  barplot(barcol = heat.colors(3), posx2 = -0.2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTabela 2.8: Dados da variável região da Amazônia Legal, Exemplo 1.3.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRegião\n\\(\\mathbf{f_i}\\)\n\\(\\mathbf{f_{r_i}}\\)\n\\(\\mathbf{f_{ac\\downarrow_i}}\\)\n\\(\\mathbf{f_{ac\\uparrow_i}}\\)\n\\(\\mathbf{f_{\\%_i}}\\)\n\\(\\mathbf{f_{ac_{\\downarrow}\\%}}\\)\n\\(\\mathbf{f_{ac_{\\uparrow}\\%}}\\)\n\n\n\n\n\n1\nCentro-Oeste\n1,00\n0,11\n1,00\n9,00\n11,00\n11,11\n100,00\n\n\n\n2\nNordeste\n1,00\n0,11\n2,00\n8,00\n11,00\n22,22\n88,89\n\n\n\n3\nNorte\n7,00\n0,78\n9,00\n7,00\n78,00\n100,00\n77,78\n\n\n\n\n\n\n\nTomando por base o ângulo (\\(360°\\)) de um círculo em torno do seu centro, em relação a soma da frequência percentual (\\(100\\%\\)) dos dados, podemos identificar o quanto que cada grupo (setor) pode ser representado em um círculo. Tomemos a região 1 (Centro-Oeste):\n\n\n\n\\(100\\%\\)\n\\(\\to\\)\n\\(360\\)°\n\n\n\\(11\\%\\)\n\\(\\to\\)\n\\(x\\)°\n\n\n\nLogo, por regra de três simples temos que \\(x\\)° = \\(39,6\\)°, isto é, o setor correspondente a região Centro-Oeste contempla uma área com \\(39,6\\)° em torno do centro do círculo, e isso representa \\(11\\%\\) do círculo. Usando essa mesma ideia para os outros dois setores (grupos), temos para a região Nordeste (\\(39,6\\)°) e região Norte (\\(280,8\\)°). Para representa o gráfico de pizzas, usaremos o Código R 2.6. Lembrando que esta representação para dados contínuos poderia ser possível, desde que estes tivessem agrupados em classes. Outro ponto importante é que o gráfico de pizzas é bem mais utilizado para a área de publicidade do que na ciência de uma forma geral, uma vez que a visualização gráfica de barras ou de pontos se tornam muito mais fácil de ser visualizada por meio de suas frequências do que suas representações em forma de ângulo. Nossas percepções são melhores para julgamentos de medidas lineares do que áreas relativas.\n\n\n\n\nCódigo R 2.6: Gráfico de pizzas.\n\n\n# Anexando o pacote leem\nlibrary(leem)\n# Regiao (Estados a amazonia legal)\nregiao &lt;- c(rep(\"Norte\", 7), \"Centro-Oeste\",\n\"Nordeste\")\n# Tabulando os dados\nregiao |&gt;\n  new_leem(variable = 1) |&gt;\n  tabfreq(namereduction = FALSE) |&gt;\n  piechart(main = \"Estados da Amazônia Legal\")\n\n\n\n\n\n\n\n\n\n\n\nFalamos anteriormente que poderíamos representar os dados de uma variável quantitativa contínua distribuída em intervalo de classes por meio de um gráfico de pizzas, porém uma representação mais adequada seria por meio do histograma de frequências, apresentado a seguir.\n\n\n2.3.3 Histograma de frequências\nO histograma de frequências está relacionado diretamente com a distribuição de frequências em intervalo de classes. Esse gráfico apresenta a mesma ideia do gráfico de barras, porém a largura das barras apresentam um significado prático que é a amplitude de cada classe. Lembrando que as amplitudes das classes não necessariamente precisam ser iguais, depende de que metodologia está sendo adotada. Para o nosso caso, assumiremos que a amplitude da classe (\\(c\\)) será sempre igual para todas as classes. Ainda, os extremos de cada barra representam o limite inferior e superior de cada classe.\nUsaremos como ilustração, os dados da tabela apresentados no Exemplo 2.1. Por meio do Código R 2.7, verificamos o histograma de frequência destes dados.\n\n\n\n\nCódigo R 2.7: Gráfico de histograma.\n\n\n# Anexando o pacote leem\nlibrary(leem)\n# Importando o banco de dados\ncon &lt;- url(\"https://raw.githubusercontent.com/bendeivide/book-epaec/master/dados/cap02/challenger.RData\")\nload(con); close(con)\n# Imprimindo os dados\n# challenger\n# Tabulando os dados\nchallenger |&gt;\n  new_leem(variable = 2) |&gt;\n  hist()\n\n\n\n\n\n\n\n\n\n\n\nVerificando o histograma de frequências, visualmente se tentássemos predizer a frequência com que ocorre determinadas observações entre os limites, isso não seria possível. E que apesar de teoricamente a chance de uma observação de uma variável quantitativa contínua se repetir em um conjunto de dados, ser praticamente nula, sabemos que internamente em uma classe de distribuição de frequências esta região não é equitativa. Pode ser que a maior concentração dos dados em uma classe esteja mais próxima do limite superior, ou o contrário, ou nenhum dos dois. E isso pode ser verificado visualmente pelo polígono de frequências, apresentado a seguir.\n\n\n2.3.4 Polígono de frequências\nO polígono de frequências consiste em observar o histograma de frequência e representar os pontos médios das classes por meio de um ponto, elevando-os a altura das barras. Posteriormente, une-as por uma linha.\nPodemos representar o mesmo conjunto de dados com o que foi abordado no Código R 2.7 graficamente pelo polígonos de frequências na Figura 2.1.\n\n\n\n\n\n\n\n\nFigura 2.1: Polígono de frequências dos dados representam a temperatura (°F) do anel de vedação de cada teste de acionamento ou lançamento real do motor do foguete Challenger.\n\n\n\n\n\nO polígono de frequências representa apenas os pontos ligados a um linha tracejada na Figura 2.1. As barras representam apenas a ideia de como este gráfico foi originado. Uma outra observação interessante é que não iniciamos o polígono de frequências identificando como o primeiro ponto como o limite inferior da primeira classe, como também o último ponto sendo o limite superior da última classe. Estes pontos apresentam frequências iguais a zero, e acaba não sendo verdade afirmar que o limite inferior e o limite superior, ou valores próximos a eles tenham frequências próximas de zero. Assim, para representar melhor o conjunto de dados, criamos mais duas classes vizinhas às classes extremas, como apresentados na Figura 2.1, que são as classes: “\\(15,1\\) |— \\(25,7\\)” e \\(89,3\\) |— \\(99,9\\)“, respectivamente. Assim, o ponto inicial e o final do polígono de frequências serão os pontos médios dessas classes criadas com frequência zero. Dessa forma, perceberemos que as frequências próximas do limite inferior e superior da primeira classe e da última classe, respectivamente, não são iguais a zero como de fato esperamos.\nCom isso apresentamos como de fato deve ficar o polígono de frequências usando o Código R 2.8. Por fim, para representarmos graficamente de forma cumulativa a apresentados dos dados, abordaremos as ogivas na próxima seção.\n\n\n\n\nCódigo R 2.8: Gráfico do polígono de frequências.\n\n\n# Anexando o pacote leem\nlibrary(leem)\n# Tabulando os dados\nchallenger |&gt;\n  new_leem(variable = 2) |&gt;\n  polyfreq(bars = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.3.5 Ogivas\nAs ogivas são a representação gráfica das frequências acumuladas. Para a frequência acumulada “abaixo de” (\\(f_{ac\\downarrow}\\)), temos a representação gráfica da ogiva crescente. Já para a frequência acumulada “*acima de”” (\\(f_{ac\\uparrow}\\)), temos a ogiva decrescente.\n\n2.3.5.1 Ogiva crescente\nPara a criação da ogiva crescente, faremos um gráfico auxiliar com o eixo \\(X\\) a representação das classes, e no eixo \\(Y\\) frequência acumulada “abaixo de” (\\(f_{ac\\downarrow}\\)), como temos na Figura 2.2.\nO gráfico de ogivas é representado por pontos e uma linha que os une, sendo um tipo de gráfico similar ao polígono de frequências. A diferença é que a alturas das barras representa a frequência acumulada ao invés da frequência absoluta. A outra diferença é que os pontos no gráficos têm como coordenadas o limite superior de cada classe e a sua respectiva \\(f_{ac\\downarrow}\\), exceto para o primeiro ponto que terá como coordenadas o limite inferior da primeira classe e o valor zero. Dessa forma, teremos a versão final do gráfico da ogiva crescente no Código R 2.9.\n\n\n\n\nCódigo R 2.9: Gráfico da ogiva crescente.\n\n\n# Anexando o pacote leem\nlibrary(leem)\n# Ogiva crescente\nchallenger |&gt;\n  new_leem(variable = 2) |&gt;\n  ogive(bars = TRUE)\n\n\n\n\n\n\n\n\n\n\nFigura 2.2: Representação inicial das barras acumuladas para a criação da ogiva crescente.\n\n\n\n\n\n\n\n2.3.5.2 Ogiva decrescente\nA ogiva decrescente é similar a construção da ogiva crescente, exceto que a primeira leva em consideração a frequência acumulada “acima de” (\\(f_{ac\\uparrow}\\)) e que os pontos do gráfico tem como abscissa o limite inferior de cada classe, exceto para o último ponto que sua abscissa é o limite superior da última classe. Como a base de desenvolvimento da ogiva decrescente é a frequência acumulada “acima de” (\\(f_{ac\\uparrow}\\)), os pontos têm como ordenadas estas frequências para cada classe. Para criarmos um gráfico desse tipo, usamos o Código R 2.10.\n\n\n\n\nCódigo R 2.10: Gráfico da ogiva decrescente.\n\n\n# Anexando o pacote leem\nlibrary(leem)\n# Ogiva descrescente\nchallenger |&gt;\n  new_leem(variable = 2) |&gt;\n  ogive(decreasing = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.3.5.3 Interseção entre as ogivas\nAlgo muito interessante surge quando plotamos as duas ogivas em um mesmo gráfico, Figura 2.3. Percebemos que existe um ponto em comum entre as duas curvas. A indagação que se segue é de saber a existência de como calcular o ponto de interseção entre essas duas curvas, denotado por \\(x^*\\). Vamos entender com maior profundidade mais a frente, quando estivermos falando nos próximos capítulos sobre variável aleatória e que sua caracterização e representada pelo seu modelo probabilístico. O modelo probabilístico pode ser representado pela função de distribuição, denotada por \\(F_X(x) = \\int^{x}_{-\\infty}f_X(t)dt\\) para todo \\(x \\in \\mathbb{R}\\), em que denotamos \\(f_X(x)\\) a função densidade de probabilidade de \\(X\\), sendo \\(X\\) um variável aleatória contínua2. A forma empírica da função de distribuição é justamente a frequência acumulada “abaixo de”, sendo que o objetivo da Função de distribuição é calcular área abaixo da função densidade até o ponto \\(x\\), cuja área total de \\(x \\to +\\infty\\) é o valor unitário. Empiricamente o que fazemos por meio da ogiva, que podemos denotá-la por \\(\\hat{F}_X(x)\\), é somar cumulativamente as frequências sendo uma aproximação da área desejada abaixo da densidade até o valor \\(x\\) desejado. Ao passo que a ogiva decrescente representa a forma empírica da função suporte da Função de distribuição, isto é, \\(1 - \\hat{F}_X(x)\\). É fato a equivalência de \\(\\hat{F}_X(x^*) = 1 - \\hat{F}_X(x^*)\\) sendo \\(x^*\\) o ponto de interseção entre a função de distribuição e a função suporte.\n\n\n\n\n\n\nFigura 2.3: Interseção entre as ogivas.\n\n\n\nUma outra informação que vamos entender no Capítulo 3 é que uma medida de posição muito interessante é a mediana, que representa um ponto cuja área abaixo e acima desse ponto da função densidade (ou função de probabilidade), representa \\(50\\%\\) de área.\nRetornando a indagação anterior, e observarmos novamente a Figura 2.3, percebemos que a abscissa desse ponto é o mesmo nas duas ogivas, isto é,\n\\[\n\\begin{align}\n\\hat{F}_X(x^*) = 1 - \\hat{F}_X(x^*),\n\\end{align}\n\\tag{2.15}\\] sendo que o primeiro termo antes da igualdade representa a abscisa da ogiva crescente, e o segundo termo, a abscissa da ogiva decrescente. Podemos observar que a expressão (2.15) pode ser simplificada por:\n\\[\\begin{align}\n\\hat{F}_X(x^*) = 1/2.\n\\end{align}\\]\nLogo, percebemos que o ponto \\(x^*\\) cuja área abaixo é \\(1/2\\) é justamente a mediana por definição, que pode ser confirmado no Código R 2.11.\n\n\n\n\nCódigo R 2.11: Ponto de interseção nas ogivas.\n\n\n# Anexando o pacote leem\nlibrary(leem)\n# Inserindo a mediana nas ogivas\nchallenger |&gt;\n  new_leem(variable = 2) |&gt;\n  ogive(both = TRUE, histogram = TRUE) |&gt;\n  insert(type = \"median\", lcol = \"red\",\n         ptext = 0.08, side = \"right\", \n         larrow = 0.4, parrow = .5)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Coleta, organização e apresentação dos dados</span>"
    ]
  },
  {
    "objectID": "cap02.html#exercícios-propostos",
    "href": "cap02.html#exercícios-propostos",
    "title": "2  Coleta, organização e apresentação dos dados",
    "section": "Exercícios propostos",
    "text": "Exercícios propostos\n\nExercício 2.1Observamos nas expressões (2.3) e (2.4), a forma de se calcular as frequências acumuladas acima de e abaixo de, quando indagamos questões que envolvem situações do tipo, quantas vezes observamos, no máximo, \\(X = x\\)? Para isso, usamos a expressão (2.3). Em outra situação, indagamos, quantas vezes observamos, no mínimo, \\(X = x\\)? Para isso, usamos a expressão (2.4). Percebemos que a condição limiar está inclusa na situação. Por exemplo, na Tabela 2.4, podemos estar interessados em saber quantos {grupos de caracteres monitorados} 3 em um canal de comunicação, foram encontrados, no mínimo, \\(2\\) erros? Isto significa, que desejamos saber todos os grupos, tais que \\(X \\geq 2\\). Ou seja, o grupo que continha dois erros estava incluso na contagem. Para isso, usamos a expressão (2.4). Porém, podemos estar interessados na situação em que a condição limiar não esteja inclusa na contagem de elementos. Por exemplo, refazendo a indagação anterior, quantos grupos de caracteres apresentam acima de \\(2\\) erros. Observe que os grupos apresentam dois erros não entram na contagem. Isso vale também para a outra situação. Logo, não será possível utilizar as expressões das frequências acumuladas (2.3) e (2.4).\nDesenvolva as expressões, para essas últimas situações, de modo similar ao apresentado para as expressões (2.3) e (2.4), fazendo as adaptações devidas.\n\n\n\nSoluçãoComo desejamos não incluir as condições limiares às indagações, podemos expressar as frequências acumuladas abaixo de e acima de como \\[\n\\begin{align}\n  F_{ac\\downarrow_i} & = \\sum_{j = 1}^{i - 1}F_j, \\quad i = 1, 2, \\ldots, k,\n\\end{align}\n\\tag{2.16}\\] e \\[\n\\begin{align}\n  F_{ac\\uparrow_i} & = \\sum_{j = i + 1}^{k}F_j, \\quad i = 1, 2, \\ldots, k,\n\\end{align}\n\\tag{2.17}\\] respectivamente, sendo \\(k\\) o número de grupos ou classes.\n\n\n\nExercício 2.2Os dados retirados de Tavares e Anjos (1999), representam a distribuição percentual do estado nutricional em homens idosos brasileiros (idade \\(\\geq\\) 60 anos), segundo Índice de Massa Corporal (IMC4), por macrorregião e situação de domicílio, Pesquisa Nacional sobre Saúde e Nutrição, 1989, que seguem abaixo. Como poderíamos, em notação usando as técnicas de somatório, representar a soma de todos os valores de IMC do Brasil, levando em consideração as demais variáveis? Se desejássemos, calcular o total dos valores observados de IMC dos homens do nordeste, considerando as demais condições? E se fosse do nordeste e da zona urbana, como representaríamos esse somatório?\n\n\n\n\n\n\nRegiões\n\n\nNúmero\n\n\nEstado Nutricional (%)\n\n\n\n\nM\n\n\nA\n\n\nSI\n\n\nSII e SIII\n\n\n\n\n\n\nNorte\n\n\n223\n\n\n4,4\n\n\n60,6\n\n\n29,4\n\n\n5,6\n\n\n\n\nNordeste\n\n\n586\n\n\n8,8\n\n\n68,3\n\n\n19,8\n\n\n3,1\n\n\n\n\nUrbano\n\n\n267\n\n\n7,1\n\n\n62,3\n\n\n26,6\n\n\n4,0\n\n\n\n\nRural\n\n\n319\n\n\n10,7\n\n\n74,6\n\n\n12,5\n\n\n2,2\n\n\n\n\nSudeste\n\n\n463\n\n\n7,9\n\n\n59,0\n\n\n26,7\n\n\n6,4\n\n\n\n\nUrbano\n\n\n197\n\n\n5,6\n\n\n56,4\n\n\n30,2\n\n\n7,8\n\n\n\n\nRural\n\n\n266\n\n\n17,3\n\n\n69,5\n\n\n12,4\n\n\n0,8\n\n\n\n\nSul\n\n\n429\n\n\n5,1\n\n\n56,5\n\n\n29,2\n\n\n9,2\n\n\n\n\nUrbano\n\n\n197\n\n\n4,5\n\n\n51,2\n\n\n33,0\n\n\n11,3\n\n\n\n\nRural\n\n\n232\n\n\n6,4\n\n\n66,4\n\n\n22,0\n\n\n5,2\n\n\n\n\nCentro-Oeste\n\n\n327\n\n\n10,7\n\n\n60,6\n\n\n22,8\n\n\n5,9\n\n\n\n\nUrbano\n\n\n154\n\n\n10,6\n\n\n55,2\n\n\n27,3\n\n\n6,9\n\n\n\n\nRural\n\n\n173\n\n\n11,0\n\n\n71,4\n\n\n13,7\n\n\n3,9\n\n\n\n\nBrasil\n\n\n2.028\n\n\n7,8\n\n\n61,8\n\n\n24,7\n\n\n5,7\n\n\n\n\nUrbano\n\n\n1.038\n\n\n6,0\n\n\n57,2\n\n\n29,5\n\n\n7,3\n\n\n\n\nRural\n\n\n990\n\n\n11,7\n\n\n71,7\n\n\n14,2\n\n\n2,4\n\n\n\n\n\nConsidere a variável estado nutricional como estudo, então como seria desenvolvido a distribuição de frequência baseado nas informações da tabela? Apresente-a(s).\n\n\n\nExercício 2.3Considerando os dados do Exercício 2.2, como poderíamos representá-los graficamente, considerando apenas um gráfico?\n\n\n\nSolução\nVamos representar esses dados por meio de um gráfico de barras, bem como o seu código em R, isto é,\n\n# Pacotes (Se nao tiver instalado, descomente a linha seguinte)\n# install.packages(\"ggplot2\")\n\n# Dados\ndado &lt;- read.table(\"dados/ex2.2.csv\", h = T, sep = \";\")\n\n# Anexando o pacote\nlibrary(ggplot2)\n\n# Gerando o grafico\nggplot(dado) +\n aes(x = estnut, fill = zona, weight = feq) +\n geom_bar() +\n scale_fill_hue() +\n labs(x = \"Estado Nutricional\", y = \"Frequência\", fill = \"Zona\") +\n coord_flip() +\n theme_bw() +\n facet_grid(vars(), vars(regiao))\n\n\n\n\n\n\n\n\n\n\n\nExercício 2.4\nDados retirados de Montgomery e Runger (2016), mostram os dados retirados planta de fabricação de semicondutores. Nessa planta, o semicondutor é um fio colado a uma estrutura. A variável em estudo representa a resistência à tração (\\(lbf/pol^2\\)), isto é, uma força requerida para romper a cola. Os dados são apresentados a seguir.\n\n\n\n9,95\n24,45\n31,75\n35,00\n25,02\n\n\n16,86\n14,38\n9,60\n24,35\n27,50\n\n\n17,08\n37,00\n41,95\n11,66\n21,65\n\n\n17,89\n69,00\n10,30\n34,93\n46,59\n\n\n44,88\n54,12\n56,63\n22,13\n21,15\n\n\n\n\n\n\n\n\n\nFERREIRA, D. F. Estatística Básica. 2 Revisada ed. Lavras: Editora UFLA, 2009. p. 664\n\n\nMONTGOMERY, D. C.; RUNGER, G. C. Estatística Aplicada e Probabilidade para Engenheiros. 6. ed. Rio de Janeiro: LTC, 2016. p. 629\n\n\nPRESIDENTIAL COMISSION. On the Space Shuttle Challanger Accident. Washington: National Aeronautics; Space Administration, 1986.\n\n\nTAVARES, E. L.; ANJOS, L. A. DO. Perfil antropométrico da população idosa brasileira. Resultados da Pesquisa Nacional sobre saúde e Nutrição. Cad. Saúde Pública, v. 15, n. 4, p. 759–768, 1999.\n\n\nWICKHAM, H. ggplot2: Elegant graphics for data analysis. 2. ed. New York: Springer International Publishing, 2016. p. 260",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Coleta, organização e apresentação dos dados</span>"
    ]
  },
  {
    "objectID": "cap02.html#footnotes",
    "href": "cap02.html#footnotes",
    "title": "2  Coleta, organização e apresentação dos dados",
    "section": "",
    "text": "Caso ainda não tenha instalado o pacote leem, deve ser executado o Código R 2.1.↩︎\nSe observarmos esse mesmo raciocínio em termos de variável aleatória discreta, a ideia é a mesma, exceto que a função de distribuição será baseada em termos de somatório ao invés de ser expressada em termos de integração.↩︎\nEntenda nessa situação que grupo de caracteres é um elemento da amostra.↩︎\nA unidade de IMC em \\(kg/m^2\\).↩︎",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Coleta, organização e apresentação dos dados</span>"
    ]
  },
  {
    "objectID": "cap03.html",
    "href": "cap03.html",
    "title": "3  Medidas de Posição",
    "section": "",
    "text": "3.1 Introdução\nApós tabularmos os dados ou apresentarmos graficamente, percebemos que ainda assim a quantidade de informações pode ser muito grande para descrevê-los. Desse modo, surgem algumas medidas que podem resumir tudo isso, de modo a preservar as principais características contidas nessas observações, são as denominadas medidas de posição ou tendência central, e as medidas de dispersão ou de variabilidade, que tem a propriedade de localizar a distribuição dos dados e também caracterizar sua variabilidade, respectivamente. Nesse capítulo trataremos das medidas de posição, e no Capítulo 4, as medidas de dispersão.\nAs medidas de posição representam o ponto central da massa de dados, de modo que o seu valor indica que as observações estão em torno dele, mas que não necessariamente, o valor dessa medida central exista no conjunto de dados. A escolha das medidas de posição apresentadas, dependerá da natureza das variáveis, bem como algumas peculiaridades existentes nos dados, como por exemplo, a existência de dados discrepantes. Vamos apresentar na sequência, a primeira medida de tendência central e a mais conhecida e utilizada na estatística, a média aritmética.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Medidas de Posição</span>"
    ]
  },
  {
    "objectID": "cap03.html#média-aritmética",
    "href": "cap03.html#média-aritmética",
    "title": "3  Medidas de Posição",
    "section": "3.2 Média aritmética",
    "text": "3.2 Média aritmética\nQuando iniciamos uma conversa e percebemos que alguém está no meio termo em um determinado posicionamento, dizemos que a pessoa está fazendo “média”, vulgarmente, dizemos que está em cima do muro. Nesse mesmo raciocínio, é a média aritmética, uma medida em que o seu valor representa o valor central das observações. Podemos comparar a média como um ponto de equilíbrio em um sistema de pesos, do qual se cada observação pode ser representada com uma certa massa no ponto no eixo X de um plano cartesiano, então o ponto que representa a média equilibrará esse sistema de pesos. Definimos,\n\nDefinição 3.1: Média aritméticaSeja uma amostra \\(X_1\\), \\(X_2\\), , \\(X_n\\), de uma população \\(X_1\\), \\(X_2\\), \\(\\ldots\\), \\(X_N\\), de tamanhos \\(n\\) e \\(N\\), respectivamente, definimos a média aritmética por: \\[\n\\begin{align}\n\\mu & = \\frac{\\displaystyle\\sum_{i=1}^{N}X_i}{N}, \\quad \\textrm{(População)}\n\\end{align}\n\\tag{3.1}\\] e \\[\n\\begin{align}\n\\bar{X} = \\frac{\\displaystyle\\sum_{i=1}^{n}X_i}{n}. \\quad \\textrm{(Amostra)}\n\\end{align}\n\\tag{3.2}\\]\n\n\nEm notação, dizemos que \\(\\mu\\) é uma característica amostral, isto é, representa a média populacional e chamamos de parâmetro. Na prática, essa informação é desconhecida e a representamos por uma medida amostral, que chamamos de estimador, uma função que depende apenas dos dados amostrais. Um estimador para \\(\\mu\\) representa a média aritmética \\(\\bar{X}\\). O valor observado de \\(\\bar{X}\\) pode ser representado por \\(\\bar{x}\\), em termos de notação. Vejamos um exemplo a seguir.\n\nExemplo 3.1Considerando os dados da Tabela 2.1, podemos calcular a média amostral da seguinte forma:\n\\[\\begin{align*}\n  \\bar{X} =  \\frac{3 + 1 + \\ldots + 1}{20}=\\frac{34}{20}= 1,7~\\textrm{erros}.\n\\end{align*}\\]\nPortanto, o número de erros encontrados em um conjunto de caracteres, podem ser representados por uma única medida, que é a média amostral. A interpretação é que, em média, ocorreram \\(1,7\\) erros nos caracteres monitorados em um meio de comunicação, e significa, que os 20 conjuntos de caracteres apresentam um número de erros em torno desse valor.\n\n\nA Definição 3.1 é utilizada para dados sem agrupamento, isto é, dados brutos ou dados elaborados. Para o caso de dados agrupados em distribuição de frequência, definimos,\n\nDefinição 3.2: Média aritmética em dados agrupadosSeja uma amostra \\(X_1\\), \\(X_2\\), \\(\\ldots\\), \\(X_n\\), de tamanho \\(n\\), agrupados em \\(k\\) grupos com variáveis \\(X_i\\) e frequência \\(F_i\\), ou \\(k\\) classes com pontos médios \\(\\tilde{X}_i\\) e \\(F_i\\) frequências, para \\(i\\) \\(=\\) \\(1\\), \\(2\\), \\(\\ldots\\), \\(k\\) e \\(\\sum_{i = 1}^{k}F_i = n\\), então a média aritmética de uma amostra, é definida por: \\[\n\\begin{align}\n\\bar{X} & = \\left\\{\\begin{array}{ll}\n                   \\frac{\\sum_{i = 1}^{k}X_i \\times F_i}{\\sum_{i = 1}^{k}F_i}, &  \\textrm{agrupados sem intervalo de classe}, \\\\\n                   &\\\\\n                   \\frac{\\sum_{i = 1}^{k}\\tilde{X}_i \\times F_i}{\\sum_{i = 1}^{k}F_i}, &  \\textrm{agrupados com intervalo de classe},\\\\\n                 \\end{array}\\right.\n\\end{align}\n\\tag{3.3}\\] sendo \\(\\tilde{X}_{i}\\) o ponto médio das classes.\n\n\nPodemos representar a Definição 3.2 em termos populacionais, substituindo o tamanho \\(n\\) por \\(N\\), como também representar a expressão em termos de valor observado. Porém, para simplificarmos a notação, preferimos usar dessa forma. Vejamos mais um exemplo a seguir.\n\nExemplo 3.2\\[\\begin{align*}\n  \\bar{X} = \\frac{0 \\times 3 + 1 \\times 7 + \\ldots + 4 \\times 1}{20}=\\frac{34}{20}=1,7~\\textrm{erros}.\n\\end{align*}\\] Notamos que o resultado para a média amostral é o mesmo obtido no Exemplo 3.1, porque mesmo agrupando os dados, o cálculo da média para esse tipo de dado, se baseia nos próprios valores observados.\n\n\nPorém, para o caso da variáveis quantitativas contínuas isso não ocorre, porque usamos o ponto médio para representar as observações de cada classe. Vejamos o próximo exemplo, a seguir.\n\nExemplo 3.3Consideremos agora os dados agrupados do Exemplo 2.1. Temos uma variável quantitativa contínua e, portanto, a média é baseada de acordo com a expressão (3.3), para o caso de dados agrupados com intervalo de classe, que segue: \\[\n\\begin{align*}\n\\bar{X} & =\\displaystyle\\sum_{i=1}^{k}\\frac{\\tilde{X}_iF_i}{\\sum_{i=1}^{k}F_i}\\\\\n&= \\frac{31 \\times 1 + 41,60 \\times 2 + \\ldots + 84,00 \\times 5}{1+2+\\ldots+5}\\\\\n& = 66,04\\textrm{ºF}.\n\\end{align*}  \n\\tag{3.4}\\]\nSe calculássemos a média sem agrupamento, o valor seria \\(\\bar{X} = 65,86\\)ºF. Observamos uma perda de precisão com os dados quando agrupados com intervalo de classe. Mas isso pode ser justificado por exemplo, se nesse experimento a diferença em \\(0,18\\)ºF não altera os resultados da pesquisa, e assim, podemos apresentar os dados de forma mais organizada.\n\n\nNos exemplos anteriores, observamos que a média leva em consideração a todas as observações, em seu cálculo. Apesar dessa ideia ser interessante, uma vez que conseguimos captar as informações de cada elemento da amostra ou população, qualquer alteração que houver em alguma observação, pode alterar completamente o resultado da média aritmética. É caso dos dados discrepantes, isto é, observações muito distante da grande parte dos dados. Isso pode ocorrer por diversas situações, como erro humano, ao digitar errado em uma planilha, elementos mal amostrados, de modo que, determinado elemento selecionado para a amostra não pertencia a população de interesse, ou até mesmo, uma condição atípica na realização da coleta dos dados. Vejamos mais algumas características da média aritmética:\n\na unidade da média está na mesma escala da variável em estudo;\na média é uma das medidas mais conhecidas e utilizadas, devido as suas propriedades estatísticas que serão vistas nos capítulos seguintes;\né única para cada conjunto de dados;\nusada apenas para variáveis quantitativas;\nnão pode ser calculada para dados agrupados que apresentam classes extremas abertas;\né influenciada por dados discrepantes.\n\nUma saída para contornar o problema dos dados discrepantes, pode ser abordado no exemplo a seguir.\n\nExemplo 3.4Considere um conjunto de dados (\\(n=17\\)) fictícios que apresentam a maior e a menor observação como suspeitos de serem atípicos quanto as suas ocorrências: \\[1, 5, 5, 6, 7, 7, 7, 8, 8, 8, 8, 8, 9, 9, 10, 10, 40\\]\nPara representar esse conjunto de dados, usamos a média aritmética para representá-los:\n\\[\\begin{align*}\n  \\bar{X} & = \\frac{1 + 5 + \\ldots + 40}{17} = 9,67~und.\n\\end{align*}\\]\nObservamos que as observações \\(x_1 = 1~unid.\\) e \\(x_{17} = 40~und.\\) podem ter influenciado o resultado, e como suspeitamos desses valores, vamos usar uma medida mais robusta a essa violação, isto é, que não será influenciado por esses valores. Chamamos de média aparada, denotada por \\(\\bar{X}_{ap}\\), que para uma amostra de tamanho \\(n\\), temos: \\[\n\\begin{align}\n  \\bar{X}_{ap} & = \\displaystyle\\frac{\\sum_{i = 2}^{n - 1}X_{(i)}}{n - 2},\n\\end{align}\n\\tag{3.5}\\] em que \\(X_{(i)}\\) é a \\((i)\\)-ésima variável em ordem crescente de magnitude, tal que \\(X_{(1)} = \\min\\limits_{i}X_i\\) e \\(X_{(n)} = \\max\\limits_{i}X_i\\).\nUsando a expressão (3.5), apresentamos a média aparada: \\[\n\\bar{X}_{ap}=\\frac{5 + 5 + \\ldots + 10}{15} = 7,65~unid.\n\\]\nObservamos pelo resultado, que os valores extremos acabam não influenciando no resultado da média aparada, e portanto, pode ser uma alternativa de medida de posição, para representar o conjunto de dados.\n\n\nComplementando as características da média, apresentamos algumas propriedades pelo Teorema 3.1 a seguir, do qual iremos usar a Definição 3.1 como base, e as demais seguem de forma similar.\n\nTeorema 3.1: Propriedades da Média aritmética\nBaseado na Definição 3.1, e considerando \\(c\\) uma constante, então:\n\nSe para uma amostra \\(X_1\\), \\(X_2\\), , \\(X_n\\), a média aritmética é dada por \\(\\bar{X} = \\frac{\\sum_{i=1}^{n}X_i}{n}\\), então para uma transformação de \\(Y_i = X_i \\pm c\\), para \\(i\\) \\(=\\) \\(1\\), \\(2\\), \\(\\ldots\\), \\(n\\), a nova média aritmética é dada por \\(\\bar{Y} = \\bar{X} \\pm c\\);\nSe para uma amostra \\(X_1\\), \\(X_2\\), , \\(X_n\\), a média aritmética é dada por \\(\\bar{X} = \\frac{\\sum_{i=1}^{n}X_i}{n}\\), então para uma transformação de \\(Y_i = X_i \\times c\\), para \\(i\\) \\(=\\) \\(1\\), \\(2\\), \\(\\ldots\\), \\(n\\), a nova média aritmética é dada por \\(\\bar{Y} = \\bar{X} \\times c\\). Esse resultado vale também para a transformação \\(Y_i = X_i / m\\), sendo \\(m\\) também uma constante. Basta usar \\(c = 1 / m\\) e o resultado é o mesmo.\nA soma de quadrado de desvios dos dados em relação a uma constante \\(c\\), é minimizada se \\(c = \\bar{X}\\).\n\n\n\n\nProva\n\nConsiderando uma amostra \\(X_1\\), \\(X_2\\), , \\(X_n\\), e \\(c\\) uma constante, e que \\(Y_i = X_i \\pm c\\), para \\(i\\) \\(=\\) \\(1\\), \\(2\\), \\(\\ldots\\), \\(n\\), então a média aritmética de \\(Y_i\\) é dado por: \\[\\begin{align*}\n\\bar{Y} & = \\frac{\\sum_{i=1}^{n}Y_i}{n}\\\\\n         & = \\frac{\\sum_{i=1}^{n}X_i \\pm c}{n}\\\\\n         & = \\frac{\\sum_{i=1}^{n}X_i}{n} \\pm \\frac{\\sum_{i=1}^{n} c}{n}\\\\\n         & = \\frac{\\sum_{i=1}^{n}X_i}{n} \\pm \\frac{n \\times c}{n}\\\\\n         & = \\bar{X} \\pm c. \\quad \\textrm{c.q.d.}\n  \\end{align*}\\]\nConsiderando uma amostra \\(X_1\\), \\(X_2\\), , \\(X_n\\), e \\(c\\) uma constante, e que \\(Y_i = X_i \\times c\\), para \\(i\\) \\(=\\) \\(1\\), \\(2\\), \\(\\ldots\\), \\(n\\), então a amplitude de \\(Y_i\\) é dado por: \\[\\begin{align*}\n\\bar{Y} & = \\frac{\\sum_{i=1}^{n}Y_i}{n}\\\\\n        & = \\frac{\\sum_{i=1}^{n}X_i \\times c}{n}\\\\\n        & = \\frac{X_1 \\times c + X_2 \\times c + \\ldots + X_n \\times c}{n} \\\\\n        & = c \\times \\frac{X_1 + X_2 + \\ldots + X_n }{n} \\\\\n        & = c \\times \\bar{X}. \\quad \\textrm{c.q.d.}\n  \\end{align*}\\]\nFazendo:\n\n\\[\nD=\\sum\\limits_{i=1}^{n}(X_i-c)^2.\n\\] Expandindo o somatório e derivando \\(D\\) em relação a “c”, temos que\n\\[\\begin{align*}\n  D & =\\sum\\limits_{i=1}^{n}(X_i-c)^2=\\sum\\limits_{i=1}^{n}(X_i^2-2cX_i+c^2)\\\\\n    & =\\sum\\limits_{i=1}^{n}X_i^2-\\sum\\limits_{i=1}^{n}2cX_i+\\sum\\limits_{i=1}^{n}c^2,\n\\end{align*}\\] e que \\[\n\\frac{dD}{dc}=-2\\sum\\limits_{i=1}^{n}X_i+2nc.\n\\]\nIgualando a derivada a zero, e resolvendo em \\(A\\), temos: \\[\n\\frac{dD}{dc}=-2\\sum\\limits_{i=1}^{n}X_i+2nc=0,\n\\] \\[\n2nc=2\\sum\\limits_{i=1}^{n}X_i,\n\\] \\[\nc=\\frac{\\sum\\limits_{i=1}^{n}X_i}{n} = \\bar{X}.\n\\] Certificando se o ponto é de máximo ou de mínimo, \\[\n\\frac{d^2D}{d^2c}=2n&gt;0.\n\\] Como a segunda derivada é maior que zero, fica provado que o ponto é de mínimo.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Medidas de Posição</span>"
    ]
  },
  {
    "objectID": "cap03.html#mediana",
    "href": "cap03.html#mediana",
    "title": "3  Medidas de Posição",
    "section": "3.3 Mediana",
    "text": "3.3 Mediana\nUma outra alternativa para contornarmos os problemas de dados discrepantes encontrados na média aritmética, pode ser apresentada por meio da medida de posição chamada de mediana, do qual leva em consideração a posição ordenada dos dados ao invés de usar or próprios valores observados. Mas especificamente, o valor da mediana é o ponto central dos dados, em que abaixo desse valor, representa as 50% menores observação, ao passo que, os valores acima da mediana representam as 50% maiores observações. De outro modo, dizemos que a mediana representa um ponto central no conjunto de dados em que a quantidade de elementos abaixo ou acima desse valor, não supera 50%. Essa última definição representa melhor o que significa a mediana, pois podemos ter valores centrais repetidos, e dessa forma isso ocorrendo, a primeira afirmação não será válida para a definição da mediana. Formalmente, definimos,\n\nDefinição 3.3Seja uma amostra \\(X_1\\), \\(X_2\\), \\(\\ldots\\), \\(X_n\\), de uma população \\(X_1\\), \\(X_2\\), \\(\\ldots\\), \\(X_N\\), de tamanhos \\(n\\) e \\(N\\), respectivamente, definimos a mediana por: \\[\n\\begin{align}\n    \\mu_d(X) & = \\left\\{\\begin{array}{ll}\n      \\frac{X_{(\\frac{N}{2})} + X_{\\left( \\frac{N}{2} + 1\n          \\right)}}{2}, & \\textrm{se } N  \\textrm{ for par} \\\\\n          & \\\\\n      X_{(\\frac{N + 1}{2})}, & \\textrm{se } N  \\textrm{ for ímpar} \\\\\n    \\end{array}\\right., \\quad \\textrm{(População)}\n\\end{align}\n\\tag{3.6}\\] sendo \\(\\mu_d(X)\\) a mediana populacional e que \\(X_{(i)}\\) é a \\((i)\\)-ésima variável em ordem crescente de magnitude, tal que \\(X_{(1)} = \\min\\limits_{i}X_i\\) e \\(X_{(n)} = \\max\\limits_{i}X_i\\). De modo similar, \\[\n\\begin{align}\n    Md(X) & = \\left\\{\\begin{array}{ll}\n      \\frac{X_{(\\frac{n}{2})} + X_{\\left( \\frac{n}{2} + 1\n          \\right)}}{2}, & \\textrm{se } n  \\textrm{ for par} \\\\\n          & \\\\\n      X_{(\\frac{n + 1}{2})}, & \\textrm{se } n  \\textrm{ for ímpar} \\\\\n    \\end{array}\\right., \\quad \\textrm{(Amostra)}\n\\end{align}\n\\tag{3.7}\\] sendo \\(Md(X)\\) a mediana amostral e que \\(X_{(i)}\\) é a \\((i)\\)-ésima variável em ordem crescente de magnitude, tal que \\(X_{(1)} = \\min\\limits_{i}X_i\\) e \\(X_{(n)} = \\max\\limits_{i}X_i\\).\n\n\nA mediana amostral é o melhor estimador para a mediana populacional, e pode ser considerado também como um estimador para a média populacional (\\(\\mu\\)). Detalhes sobre a escolha de um melhor estimador para um determinado parâmetro, será estudado no Capítulo 9. Como a mediana leva em consideração a posição das observações, a condição do tamanho amostral ou populacional acaba sendo importante para essa medida, de modo que, se o tamanho for um número par ou ímpar, teremos condições diferentes para o cálculo. Uma outra informação importante para o cálculo da mediana, é que será necessário ordenar as observações de modo crescente. Em notação para o caso de uma amostra de tamanho \\(n\\), dizemos que \\(X_{(1)}\\), \\(X_{(2)}\\), \\(\\ldots\\), \\(X_{(n)}\\) representa uma amostra em ordem crescente de magnitude, isto é, \\(X_{(1)} = \\min_{i}X_i\\) e \\(X_{(n)} = \\max_{i}X_i\\), e precisaremos desse ordenamento para obter o valor da mediana, baseados na expressões da Definição 3.3. Se utilizarmos o Exemplo 3.4, perceberemos que não é necessário eliminar as observações extremas em ordem de magnitude, como foi realizado com a média aparada. Isso demonstra que a mediana é uma outra alternativa de medida robusta para a escolha de uma medida de posição de modo a representar um conjunto de dados. Vejamos o exemplo a seguir.\n\nExemplo 3.5Considerando o Exemplo 3.4, como \\(n = 17\\) é ímpar, a mediana amostral desse conjunto de dados fictícios é dado por: \\[\\begin{align*}\n      Md(X) & = X_{(\\frac{17 + 1}{2})} = X_{(9)} = 8~unid.\n    \\end{align*}\\] Esse valor representa uma medida central do qual os 50% menores valores dos dados estão abaixo de \\(8~unid.\\), e que os 50% maiores valores dos dados estão acima de \\(8~unid.\\). Porém, percebemos que os valores \\(x_{(1)} = 1\\) e \\(x_{(17)} = 40\\) não influenciaram nesse resultado. Isso mostra, a robustez da mediana quanto a esse aspecto.\n\n\nPara o caso de variáveis quantitativas contínuas sem agrupamento, o procedimento é o mesmo realizado no Exemplo 3.4. Para os dados da Tabela 2.3, isto é, dados agrupados sem intervalo de classe (variáveis quantitativas discretas), podemos calcular a mediana usando a Definição 3.3. Precisaremos apenas complementar as informações com o acréscimo da frequência acumulada abaixo de (\\(f_{ac\\downarrow_i}\\)), que foi apresentada na Tabela 2.6. Vejamos o próximo exemplo.\n\nDefinição 3.4Vejamos os dados do número de erros de caracteres em 20 conjuntos, descritos na Tabela 2.6, em que simplificamos os resultados, que segue:\n\n\n\n\n\n\n\n\nNúmero de erros \\(\\mathbf{(X_i)}\\)\n\\(\\mathbf{F_i}\\)\nFrequência acumulada (\\(\\mathbf{F_{ac\\downarrow_i}}\\))\n\n\n\n\n\\(0\\)\n\\(3\\)\n\\(3\\)\n\n\n\\(1\\)\n\\(7\\)\n\\(10\\)\n\n\n\\(2\\)\n\\(4\\)\n\\(14\\)\n\n\n\\(3\\)\n\\(5\\)\n\\(19\\)\n\n\n\\(4\\)\n\\(1\\)\n\\(20\\)\n\n\nTotal\n\\(20\\)\n-\n\n\n\nO valor da mediana será dado da seguinte forma: \\[\\begin{align*}\n    Md(X) & = \\frac{X_{(\\frac{20}{2})} + X_{\\left( \\frac{20}{2} + 1\n          \\right)}}{2}\\\\\n          & = \\frac{X_{(10)} + X_{(11)}}{2}.\n\\end{align*}\\] Para sabermos qual o valor observado para a variável \\(X_{(10)}\\) e \\(X_{(11)}\\), marcamos os grupos 2 (linhas 2 de vermelho) e 3 (linha 3 de amarelo). No grupo 2, temos sete elementos que correspondem as variáveis \\(X_{(4)}\\), \\(X_{(5)}\\), \\(\\ldots\\), \\(X_{(10)}\\), uma vez que os três menores valores estão no grupo 1. Assim o \\(X_{(10)} = 1\\) erros. No grupo 3, nós temos quatro elementos que correspondem as variáveis \\(X_{(11)}\\), \\(X_{(12)}\\), \\(\\ldots\\), \\(X_{(14)}\\), uma vez que abaixo desse grupo nós temos as dez primeiras observações. Assim, o \\(X_{(11)} = 2\\) erros. Usamos as frequências simples (\\(F_i\\)) e acumulada \\(F_{ac\\downarrow_i}\\), para obter essas informações. Retornando ao cálculo da mediana, temos: \\[\\begin{align*}\n    Md(X) & = \\frac{X_{(10)} + X_{(11)}}{2}\\\\\n          & = \\frac{1 + 2}{2} = 1,5~\\textrm{erros}.\n  \\end{align*}\\] Caso os dados estivessem em rol, o resultado seria o mesmo.\n\n\nNo caso de dados agrupados com intervalo de classe (variáveis quantitativas contínuas), vamos definir um estimador para a mediana populacional, usando uma dedução geométrica por meio do histograma de frequências e as ogivas. Para isso, vamos usar os dados do Exemplo 2.1 para facilitar a explicação, em que apresentamos na Figura 3.1 o histograma e as ogivas desses dados agrupados.\n\n\n\n\n\n\nFigura 3.1: Histograma de frequência e ogivas para a dedução do cálculo da mediana.\n\n\n\nPara estimar a mediana a partir dos dados arranjados em uma tabela de distribuição de frequência com intervalo de classe, é necessário definir a classe mediana e em seguida encontrar a mediana interpolando os resultados. A posição da mediana é obtida acumulando-se frequências das classes 1, 2, etc., até se encontrar o valor que seja igual ou imediatamente superior a \\(n/2\\). Apresentamos algumas notações importantes para o entendimento da dedução do estimador de \\(\\mu_d(X)\\), que segue:\n\n\\(LI_{Md}\\): Limite inferior da classe da mediana;\n\\(LS_{Md}\\): Limite superior da classe da mediana;\n\\(f_{Md}\\): Frequência absoluta da classe da Mediana;\n\\(f_{ant}\\): Frequência acumulada (abaixo de) anterior à classe da Mediana;\n\\(f_{post}\\): Frequência acumulada (acima de) posterior à classe da Mediana;\n\\(c\\): Amplitude da classe da Mediana.\n\nCom essa notação apresentamos a Figura 3.2 para facilitar a compreensão da dedução. Iremos apresentar dois métodos, o primeiro baseado no limite inferior da classe da mediana, e o segundo baseado no limite superior da classe da mediana. Nesse tipo de natureza de dados, desprezaremos se o número de elementos é par ou ímpar. Entenderemos que a classe da mediana é aquela que contempla o valor observado para a variável \\(X_{(n / 2)}\\). Para isso, podemos observar esse valor na coluna da frequência acumulada (abaixo de), \\(f_{ac\\downarrow_i}\\). Nos dados do Exemplo 2.1, a classe da mediana é \\(57,5\\) \\(|\\)— \\(68,1\\) porque \\(f_{ac\\downarrow_4} = 19\\), isto é, abaixo de \\(68,1~\\textrm{ºF}\\) temos as primeiras \\(19\\) observações, e nessa classe contemplamos as observações ordenadas \\(x_{(8)}\\), \\(x_{(9)}\\), \\(\\ldots\\), \\(x_{(19)}\\), que contém \\(x_{(n / 2)} = x_{(36 / 2)} = x_{(19)}\\). Temos essas observações na classe 4 (classe da mediana), porque a frequência acumulada (abaixo de) anterior a classe da mediana, \\(f_{ac\\downarrow_3} = 7\\). Isso significa que a partir do oitavo elemento ordenado até o décimo nono temos elementos pertencentes a classe da mediana.\nFeito essas considerações, apresentamos o primeiro método de dedução da expressão da mediana, a seguir.\n\n\n\n\n\n\nFigura 3.2: Histograma de frequência e ogivas para a dedução do cálculo da mediana com as notações.\n\n\n\n1° Método\nUma vez que sabemos a classe da mediana, pela Figura 3.3 podemos determinar o valor da mediana por:\n\n\n\n\n\n\nFigura 3.3: Detalhamento do Histograma de frequência e ogivas para a dedução do cálculo da mediana com as notações.\n\n\n\n\\[\n\\begin{align}\n  Md(X) & = LI_{Md}+x,\n\\end{align}\n\\tag{3.8}\\]\nsendo necessário encontrar o valor \\(x\\). Assim, faremos uma regra de três simples pela semelhança de triângulos (triângulo verde e vermelho) que pode ser observado pela Figura 3.4.\n\n\n\n\n\n\nFigura 3.4: Semelhança de triângulos para a dedução do cálculo da mediana com as notações.\n\n\n\nAssim, temos\n\n\n\nVariação\n\nFrequência\n\n\n\n\n\\(c\\)\n\\(\\rightarrow\\)\n\\(f_{Md}\\)\n\n\n\\(x\\)\n\\(\\rightarrow\\)\n\\(n/2-f_{ant}\\).\n\n\n\nDeterminando \\(x\\), \\[\nx=\\left\\lbrace \\frac{\\frac{n}{2}-f_{ant}}{f_{Md}}\\right\\rbrace c.\n\\]\nComo \\(Md(X) = LI_{Md} + x\\), então \\[\n\\begin{equation}\nMd(X) = LI_{Md} + \\left\\lbrace \\frac{\\frac{n}{2}-f_{ant}}{f_{Md}}\\right\\rbrace \\times c.\n\\end{equation}\n\\tag{3.9}\\]\n2° Método\nUma vez que sabemos a classe da mediana, pela Figura 3.3 podemos determinar o valor da mediana pelo segundo método, sendo necessário encontrar o valor \\(y\\) na seguinte expressão (3.10). \\[\n\\begin{align}\n  Md(X) & = LS_{Md} - y.\n\\end{align}\n\\tag{3.10}\\]\nAssim, faremos uma regra de três simples usando a semelhança de triângulos (triângulo verde e amarelo). Assim,\n\n\n\nVariação\n\nFrequência\n\n\n\n\n\\(c\\)\n\\(\\rightarrow\\)\n\\(f_{Md}\\)\n\n\n\\(y\\)\n\\(\\rightarrow\\)\n\\(n/2-f_{post}\\)\n\n\n\nDeterminando \\(y\\), \\[\ny=\\left\\lbrace \\frac{\\frac{n}{2}-f_{post}}{f_{Md}}\\right\\rbrace c.\n\\] a mediana amostral pode ser expressa como\n\\[\\begin{equation}\nMd(X) = LS_{Md} - \\left\\lbrace \\frac{\\frac{n}{2}-f_{post}}{f_{Md}} \\right\\rbrace \\times c.\n\\end{equation}\\]\nFormalizando essas ideias, definimos um estimador da mediana amostral para dados agrupados com intervalo de classe da seguinte forma,\n\nDefinição 3.5: Mediana em dados agrupados com intervalo de classeSeja uma amostra \\(X_{(1)}\\), \\(X_{(2)}\\), \\(\\ldots\\), \\(X_{(n)}\\) em ordem crescente de magnitude, de tamanho \\(n\\), agrupados em \\(k\\) classes com pontos médios \\(\\tilde{X}_i\\) e \\(F_i\\) frequências, para \\(i\\) \\(=\\) \\(1\\), \\(2\\), \\(\\ldots\\), \\(k\\) e \\(\\sum_{i = 1}^{k}F_i = n\\), então a mediana amostral é definida por: \\[\n\\begin{align}\n    Md(X) = LI_{Md} + \\left\\lbrace \\frac{\\frac{n}{2}-f_{ant}}{f_{Md}}\\right\\rbrace \\times c.\n\\end{align}\n\\tag{3.11}\\] em que \\(LI_{Md}\\) é o limite inferior da classe da mediana, \\(f_{ant}\\) é a frequência acumulada (abaixo de) anterior a classe da mediana, \\(f_{Md}\\) frequência absoluta da classe da mediana, \\(c\\) a amplitude da classe da mediana, ou de forma similar, \\[\n\\begin{align}\n    Md(X) = LS_{Md} - \\left\\lbrace \\frac{\\frac{n}{2}-f_{post}}{f_{Md}} \\right\\rbrace \\times c.\n\\end{align}\n\\tag{3.12}\\] em que \\(LS_{Md}\\) é o limite superior da classe da mediana e \\(f_{post}\\) é a frequência acumulada (acima de) posterior a classe da mediana.\n\n\nVamos apresentar o resultado da mediana para os dados do Exemplo 2.1 a seguir.\n\nExemplo 3.6Retornando aos dados do Exemplo 2.1, vamos calcular a mediana pelos dois métodos, do qual temos o primeiro resultado, usando a expressão (3.11), \\[\\begin{align*}\n  Md(X) & = 57,5 + \\left\\{ \\frac{18 - 7}{12}\\right\\} \\times 10,6 = 67,22~\\textrm{ºF}.\n\\end{align*}\\] Usando o segundo método, expressão (3.12), temos, \\[\\begin{align*}\n  Md(X) & = 68,1 - \\left\\{ \\frac{18 - 17}{12}\\right\\} \\times 10,6 = 67,22~\\textrm{ºF}.\n\\end{align*}\\] Os resultados são equivalentes como era de se esperar.\n\n\nVejamos algumas características sobre a mediana, que seguem:\n\nA mediana não é influenciada por valores extremos;\nUma medida que pode ser obtida em distribuições de frequências que apresentam classe com limites indefinidos;\no resultado da mediana é obtida na mesma escala da variavel em estudo;\na mediana é menos informativa que a média, por não levar em consideração os valores observados, mas as posições dessas observações;\na mediana pode ser calculada em variáveis qualitativas ordinais, cuja média não pode ser obtida;\na mediana ainda pode ser obtida em um conjunto de dados em que alguns valores ainda não foram registrados, caso em que a média não pode ser obtida.\n\nPara complementarmos essas características, vamos apresentar algumas propriedades da mediana no Teorema 3.2. Iremos a Definição 3.3, bem como a expressão (3.7) para \\(n\\) ímpar. Para os demais casos, os resultados são similares.\n\nTeorema 3.2: Propriedades da mediana\nBaseado na Definição 3.3, e considerando \\(c\\) uma constante, então:\n\nSe para uma amostra \\(X_{(1)}\\), \\(X_{(2)}\\), \\(\\ldots\\), \\(X_{(n)}\\) em ordem crescente de magnitude, a mediana é dada por \\(Md{X} = X_{(\\frac{n + 1}{2})}\\), então para uma transformação de \\(Y_i = X_i \\pm c\\), para \\(i\\) \\(=\\) \\(1\\), \\(2\\), \\(\\ldots\\), \\(n\\), a mediana aritmética é dada por \\(Md(Y) = Md(X) \\pm c\\);\nSe para uma amostra \\(X_{(1)}\\), \\(X_{(2)}\\), \\(\\ldots\\), \\(X_{(n)}\\) em ordem crescente de magnitude, a mediana é dada por \\(Md(X) = X_{(\\frac{n + 1}{2})}\\), então para uma transformação de \\(Y_i = X_i \\pm c\\), para \\(i\\) \\(=\\) \\(1\\), \\(2\\), \\(\\ldots\\), \\(n\\), a nova mediana é dada por \\(Md(Y) = Md(X) \\times c\\). Esse resultado vale também para a transformação \\(Y_i = X_i / m\\), sendo \\(m\\) também uma constante. Basta usar \\(c = 1 / m\\) e o resultado é equivalente;\nA soma do módulo dos desvios dos dados em relação a uma constante arbitrária \\(c\\), terá um valor mínimo se \\(c=Md(X)\\).\n\n\n\n\nProva\n\nConsiderando uma amostra \\(X_1\\), \\(X_2\\), \\(\\ldots\\), \\(X_n\\), e \\(c\\) uma constante, e que \\(Y_i = X_i \\pm c\\), para \\(i\\) \\(=\\) \\(1\\), \\(2\\), \\(\\ldots\\), \\(n\\), então a mediana de \\(Y_i\\) é dado por: \\[\\begin{align*}\n   Md(Y) & =  Y_{(\\frac{n + 1}{2})}\\\\\n       & =  X_{(\\frac{n + 1}{2})} \\pm c\\\\\n       & = Md(X) \\pm c.\n\\end{align*}\\]\nConsiderando uma amostra \\(X_1\\), \\(X_2\\), \\(\\ldots\\), \\(X_n\\), e \\(c\\) uma constante, e que \\(Y_i = X_i \\times c\\), para \\(i\\) \\(=\\) \\(1\\), \\(2\\), \\(\\ldots\\), \\(n\\), então a mediana de \\(Y_i\\) é dado por: \\[\\begin{align*}\n  Md(Y) & =  Y_{(\\frac{n + 1}{2})}\\\\\n      & =  X_{(\\frac{n + 1}{2})} \\times c\\\\\n      & = Md(X) \\times c.\n\\end{align*}\\]\nConsiderando uma amostra \\(X_1\\), \\(X_2\\), \\(\\ldots\\), \\(X_n\\), e a soma do módulo dos desvios entre os dados e uma constante \\(c\\), por \\(h(c) = \\sum_{i = 1}^{n} |X_i - c|\\), tal que, \\[\\begin{align*}\n   h_i(c) = |X_i - c| & = \\left\\{\\begin{array}{ll}\n                                                  (X_i - c) & \\textrm{se } X_i &gt; c, \\\\\n                                                  -(X_i - c) & \\textrm{se } X_i &lt; c.\n                                                \\end{array}\\right.\n\\end{align*}\\] Para minimizar \\(h(c)\\) em relação a \\(c\\), temos que \\[\\begin{align*}\n   \\frac{dh_i(c)}{dc} & = - I_{\\{X_I &gt; A\\}}(x) + I_{\\{X_i &lt; c\\}}(x),\n\\end{align*}\\] que resulta em \\[\\begin{align*}\n   \\frac{dh(c)}{dc} & = \\sum_{i = 1}^{n}[I_{\\{X_i &lt; c\\}}(x) - I_{\\{X_I &gt; A\\}}(x)],\n\\end{align*}\\] em que \\(I(x)\\) representa a função indicadora. Logo, \\[\\begin{align*}\n   \\frac{dh_i(c)}{dc} & = 0,\n\\end{align*}\\] se \\[\\begin{align*}\n   \\sum_{i = 1}^{n}I_{\\{X_i &lt; c\\}}(x) & = \\sum_{i = 1}^{n}I_{\\{X_I &gt; A\\}}(x)\\\\\n   n_{-} & = n_{+}.\n\\end{align*}\\] De modo que a igualdade \\(n_{-} = n_{+}\\) só ocorrerá se \\(c\\) for igual a \\(Md(X)\\), pois a quantidade de valores menores a \\(c\\) é igual a quantidade de valores maiores que \\(c\\). Portanto, para \\(n = n_{-} + n_{+}\\) um número par, \\(c\\) deverá ser um valor entre \\(X_{(n / 2)}\\) e \\(X_{(\\frac{n + 2}{2})}\\), isto é, \\[\\begin{align*}\n   c = Md(X) & = \\frac{X_{(n / 2)} + X_{\\left(\\frac{n}{2} + 1\\right)}}{2},\n\\end{align*}\\] e se \\(n = n_{-} + n_{+}\\) for um número ímpar, \\[\\begin{align*}\n   c = Md(X) & = X_{\\left(\\frac{n + 1}{2}\\right)}.\n\\end{align*}\\]",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Medidas de Posição</span>"
    ]
  },
  {
    "objectID": "cap03.html#moda",
    "href": "cap03.html#moda",
    "title": "3  Medidas de Posição",
    "section": "3.4 Moda",
    "text": "3.4 Moda\nAs medidas de posição até agora apresentadas não foram aplicadas para as variáveis qualitativas de um modo geral, apenas a mediana para o caso de variável quantitativa ordinal. Contudo, podemos apresentar um medida mais simples, que seja possível ser aplicada para todas as naturezas de variáveis apresentadas, definida a seguir.\n\nExemplo 3.7: Moda para natureza de dados discretizadosSeja uma amostra \\(X_1\\), \\(X_2\\), \\(\\ldots\\), \\(X_n\\), de uma população \\(X_1\\), \\(X_2\\), , \\(X_N\\), de tamanhos \\(n\\) e \\(N\\), respectivamente, cuja natureza da variável é discretizada1. Então a moda representa o valor que mais se repete em um conjunto de dados. Denotamos \\(\\mu_o\\) a moda populacional, e \\(Mo(X)\\) a moda amostral.\n\n\nDessa forma, podemos perceber que um conjunto de dados poderá ter mais de uma moda, isto é, se observarmos dois valores mais frequentes e iguais, teremos uma distribuição bimodal, três valores mais frequentes iguais, teremos uma distribuição trimodal, mais de três, uma distribuição multimodal, ou até mesmo uma distribuição amodal, quando todos os valores se repetem apenas uma vez.\n\nExemplo 3.8Observando as variáveis da Tabela 1.2, percebemos que para a variável Região a moda é Norte. Já para UF e Número de cidades a distribuição é amodal.\n\n\nPara o caso das variáveis quantitativas contínuas, essa definição não se aplica, porque dificilmente dois valores serão iguais para esse tipo de variável. O que faz pensar que dois valores sejam iguais em uma variável quantitativa contínua é a limitação do instrumento de medida. Basta perceber que dois valores possivelmente iguais, se mensurados por outros instrumentos de medidas mais precisos, os valores serão diferentes à medida que o número de dígitos nas casas decimais aumentam. Assim, faz-se necessário pensarmos em uma definição para a moda como sendo o valor com alta densidade de observações em sua proximidade. Uma forma de determinarmos um estimador para \\(\\mu_o\\) em variáveis contínuas é por meio do histograma de frequências. Inicialmente, determinamos a classe de maior frequência para os dados agrupados com intervalo de classe, para determinarmos a moda. Se todas as classes apresentarem mesma frequência, não haverá moda. A classificação quanto a distribuição segue a mesma mencionada anteriormente, isto é, amodal, unimodal, bimodal, trimodal ou multimodal. A moda baseada no histograma de frequência é também chamada de moda de Czuber.\nA moda de Czuber pode ser facilmente obtida pela semelhança de triângulos ABC e DCE no esquema seguinte. A moda, se refere ao valor da abscissa correspondente ao vértice C comum aos dois triângulos. É fácil perceber que os segmentos de retas AB e DE correspondem aos valores \\(\\Delta_1\\) e \\(\\Delta_2\\).\nObservamos pela Figura 3.5, que o valor da moda é \\(Mo=LI_{Mo}+x\\), bastando determinar o valor \\(x\\) pela semelhança de triângulos, isto é, \\[\n\\frac{x}{c-x}=\\frac{\\Delta_1}{\\Delta_2}\\Rightarrow x=\\left\\lbrace \\frac{\\Delta_1}{\\Delta_1+\\Delta_2}\\right\\rbrace \\times  c.\n\\] Assim, a moda é determinada por: \\[\\begin{equation*}\nMo(X)=LI_{Mo}+\\left\\lbrace \\frac{\\Delta_1}{\\Delta_1+\\Delta_2}\\right\\rbrace \\times c,\n\\end{equation*}\\] sendo \\(LI_{Mo}\\) o limite inferior da classe da moda, \\(\\Delta_1 = f_{Mo} - f_{i_{ant}}\\), \\(\\Delta_2 = f_{Mo} - f_{i_{post}}\\), \\(f_{Mo}\\) é a frequência absoluta da classe da moda, \\(f_{i_{ant}}\\) frequência absoluta anterior à classe da moda, \\(f_{i_{post}}\\) frequência posterior à classe da moda, e \\(c\\) a amplitude da classe.\n\n\n\n\n\n\nFigura 3.5: Histograma de frequência para a dedução do cálculo da moda.\n\n\n\nKarl Pearson, observou a existência de uma relação empírica que permite calcular a moda quando são conhecidas a média (\\(\\overline{X}\\)) e a mediana (\\(Md\\)) de uma distribuição assimétrica. Essas condições satisfazem a relação empírica, \\[\n\\begin{equation}\nMo(X)=3Md(X)-2\\overline{X}.\n\\end{equation}\n\\tag{3.13}\\] Formalmente, definimos\n\nDefinição 3.6: Moda para dados agrupados com intervalo de classeSeja uma amostra \\(X_{(1)}\\), \\(X_{(2)}\\), \\(\\ldots\\), \\(X_{(n)}\\) em ordem crescente de magnitude, de tamanho \\(n\\), agrupados em \\(k\\) classes com pontos médios \\(\\tilde{X}_i\\) e \\(F_i\\) frequências, para \\(i\\) \\(=\\) \\(1\\), \\(2\\), \\(\\ldots\\), \\(k\\) e \\(\\sum_{i = 1}^{k}F_i = n\\), então a moda amostral é definida por: \\[\n\\begin{align}\nMo(X) & = LI_{Mo} + \\left\\lbrace \\frac{\\Delta_1}{\\Delta_1 + \\Delta_2}\\right \\rbrace \\times c,\n\\end{align}\n\\tag{3.14}\\] em que \\(LI_{Mo}\\) o limite inferior da classe da moda, \\(\\Delta_1 = f_{Mo} - f_{i_{ant}}\\), \\(\\Delta_2 = f_{Mo} - f_{i_{post}}\\), \\(f_{Mo}\\) é a frequência absoluta da classe da moda, \\(f_{i_{ant}}\\) frequência absoluta anterior à classe da moda, \\(f_{i_{post}}\\) frequência posterior à classe da moda, e \\(c\\) a amplitude da classe.\n\n\nVejamos algumas características sobre a moda, que seguem:\n\nA moda não é influenciada por valores extremos, desde que estes não pertençam a classe modal;\nUma medida que pode ser obtida em distribuições de frequências que apresentam classe com limites indefinidos;\no resultado da moda é obtida na mesma escala da variavel em estudo;\na moda é menos informativa que a média, por não levar em consideração os valores observados;\na moda pode ser calculada para todas as naturezas de variáveis;\na moda é a medida mais simples dentre as apresentadas;\n\n\nExemplo 3.9Observando a tabela de frequência dos dados de temperatura do anel de vedação do foguete Challenger no Exemplo 2.1, percebemos que há duas classes de maior frequência, porém classes vizinhas. Perceberemos pelo cálculo que na realidade haverá apenas uma moda nesse caso. Vejamos, o cálculo da moda para a classe 4, \\[\\begin{align*}\n  Mo(X) & = 57,5 + \\left\\lbrace\\frac{12 - 4}{(12 - 4) + (12 - 12)} \\right\\rbrace \\times 10,6 = 68,1~\\text{ºF}.\n\\end{align*}\\] Vejamos a moda para a classe 5, \\[\\begin{align*}\n  Mo(X) & = 67,1 + \\left\\lbrace\\frac{12 - 12}{(12 - 5) + (12 - 12)} \\right\\rbrace \\times 10,6 = 68,1~\\text{ºF}.\n\\end{align*}\\] O que poderia ser feito para que não gerasse confusão quanto a distribuição ser unimodal ou bimodal, era reagrupar os dados com um outro número de classes, abaixo ou acima do valor de \\(k\\) adotado.\n\n\nPara complementarmos essas características, vamos apresentar algumas propriedades da moda no Teorema 3.2. Iremos usar a Definição 3.7 como referência, porém, para os demais casos, os resultados são similares.\n\nTeorema 3.3: Propriedades da moda\nBaseado na Definição 3.7, e considerando \\(c\\) uma constante, então:\n\nSe para uma amostra \\(X_1\\), \\(X_2\\), \\(\\ldots\\), \\(X_n\\) em ordem crescente de magnitude, a moda representa o valor de maior frequência e representado por \\(Mo(X)\\), então para uma transformação de \\(Y_i = X_i \\pm c\\), para \\(i\\) \\(=\\) \\(1\\), \\(2\\), \\(\\ldots\\), \\(n\\), a moda é dada por \\(Mo(Y) = Mo(X) \\pm c\\);\nSe para uma amostra \\(X_1\\), \\(X_2\\), \\(\\ldots\\), \\(X_n\\) em ordem crescente de magnitude, a moda representa o valor de maior frequência e representado por \\(Mo(X)\\), então para uma transformação de \\(Y_i = X_i \\pm c\\), para \\(i\\) \\(=\\) \\(1\\), \\(2\\), \\(\\ldots\\), \\(n\\), a nova moda é dada por \\(Mo(Y) = Mo(X) \\times c\\). Esse resultado vale também para a transformação \\(Y_i = X_i / m\\), sendo \\(m\\) também uma constante. Basta usar \\(c = 1 / m\\) e o resultado é o mesmo.\n\n\n\n\nProva\n\nA soma ou subtração de uma constante (\\(c\\)) aos dados, altera a moda de tal forma que a nova moda fica adicionada ou subtraída pela constante.\n\nSeja \\[\nY_i=X_i\\pm c,\n\\] então \\[\nMo(Y)=Mo(X) \\pm c.\n\\]\n\nA multiplicação dos dados ou divisão por uma constante (\\(c\\)), altera a moda de tal forma que a nova moda fica complicada ou dividida pela constante.\n\nSejam \\[\nY_i=cX_i,\n\\] então \\[\nMo(Y)=cMo(X).\n\\]\n\n\nPor fim, apresentamos o Exemplo 2.1 de Magalhães e Lima (2015), para termos uma noção sobre essas três medidas de posição, a seguir.\n\nExemplo 3.10: Retirado de Magalhães e Lima (2015)Um estudante está procurando um estágio para o próximo ano. As companhias \\(A\\) e \\(B\\) têm programas de estágios e oferecem uma remuneração por 20 horas semanais com as seguintes características (em salários mínimos):\n\n\n\nCompanhia\nA\nB\n\n\n\n\nMédia\n2,5\n2,0\n\n\nMediana\n1,7\n1,9\n\n\nModa\n1,5\n1,9\n\n\n\nQual a companhia mais adequada? Inicialmente vamos discutir as informações fornecidas supondo que o estudante terá seu salário “escolhido” de acordo com uma política salarial cuja tabela acima é um resumo. A companhia \\(A\\) tem 50% dos seus estagiários recebendo até 1,7 salários mínimos e o valor com mais chance de ocorrência é 1,5. Como a média é 2,5 devem haver alguns poucos estagiários com salário bem mais alto. A companhia B tem as três medidas bem próximas indicando uma razoável simetria entre salários altos e baixos. A opção do estudante dependerá de sua qualificação. Se ele for bem qualificado, deve preferir a companhia A pois terá maior chance de obter um dos altos salários. se tiver qualificação próxima ou abaixo dos outros estudantes, deve preferir B que parece ter uma política mais homogênea de salários.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Medidas de Posição</span>"
    ]
  },
  {
    "objectID": "cap03.html#aplicações-com-o-pacote-leem",
    "href": "cap03.html#aplicações-com-o-pacote-leem",
    "title": "3  Medidas de Posição",
    "section": "3.5 Aplicações com o pacote leem",
    "text": "3.5 Aplicações com o pacote leem\nCom o pacote leem podemos utilizar todas os cálculos para as medidas de posição, tanto para dados agrupados quanto para dados não agrupados, sendo variável qualitativa ou quantitativa, e ainda inseri-los nos gráficos apresentados na Seção 2.3 do Capítulo 2. As funções para computar as medidas média, mediana e moda são: mean(), median() e mfreq(), respectivamente.\nPor questão didática, usaremos apenas os dados apresentados do Exemplo 2.1 a título de ilustração, no Código R 3.3, para computarmos as três medidas de posição abordadas neste capítulo.\n\n\n\n\nCódigo R 3.1: Medidas de posição para dados agrupados e não agrupados, bem como a representação gráfica no histograma.\n\n\n# Anexando o pacote leem\nlibrary(leem)\n# Importando o banco de dados\ncon &lt;- url(\"https://raw.githubusercontent.com/bendeivide/book-epaec/master/dados/cap02/challenger.RData\")\nload(con); close(con)\n# Medidas de posicao (dados agrupados)\nchallenger |&gt;\n  new_leem(variable = 2) |&gt; # var. quant. continua\n  mpos(grouped = TRUE) # Medidas de posicao\n\n\n\n\n$average\n[1] 66.04\n\n$median\n[1] 67.22\n\n$mode\n[1] 68.1 68.1\n\n\n\n\nCódigo R 3.2: Medidas de posição para dados agrupados e não agrupados, bem como a representação gráfica no histograma.\n\n\n# Medidas de posicao (dados nao agrupados)\nchallenger |&gt;\n  new_leem(variable = 2) |&gt; # var. quant. continua\n  mpos(grouped = FALSE) # Medidas de posicao\n\n\n\n\n$average\n[1] 65.86\n\n$median\n[1] 67.5\n\n$mode\n[1] 67 70\n\n\n\n\nCódigo R 3.3: Medidas de posição para dados agrupados e não agrupados, bem como a representação gráfica no histograma.\n\n\n# Insrindo as medidas no histograma\nchallenger |&gt;\n  new_leem(variable = 2) |&gt; # var. quant. continua\n  hist(barcol = heat.colors(5)) |&gt;\n  insert(type = \"all\", \n    lcol = c(\"black\", \"blue\", \"brown\"),\n    ptext = 0.08, larrow = 0.4)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Medidas de Posição</span>"
    ]
  },
  {
    "objectID": "cap03.html#exercícios-propostos",
    "href": "cap03.html#exercícios-propostos",
    "title": "3  Medidas de Posição",
    "section": "Exercícios propostos",
    "text": "Exercícios propostos\n\nExercício 3.1A tabela abaixo apresenta a distribuição de frequências das notas (em pontos) obtidas num teste de matemática, realizado por 50 estudantes.\n\n\n\nNotas\n\\(F_i\\)\n\n\n\n\n0 \\(|\\)— 2\n4\n\n\n2 \\(|\\)— 4\n12\n\n\n4 \\(|\\)— 6\n15\n\n\n6 \\(|\\)— 8\n13\n\n\n8 \\(|\\)— 10\n6\n\n\n\nApresente o cálculo para todas as medidas de posição estudadas e as interprete.\n\n\n\nSolução\nVamos inicialmente inserir na tabela de notas, a coluna dos pontos médios das classes, e a frequência acumulada abaixo de (\\(f_{ac\\downarrow_i}\\)), do qual segue:\n\n\n\nNotas\n\\(F_i\\)\n\\(\\tilde{X}_i\\)\n\\(F_{ac\\downarrow_i}\\)\n\n\n\n\n0 \\(|\\)— 2\n4\n1\n4\n\n\n2 \\(|\\)— 4\n12\n3\n16\n\n\n4 \\(|\\)— 6\n15\n5\n31\n\n\n6 \\(|\\)— 8\n13\n7\n44\n\n\n8 \\(|\\)— 10\n6\n9\n50\n\n\n\n\nMédia \\[\\begin{align*}\n  \\bar{X} & = \\frac{1 \\times 4 + 3 \\times 12 + \\ldots + 9 \\times 6}{50} = 5,2~\\textrm{pontos},\n\\end{align*}\\] em que a notas dos estudantes se distribuem em torno desse valor;\nMediana \\[\\begin{align*}\n  Md(X) & = 4 + \\frac{25 - 16}{15} \\times 2 = 5,2~\\textrm{pontos},\n\\end{align*}\\] em que a distribuição das notas dos estudantes abaixo e acima de \\(5,2\\) pontos, representam 50% dos dados;\nModa \\[\\begin{align*}\n  Mo(X) & = 4 + \\frac{3}{3 + 2} \\times 2 = 5,2~\\textrm{pontos},\n\\end{align*}\\] em que esta representa a nota de maior frequência.\n\n\n\n\nExercício 3.2Observando as expressões \\(\\sum_{i = 1}^{n}(X_i - \\bar{X})^2\\) e \\(\\sum_{i = 1}^{n}(X_i - \\mu)^2\\), em que \\(\\bar{X} = \\sum_{i = 1}^{n} X_i / n\\) e \\(\\mu = \\sum_{i = 1}^{N} X_i / N\\), representam a média amostral e a média populacional, respectivamente, qual das duas somas de quadrados representa o menor valor para soma?\n\n\n\nExercício 3.3Considere uma amostra \\(X_1\\), \\(X_2\\), \\(\\dots\\), \\(X_n\\) de tamanho \\(n\\), do qual conseguimos computar as medidas de posição \\(\\bar{X}\\), \\(Md(X)\\) e \\(Mo(X)\\), isto é, a média, mediana e moda, respectivamente, bem como a variância \\(S^2_X\\). Considere também as transformações \\(Y_i = X_i - \\bar{X}\\) e \\(Z_i = (X_i - \\bar{X}) / S\\), para \\(i\\) \\(=\\) \\(1\\), \\(2\\), \\(\\ldots\\), \\(n\\), sendo \\(S = \\sqrt{S^2}\\). Apresente as medidas de posição para essas transformações, \\(Y\\) e \\(Z\\).\n\n\n\nSolução\nPara as duas transformações \\(X\\) e \\(Y\\), dada uma amostra fixada, as medidas \\(\\bar{X}\\) e \\(S\\) podem ser consideradas como uma constante, pois elas não se alteram. Então, usando a propriedade (II) para os Teoremas 3.1, 3.2 e 3.3, temos que respectivamente, a média, a mediana e a moda de \\(Y\\), são iguais a 0. Usando esses mesmos teoremas para o cálculo da média, mediana e moda de \\(Z\\), precisamos redefinir essa variável como \\(Z_i = X_i/S + \\bar{X}/S\\). Assim, para \\(X_i/S\\) basta considerarmos que \\(X_i\\) está multiplicado por uma constante \\(k_1 = 1/ S\\) e daí usamos a propriedade (I) dos teoremas citados, acrescido de outra constante \\(k_2 = \\bar{X}/S\\), do qual usamos a propriedade (II) desses mesmos teoremas, logo, a média, média e moda serão também iguais a 0. Para que haja um entendimento mais claro, faremos a prova apenas para a média nas duas transformações, e para as demais medidas, deixaremos como exercício para os leitores.\n\nMédia de \\(Y\\) \\[\\begin{align*}\n  \\bar{Y} & = \\sum_{i = 1}^{n}\\frac{Y_i}{n}\\\\\n          & = \\sum_{i = 1}^{n}\\frac{X_i - \\bar{X}}{n}\\\\\n          & = \\sum_{i = 1}^{n}\\frac{X_i}{n} - \\bar{X}\\\\\n          & = \\bar{X} - \\bar{X} = 0;\n\\end{align*}\\]\nMédia de \\(Z\\) \\[\\begin{align*}\n  \\bar{Z} & = \\sum_{i = 1}^{n}\\frac{Z_i}{n}\\\\\n          & = \\sum_{i = 1}^{n}\\frac{X_i\\times k_1 - k_2}{n}\\\\\n          & = \\sum_{i = 1}^{n}\\frac{X_i \\times k_1}{n} - k_2\\\\\n          & = k_1\\sum_{i = 1}^{n}\\frac{X_i}{n} - k_2\\\\\n          & = k_1\\times \\bar{X} - k_2\\\\\n          & = \\bar{X}/S - \\bar{X}/S, \\quad k_1 = 1/S~\\textrm{ e } k_2 = \\bar{X}/S\\\\\n          & = 0.\n\\end{align*}\\]\n\n\n\n\nExercício 3.4Uma empresa de telecomunicações concedeu 10% de aumento de salário a todos os seus funcionários. A média salarial foi de 1.500 reais antes do reajuste. Qual será a nova média salarial após o reajuste?\n\n\n\nExercício 3.5Uma prova de estatística foi aplicada com pontuação de 0 a 10 pontos, sendo que a média das notas de todos os alunos de uma turma foi de 5,8 pontos. Se a média das mulheres é 6,3 pontos e a dos rapazes é 4,3 pontos, então qual a porcentagem de mulheres na turma?\n\n\n\nSoluçãoConsidere que a nota dos alunos podem ser representados pela variável \\(X_i\\), com \\(i = 1, 2, \\ldots, n\\), em que \\(n\\) representa o número de alunos que fizeram a prova. Considere ainda o índice \\(H\\) na variável \\({X_H}_j\\), representa o aluno \\(j\\) do sexo masculino que obteve nota \\({X_H}_j\\), tal que \\(j = 1, 2, \\ldots, n_H\\), sendo \\(n_H\\) o número de rapazes que fizeram a prova. E de modo similar, o índice \\(M\\) na variável \\({X_M}_k\\), representa a aluna \\(k\\) do sexo feminino que obteve nota \\({X_M}_j\\), tal que \\(k = 1, 2, \\ldots, n_M\\), sendo \\(n_M\\) o número de moças que fizeram a prova. Dessa forma a proporção de mulheres que fizeram a prova é: \\[\\begin{align*}\n        \\sum_{i = 1}^{n}X_i & = \\sum_{k = 1}^{n_M}X_k + \\sum_{j = 1}^{n_H}X_j\\\\\n        n\\bar{X} & = n_M \\bar{X}_M + n_H \\bar{X}_H \\quad \\\\\n        5,8n & = 6,3n_M + 4,3n_H \\quad (n = n_H + n_M)\\\\\n        5,8n & = 6,3n_M + 4,3(n - n_M)\\\\\n        5,8n - 4,3n & = 6,3n_M - 4,3n_M\\\\\n        0,75n & = n_M.\n      \\end{align*}\\] Portanto, há 75% dos alunos que realizaram a prova, eram mulheres.\n\n\n\nExercício 3.6Uma prova de estatística foi aplicada com pontuação de 0 a 10 pontos, numa turma com 30 alunos, sendo uma média de 70 pontos. Nenhum dos alunos obteve nota inferior a 60 pontos. Dessa forma, qual o número máximo de alunos que podem ter obtido nota igual a 90 pontos?\n\n\n\n\n\n\nMAGALHÃES, M. N.; LIMA, A. C. P. DE. Noções de Probabilidade e Estatística. 7. ed. São Paulo: Edusp, 2015. p. 416",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Medidas de Posição</span>"
    ]
  },
  {
    "objectID": "cap03.html#footnotes",
    "href": "cap03.html#footnotes",
    "title": "3  Medidas de Posição",
    "section": "",
    "text": "Entendemos que uma variável tem natureza discretizada quando seus potenciais valores assumem em um conjunto enumerável ou categorizado, isto é, variável quantitativa discreta e variáveis qualitativas.↩︎",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Medidas de Posição</span>"
    ]
  },
  {
    "objectID": "cap04.html",
    "href": "cap04.html",
    "title": "4  Medidas de dispersão",
    "section": "",
    "text": "4.1 Amplitude total ou Amplitude\nA primeira medida de dispersão que definiremos é a amplitude ou amplitude total, denotada por \\(A\\) ou \\(A_t\\). Iremos apresentar, três definições sobre a amplitude baseadas nos valores observados da população, da amostra, e em dados agrupados sem e com intervalo de classe. Vejamos o primeiro caso, pensando em uma população, apresentada na Definição 4.1.\nSe desejarmos representar essa notação em termos de valor observado, temos \\(a_t = x_{(N)} - x_{(1)}\\). Já usamos uma referência sobre a amplitude total ou amplitude, expressão (2.11), quando agrupamos os dados em intervalo de classes, para o caso das variáveis quantitativas contínuas. Vejamos o Exemplo 4.1 sobre os dados da taxa de desmatamento na Amazônia legal, compreendido entre 1988 a 07/12/2020.\nPodemos representar a aplitude em termos amostras, como será apresentado na Definição 4.2, a seguir.\nO que vai diferenciar a representação nas expressões (4.1) e (4.2), e o número de elementos, isto é, o tamanho populacional representado por “\\(N\\)”, e o tamanho amostral, representado por “\\(n\\)”. Porém, percebemos que a realização do cálculo é a mesma. Da mesma forma que a representação populacional, podemos representar a amplitude em uma amostra, em termos de valor observado como \\(a = x_{(n)} - x_{(1)}\\). Vejamos o Exemplo 4.2, a seguir.\nPara a amplitude em termos de dados agrupados, temos a situação em que as variáveis podem ser discretas ou contínuas. No caso, das variáveis quantitativas contínuas, os grupos são classes, e os valores passam a ser representados pelos seus pontos médios de cada classe. Assim, apresentamos na Definição 4.3, a amplitude para dados agrupados com e sem intervalo de classe.\nPodemos representar a Definição 4.3 em termos populacionais, substituindo o tamanho \\(n\\) por \\(N\\), como também representar a expressão em termos de valor observado, como mencionado na definições anteriores. Vejamos o Exemplo 4.3, a seguir.\nPodemos ainda apresentar algumas características sobre a amplitude, dos quais temos:\nComplementando as características da amplitude, apresentamos algumas propriedades pelo Teorema 4.1 a seguir, do qual iremos usar a Definição 4.2 como base, e as demais seguem de forma similar.\nDevido ao problema encontrado no Exemplo 4.2, vamos apresentar algumas outras medidas que levem em consideração as demais variáveis bem como uma referência da posição central dos dados, que em nosso caso será a média aritmética.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Medidas de dispersão</span>"
    ]
  },
  {
    "objectID": "cap04.html#amplitude-total-ou-amplitude",
    "href": "cap04.html#amplitude-total-ou-amplitude",
    "title": "4  Medidas de dispersão",
    "section": "",
    "text": "Definição 4.1: Amplitude em uma populaçãoSeja uma população \\(X_1\\), \\(X_2\\), \\(\\ldots\\), \\(X_N\\), de tamanho \\(N\\), e em ordem crescente de magnitude temos \\(X_{(1)} = \\min\\limits_{i}(X_i)\\), \\(X_{(2)}\\), \\(\\ldots\\), \\(X_{(N)} = \\max\\limits_{i}(X_i)\\), para \\(i\\) \\(=\\) \\(1\\), \\(2\\), \\(\\ldots\\), \\(N\\). Então a amplitude de uma população, denotada por \\(A_p\\), é definida por: \\[\n\\begin{align}\n  A_p & = X_{(N)} - X_{(1)}.\n\\end{align}\n\\tag{4.1}\\]\n\n\n\n\nExemplo 4.1: Desmatamento da Amazônia LegalJá mencionamos anteriormente, na Tabela 1.2, os dados de desmatamento da Amazônia legal. Se considerarmos que os elementos da população sejam os estados, portanto, temos as informações de todos os elementos, e assim, estamos diante de dados populacionais. Vamos assim, calcular a amplitude para a variável desmatamento acumulado, em \\(km^2\\), de acordo com a expressão (2.11), isto é, \\[\\begin{align*}\n  A & = 157.667,00 - 1.696,00 = 155971~km^2.\n\\end{align*}\\] Isso representa, uma variação de \\(155971~km^2\\). Observe que essa medida está na mesma escala da variável, e que se houve um outro conjunto de dados, em mesma unidade, poderíamos comparar qual a que apresentou maior dispersão.\n\n\n\n\nDefinição 4.2: Amplitude em uma amostraSeja uma amostra \\(X_1\\), \\(X_2\\), \\(\\ldots\\), \\(X_n\\), de tamanho \\(n\\), e em ordem crescente de magnitude temos \\(X_{(1)} = \\min\\limits_{i}(X_i)\\), \\(X_{(2)}\\), \\(\\ldots\\), \\(X_{(n)} = \\max\\limits_{i}(X_i)\\), para \\(i\\) \\(=\\) \\(1\\), \\(2\\), \\(\\ldots\\), \\(n\\). Então a amplitude de uma população, denotada por \\(A\\), é definida por: \\[\n\\begin{align}\\label{}\n  A & = X_{(n)} - X_{(1)}.\n\\end{align}\n\\tag{4.2}\\]\n\n\n\n\nExemplo 4.2Retornando aos dados amostrais simulados na Tabela 4.1, calculamos as amplitudes,\n\n\n\nGrupo\nAmplitude\n\n\n\n\ngA\n\\(A = 10,77959  - 6,746655 = 4,032934~und.\\)\n\n\ngB\n\\(A = 18,787223 - 3,493309 = 15,29391~und.\\)\n\n\ngC\n\\(A = 20,000000 - 3,493309 = 15,29391~und.\\)\n\n\n\nPor esse resultado, podemos observar os grupos gB e gC que suas amplitudes foram iguais. Será que podemos, então afirmar que esses dois grupos são iguais? Quando observamos os dados, percebemos que os valores não são iguais. Isso ocorre por uma limitação nessa medida de dispersão. Vamos deixar para explorar essa situação mais a frente.\n\n\n\n\nDefinição 4.3: Amplitude em dados agrupadosSeja uma amostra \\(X_1\\), \\(X_2\\), \\(\\ldots\\), \\(X_n\\), de tamanho \\(n\\), agrupados em \\(k\\) grupos com variáveis \\(X_i\\) e \\(F_i\\) frequências, ou \\(k\\) classes com pontos médios \\(\\tilde{X}_i\\) e \\(F_i\\) frequências, para \\(i\\) \\(=\\) \\(1\\), \\(2\\), \\(\\ldots\\), \\(k\\) e \\(\\sum_{i = 1}^{k}F_i = n\\), então a amplitude de uma amostra, denotada por \\(A\\), é definida por: \\[\n\\begin{align}\n    A & = \\left\\{\\begin{array}{ll}\n                   X_{(k)} - X_{(1)}, &  \\textrm{Agrupados sem intervalo de classe}, \\\\\n                   \\tilde{X}_{(k)} - \\tilde{X}_{(1)}, & \\textrm{Agrupados com intervalo de classe},\\\\\n                 \\end{array}\\right.\n\\end{align}\n\\tag{4.3}\\] em que \\(X_{(k)} = \\max\\limits_{i}(X_i)\\), \\(X_{(1)} = \\min\\limits_{i}(X_i)\\), \\(\\tilde{X}_{(k)} = \\max\\limits_{i}(\\tilde{X}_{i})\\), \\(\\tilde{X}_{(1)} = \\min\\limits_{i}(\\tilde{X}_{i})\\), sendo \\(\\tilde{X}_{i}\\) o ponto médio das classes.\n\n\n\n\nExemplo 4.3Retornando aos dados da Tabela 2.3, podemos calcular a amplitude do número de erros encontrados em 20 conjunto de caracteres, usando a expressão (4.3), da seguinte forma: \\[\\begin{align*}\n  A & = 4 - 1 = 3~\\textrm{erros}.\n\\end{align*}\\] Para os dados agrupados com intervalo de classe, apresentados no Exemplo 2.1, podemos calcular a amplitude da temperatura do anel de vedação de cada teste de acionamento do motor do foguete Challenger, da seguinte forma: \\[\\begin{align*}\n  A & = 84 - 31 = 53~\\textrm{ºF}.\n\\end{align*}\\] No primeiro caso, usamos as próprias observações para o cálculo da amplitude. No segundo caso, usamos os pontos médios.\n\n\n\n\no resultado da amplitude é dado na mesma unidade da variável em estudo;\numa medida de dispersão facilmente calculada;\nlimitada apenas as variáveis quantitativas;\nessa medida é muito utilizada em comparações múltiplas, cartas de controle em estatística de qualidade, dentre outras áreas;\na amplitude pode ser utilizada como medida de dispersão para comparar a variabilidade de dados de dois ou mais grupos diferentes;\na amplitude é sensível a dados discrepantes1;\na amplitude é limitada por levar em consideração apenas os valores extremos, e nada sobre as demais observações. Nesse caso, podem ocorrer situações como os apresentados no Exemplo 4.2, em que poderíamos erroneamente concluir que os grupos de dados gB e gC são iguais, uma vez que apresentam amplitude e média aritmética iguais;\nsegundo Ferreira (2009, p. 36), a amplitude amostral, expressão (4.2), substima a amplitude populacional, expressão (4.1), uma vez que é pouco provável que uma amostra contenha os valores mínimo e máximo da população, portanto, a amplitude amostral é um estimador2 viesado3 e ineficiente.\n\n\n\nTeorema 4.1: Propriedades da Amplitude\nBaseado na Definição 4.2, e considerando \\(c\\) uma constante, então:\n\nSe para uma amostra \\(X_1\\), \\(X_2\\), \\(\\ldots\\), \\(X_n\\), a amplitude é dada por \\(A_X = X_{(n)} - X_{(1)}\\), então para uma transformação de \\(Y_i = X_i \\pm c\\), para \\(i\\) \\(=\\) \\(1\\), \\(2\\), \\(\\ldots\\), \\(n\\), a nova amplitude não se altera, isto é, \\(A_Y = A_X\\).\nSe para uma amostra \\(X_1\\), \\(X_2\\), \\(\\ldots\\), \\(X_n\\), a amplitude é dada por \\(A_X = X_{(n)} - X_{(1)}\\), então para uma transformação de \\(Y_i = X_i \\times c\\), para \\(i\\) \\(=\\) \\(1\\), \\(2\\), \\(\\ldots\\), \\(n\\), a nova amplitude é dada por \\(A_Y = A_X \\times c\\). Esse resultado vale também para a transformação \\(Y_i = X_i / m\\), sendo \\(m\\) também uma constante. Basta usar \\(c = 1 / m\\) e o resultado é o mesmo.\n\n\n\n\nProva\n\nConsiderando uma amostra \\(X_1\\), \\(X_2\\), \\(\\ldots\\), \\(X_n\\), e \\(c\\) uma constante, e que \\(Y_i = X_i \\pm c\\), para \\(i\\) \\(=\\) \\(1\\), \\(2\\), \\(\\ldots\\), \\(n\\), então a amplitude de \\(Y_i\\) é dado por: \\[\\begin{align*}\n  A_Y & = Y_{(n)} - Y_{(1)}\\\\\n      & = (X_{(n)} \\pm c)  - (X_{(1)} \\pm c)\\\\\n      & = X_{(n)}  - X_{(1)}\\\\\n      & = A_X.\n\\end{align*}\\]\nConsiderando uma amostra \\(X_1\\), \\(X_2\\), \\(\\ldots\\), \\(X_n\\), e \\(c\\) uma constante, e que \\(Y_i = X_i \\times c\\), para \\(i\\) \\(=\\) \\(1\\), \\(2\\), \\(\\ldots\\), \\(n\\), então a amplitude de \\(Y_i\\) é dado por: \\[\\begin{align*}\n  A_Y & = Y_{(n)} - Y_{(1)}\\\\\n      & = (X_{(n)} \\times  c)  - (X_{(1)} \\times c)\\\\\n      & = (X_{(n)}  - X_{(1)}) \\times c\\\\\n      & = A_X \\times c.\n\\end{align*}\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Medidas de dispersão</span>"
    ]
  },
  {
    "objectID": "cap04.html#variância",
    "href": "cap04.html#variância",
    "title": "4  Medidas de dispersão",
    "section": "4.2 Variância",
    "text": "4.2 Variância\nDiante do Exemplo 4.2, percebemos que complementar a caracterização dos dados com a amplitude, se torna uma medida muito simples. Observamos que os grupos gB e gC apresentam mesmas médias e amplitudes. Assim, poderíamos dizer que os grupos são semelhantes. Mas quando observamos a Tabela 4.1, percebemos que estes são diferentes. Assim, vamos apresentar mais algumas medidas que englobem as demais variáveis e o valor central desses dados em seu cálculo, para apresentarmos medidas mais explicativas para dispersão de dados.\nConsiderando uma população \\(X_1\\), \\(X_2\\), \\(\\ldots\\), \\(X_N\\) e sua respectiva amostra \\(X_1\\), \\(X_2\\), \\(\\ldots\\), \\(X_n\\), podemos considerar inicialmente o desvio médio como outra medida de dispersão, dada por: \\[\n\\begin{align}\n  DM_p & = \\sum_{i = 1}^{N} \\left(X_i - \\mu \\right), \\quad \\textrm{(Populacional)}\n\\end{align}\n\\tag{4.4}\\] em que \\(\\mu = \\sum_{i = 1}^{N} X_i / N\\), e seu respectivo estimador é dado por: \\[\n\\begin{align}\n  DM & = \\sum_{i = 1}^{n} \\left(X_i - \\bar{X} \\right), \\quad \\textrm{(Amostral)}\n\\end{align}\n\\tag{4.5}\\] em que \\(\\bar{X} = \\sum_{i = 1}^{n} X_i / n\\). Observamos agora, que diferentemente da amplitude, essa medida leva em consideração todos os elementos, seja da amostra ou da população, em relação a uma medida central, como preconizamos inicialmente a definição de uma medida de dispersão no início desse capítulo. O problema é que a expressão (4.5), como mostrado no Teorema 1.1, propriedade (V), sempre resulta em valor nulo para qualquer grupo amostral. De modo similar, a expressão (4.4) também \\(\\sum_{i = 1}^{N} \\left(X_i - \\mu \\right) = 0\\). Isso significa que essa medida não traz ganho algum a descrição dos dados, porque os desvios positivos anulam-se com os desvios negativos no somatório, sendo pois uma questão de problema algébrico. Para isso, podemos contornar essa situação inserindo uma função modular nessa medida anterior, e criar o módulo do desvio, dada por: \\[\n\\begin{align}\n  S_{|\\mu|} & = \\sum_{i = 1}^{N} \\left|X_i - \\mu \\right|, \\quad \\textrm{(Populacional)}\n\\end{align}\n\\tag{4.6}\\] e \\[\n\\begin{align}\n  S_{|\\bar{X}|} & = \\sum_{i = 1}^{n} \\left|X_i - \\bar{X} \\right|. \\quad \\textrm{(Amostral)}\n\\end{align}\n\\tag{4.7}\\] Desse modo, sabemos que \\(\\sum_{i = 1}^{n} \\left|X_i - \\bar{X} \\right| \\geq 0\\), e agora temos uma medida que represente a dispersão com o qual os dados estão em torno da média. Quanto maior o módulo do desvio, mais disperso é o conjunto de dados. A questão do uso do módulo para resolver o problema da medida do desvio médio, nos gera uma outra dificuldade que poderemos ter mais a frente quando formos estudar inferência estatística. Tem situações que iremos precisar integrar, derivar, etc., dentre outras ferramentas matemáticas, que se torna mais fácil ao invés de usar o módulo, usarmos uma função quadrática na medida. Daí, surge uma outra medida de variabilidade que é a soma de quadrados, dada por: \\[\n\\begin{align}\n  SQ_{p} & = \\sum_{i = 1}^{N} \\left(X_i - \\mu \\right)^2, \\quad \\textrm{(Populacional)}\n\\end{align}\n\\tag{4.8}\\] e \\[\n\\begin{align}\n  SQ & = \\sum_{i = 1}^{n} \\left(X_i - \\bar{X} \\right)^2. \\quad \\textrm{(Amostral)}\n\\end{align}\n\\tag{4.9}\\] Percebemos que a soma de quadrados amostral pode ser também expressa por: \\[\n\\begin{align}\n  SQ & = \\displaystyle\\sum_{i = 1}^{n}X_i^2 - \\frac{1}{n} \\left(\\sum_{i = 1}^{n}X_i\\right)^2,\n\\end{align}\n\\tag{4.10}\\] como pode ser provado no Teorema 1.1. Nesse último caso, podemos trabalhar sem o uso da informação da média, mas sim, apenas com as informações das observações. Essa medida apresenta uma outra informação interessante que é penalizar as observações quanto mais estiver distante do valor central. Observe que quando elevamos ao quadrado um alto desvio, esse valor se torna maior ainda, mas quando elevamos ao quadrado um desvio pequeno, esse valor não cresce tanto. Assim, conseguimos compreender quais os dados que estão mais dispersos em torno da média.\nBaseado nessas informações, surge a variância populacional que é a média da soma de quadrados, denotada por \\(\\sigma^2\\), definida a seguir.\n\nDefinição 4.4: Variância de uma populaçãoSeja uma população \\(X_1\\), \\(X_2\\), \\(\\ldots\\), \\(X_N\\), de tamanho \\(N\\), com parâmetro conhecido \\(\\mu = \\sum_{i = 1}^{N} X_i / N\\), então a variância populacional, denotada por \\(\\sigma^2\\), é definida por: \\[\n\\begin{align}\n    \\sigma^2 & = \\frac{SQ_p}{N},\n\\end{align}\n\\tag{4.11}\\] em que \\(SQ_p\\) é dado pela expressão (4.8), ou de forma similar, \\[\n\\begin{align}\n    \\sigma^2 & = \\frac{\\displaystyle\\sum_{i = 1}^{N}X_i^2 - \\frac{1}{N} \\sum_{i = 1}^{N}X_i^2}{N}.\n\\end{align}\n\\tag{4.12}\\]\n\n\nPodemos de forma intuitiva, pensar no estimador para \\(\\sigma^2\\) simplesmente substituindo “\\(N\\)” por “\\(n\\)” e \\(SQ_p\\) por \\(SQ\\), usando as mesmas expressões do que foram usados na Definição 4.4, isto é, \\[\n\\begin{align}\n  \\hat{\\sigma}^2 & = \\frac{SQ}{n}.\n\\end{align}\n\\tag{4.13}\\] Porém, existe uma propriedade nos estimadores, vista mais a frente, que é o seu viés. Dizemos que estimadores são viesados quando a sua esperança matemática não é igual ao parâmetro de interesse. Significa dizer em termos práticas, que mesmo se nós retirássemos todas as \\(k\\) amostras possíveis de uma população e para cada uma dessas amostras calculássemos a variância amostral, expressão (4.13), e posteriormente a média dessas variâncias, ou seja, \\((\\hat{\\sigma}^2_1 +\\hat{\\sigma}^2_2 + \\ldots + \\hat{\\sigma}^2_k) / k\\), esse valor não seria igual a \\(\\sigma^2\\). Logo, \\(\\hat{\\sigma}^2\\) é um estimador viesado. De outro modo, \\(\\hat{\\sigma}^2\\) é um estimador defeituoso. Para contornar esse problema, usamos a seguinte definição para uma variância amostral não viesada, denotada por \\(S^2\\), e apresentada na Definição 4.5.\n\nDefinição 4.5: Variância de uma amostraSeja uma população \\(X_1\\), \\(X_2\\), \\(\\ldots\\), \\(X_n\\), de tamanho \\(n\\), com \\(\\bar{X} = \\sum_{i = 1}^{n} X_i / n\\), então a variância amostral, denotada por \\(S^2\\), é definida como: \\[\n\\begin{align}\n    S^2 & = \\frac{SQ}{n - 1},\n\\end{align}\n\\tag{4.14}\\] em que \\(SQ\\) é dado pela expressão (4.9), ou de forma similar, \\[\n\\begin{align}\n    S^2 & = \\frac{\\displaystyle\\sum_{i = 1}^{n}X_i^2 - \\frac{1}{n} \\left(\\sum_{i = 1}^{n}X_i\\right)^2}{n - 1}.\n\\end{align}\n\\tag{4.15}\\]\n\n\nPara elucidar essas informações, vejamos o Exemplo 4.6.\n\nExemplo 4.4Retornando aos dados amostrais simulados na Tabela 4.1, podemos calcular a variância amostral para cada um dos grupos. Vamos usar a expressão (4.15) para isso, que segue:\n\nVariância amostral para o grupo gA: \\[\\begin{align*}\n  S^2_{\\textrm{gA}} & = \\frac{6,746655 + \\ldots + 10,779589^2 + }{10 - 1}\\\\\n  & = \\frac{- 1 / 10 \\times \\left(6,746655 +  \\ldots + 10,779589 \\right)^2}{10 - 1}\\\\\n  & = \\frac{831,0017 - 8133,67 / 10}{9}\\\\\n  & = 1,959404~und^2\n\\end{align*}\\]\nVariância amostral para o grupo gB: \\[\\begin{align*}\n  S^2_{\\textrm{gB}} & = \\frac{3,493309^2 + \\ldots + 18,787223^2 +}{10 - 1}\\\\\n& = \\frac{ - 1 / 10 \\times \\left(3,493309 +  \\ldots + 18,787223 \\right)^2}{10 - 1}\\\\\n& = \\frac{988,9577 - 8133,67 / 10}{9}\\\\\n& = 19,51007~und^2\n\\end{align*}\\]\nVariância amostral para o grupo gC: \\[\\begin{align*}\nS^2_{\\textrm{gC}} & = \\frac{4,706090^2 + \\ldots + 20,000000^2 +}{10 - 1}\\\\\n& = \\frac{- 1 / 10 \\times \\left(4,706090 +  \\ldots + 20,000000 \\right)^2}{10 - 1}\\\\\n& = \\frac{990,8678 - 8133.67 / 10}{9}\\\\\n& = 19,72232~und^2\n\\end{align*}\\]\n\nPodemos perceber que de fato os grupos gB e gC não são iguais, como podemos verificar pelos resultados das variâncias amostrais, uma vez que essa informação foi mascarada quando verificamos o resultado da amplitude para esses mesmos dois grupos no Exemplo 4.2. A dispersão das informações se torna mais detalhada, porque agora a medida leva em consideração todas as observações.\n\n\nPara o caso de dados agrupados, apresentamos a seguir a notação para o cálculo da variância, pela Definição 4.6.\n\nDefinição 4.6: Variância em dados agrupadosSeja uma amostra \\(X_1\\), \\(X_2\\), \\(\\ldots\\), \\(X_n\\), de tamanho \\(n\\), agrupados em \\(k\\) grupos com variáveis \\(X_i\\) e frequência \\(F_i\\), ou \\(k\\) classes com pontos médios \\(\\tilde{X}_i\\) e \\(F_i\\) frequências, para \\(i\\) \\(=\\) \\(1\\), \\(2\\), \\(\\ldots\\), \\(k\\) e \\(\\sum_{i = 1}^{k}F_i = n\\), então a variância de uma amostra, denotada por \\(S^2\\), é definida por: \\[\n\\begin{align}\n    S^2 & = \\left\\{\\begin{array}{ll}\n                   \\frac{\\sum_{i = 1}^{k}(X_i - \\bar{X})^2\\times F_i}{\\sum_{i = 1}^{k}F_i - 1}, &  \\textrm{s/ classe}, \\\\\n                   &\\\\\n                   \\frac{\\sum_{i = 1}^{k}(\\tilde{X}_i - \\bar{\\tilde{X}})^2\\times F_i}{\\sum_{i = 1}^{k}F_i - 1}, &  \\textrm{c/ classe},\\\\\n                 \\end{array}\\right.\n\\end{align}\n\\tag{4.16}\\] sendo \\(\\tilde{X}_{i}\\) o ponto médio das classes, \\(\\bar{X} = \\sum_{i = 1}^{k} X_iF_i / \\sum_{i = 1}^{k}F_i\\) e \\(\\bar{\\tilde{X}} = \\sum_{i = 1}^{k} \\tilde{X}_iF_i / \\sum_{i = 1}^{k}F_i\\), ou se forma similar, \\[\n\\begin{align}\n    S^2 & = \\left\\{\\begin{array}{ll}\n                  \\frac{\\sum_{i = 1}^{k}X_i^2\\times F_i - \\frac{1}{\\sum_{i = 1}^{k} F_i}(\\sum_{i = 1}^{k} X_iF_i)^2}{\\sum_{i = 1}^{k}F_i - 1}, &  \\textrm{s/ classe}, \\\\\n                  & \\\\\n                  \\frac{\\sum_{i = 1}^{k}\\tilde{X}_i^2\\times F_i - \\frac{1}{\\sum_{i = 1}^{k} F_i}(\\sum_{i = 1}^{k} \\tilde{X}_iF_i)^2}{\\sum_{i = 1}^{k}F_i - 1}, &  \\textrm{c/ classe}. \\\\\n                 \\end{array}\\right.\n\\end{align}\n\\tag{4.17}\\]\n\n\nPodemos representar a Definição 4.6 em termos populacionais, substituindo o tamanho \\(n\\) por \\(N\\) e considerando o denominador apenas como \\(\\sum_{i = 1}^{k}F_i - 1\\) ao invés de \\(\\sum_{i = 1}^{k}F_i - 1\\), tal que \\(\\sum_{i = 1}^{k}F_i = N\\). Podemos também representar a expressão em termos de valor observado, como mencionado na definições anteriores.\nConsiderando os dados agrupados sem intervalo de classes (Tabela 2.2) e com intervalo de classes (Exemplo 2.1), respectivamente, podemos calcular a variância de acordo a Definição 4.6, no exemplo a seguir.\n\nExemplo 4.5Iremos realizar o cálculo da variância para dados agrupados de acordo com a expressão (4.16). Inicialmente, vamos usar os dados agrupados sem intervalo de classe do número de erros encontrados em 20 conjunto de caracteres monitorado em um canal de comunicação, que segue:\n\\[\\begin{align*}\n  S^2 & = \\frac{(0 - 1,7)^2 \\times 3 + \\ldots + (4 - 1,7)^2 \\times 1}{20 - 1}\\\\\n      & = 1,3789~\\textrm{erros}^2,\n\\end{align*}\\] cujo valor da média foi obtido do Exemplo 3.2. Para o cômputo da variância do próximo conjunto de dados referentes a temperatura (°\\(F\\)) do anel de vedação de cada teste de acionamento ou lançamento real do motor do foguete Challenger, temos: \\[\\begin{align*}\n    S^2 & = \\frac{(31 - 66,04)^2 \\times 3 + \\ldots + (84 - 66,04)^2 \\times 1}{36 - 1}\\\\\n    & = 159,3550~\\text{°}F^2,\n\\end{align*}\\] cujo valor da média foi obtido do Exemplo 3.3.\n\n\nPara finalizar, podemos replicar o procedimento do Exemplo 4.5 usando o pacote leem apresentado no Código R 4.2.\n\n\n\n\nCódigo R 4.2: Cálculo da variância.\n\n\n# Anexando o pacote leem ao caminho de busca\nlibrary(leem)\n# Dados do numero de erros (Variavel quantitativa discreta)\nnerros &lt;- read.table(\"https://raw.githubusercontent.com/bendeivide/book-epaec/master/dados/cap02/tabela2.1.txt\", h = T)\n# Calculando a variancia para dados\n# agrupados sem intervalo de classe\nnerros$erros |&gt;\n  new_leem() |&gt;\n  variance(rounding = 4)\n# [1] 1.3789\n\n# Calculando a variancia para dados\n# nao agrupados\nnerros$erros |&gt;\n  new_leem() |&gt;\n  variance(rounding = 4, grouped = FALSE)\n# [1] 1.3789\n\n# Dados da temperatura do Anel de vedacao do motor do foguete Challenger (Variavel quantitativa continua)\ndados &lt;- read.table(\"https://raw.githubusercontent.com/bendeivide/book-epaec/master/dados/cap02/dados_exem2.1.txt\", h = T)\n# Calculando a variancia para dados\n#  agrupados com intervalo de classe\ndados$challenger |&gt;\n  new_leem(variable = 2) |&gt;\n  variance(rounding = 4)\n# [1] 159.355\n\n# Calculando a variancia para dados\n#  nao agrupados\ndados$challenger |&gt;\n  new_leem(variable = 2) |&gt;\n  variance(rounding = 4, grouped = FALSE )\n# [1] 147.8373\n\n\n\n\nPodemos observar no Código R 4.2, que o cálculo da variância para as variáveis quantitativas discretas não mudam o resultado quando os dados estão agrupados ou não. Porém, o mesmo não ocorre para as variáveis quantitativas contínuas. Essa discussão será deixada como exercício proposto no Exercício 4.8.\nVejamos algumas características da variância:\n\na unidade da variância está na escala ao quadrado da unidade da variável;\nlimitada apenas as variáveis quantitativas;\na variância é sempre uma medida positiva, exceto quando todos os valores são iguais que resultam em uma variância nula;\nquanto mais próximo de zero a variância for, mas concentrado os dados estão em torno da média, ao passo que, à medida que a variância se distancia de zero, mas disperso os dados estão em torno da média;\ndevido as suas propriedades matemáticas, algumas mencionadas anteriormente, bem como a quantidade de técnicas estatísticas que empregam essa medida, a torna como a mais conhecida dentre as medidas de dispersão;\numa vez que a média é sensível aos dados, a variância também é sensível, uma vez que esta depende da média.\n\nPelo Teorema 4.2, apresentamos algumas propriedades da variância a seguir, do qual iremos usar a Definição 4.5 como base, e as demais seguem de forma similar.\n\nTeorema 4.2: Propriedades da Variância\nBaseado na Definição 4.5, e considerando \\(c\\) uma constante, então:\n\nSe para uma amostra \\(X_1\\), \\(X_2\\), \\(\\ldots\\), \\(X_n\\), a variância é dada por \\(S^2_X\\), expressão (4.14), então para uma transformação de \\(Y_i = X_i \\pm c\\), para \\(i\\) \\(=\\) \\(1\\), \\(2\\), \\(\\ldots\\), \\(n\\), então a nova variância não se altera, isto é, \\(S^2_Y = S^2_X\\).\nSe para uma amostra \\(X_1\\), \\(X_2\\), \\(\\ldots\\), \\(X_n\\), a variância é dada por \\(S^2_X\\), expressão (4.14), então para uma transformação de \\(Y_i = X_i \\times c\\), para \\(i\\) \\(=\\) \\(1\\), \\(2\\), \\(\\ldots\\), \\(n\\), então a nova variância é dada por \\(S^2_Y = c^2\\times S^2_X\\). Esse resultado vale também para a transformação \\(Y_i = X_i / m\\), sendo \\(m\\) também uma constante. Basta usar \\(c = 1 / m\\) e o resultado é o mesmo.\n\n\n\n\nProva\n\nConsiderando uma amostra \\(X_1\\), \\(X_2\\), \\(\\ldots\\), \\(X_n\\), e \\(c\\) uma constante, e que \\(Y_i = X_i \\pm c\\), para \\(i\\) \\(=\\) \\(1\\), \\(2\\), \\(\\ldots\\), \\(n\\), então a variância de \\(Y_i\\) é dado por: \\[\\begin{align*}\nS^2_Y & = \\frac{\\sum_{i = 1}^{n}(Y_i - \\bar{Y})^2}{n - 1}\\\\\n     & = \\frac{\\sum_{i = 1}^{n}[(X_i \\pm c) - (\\bar{X} \\pm c)]^2}{n - 1}\\\\\n      & = \\frac{\\sum_{i = 1}^{n}(X_i - \\bar{X})^2}{n - 1}\\\\\n     & = S^2_X.\n  \\end{align*}\\]\nConsiderando uma amostra \\(X_1\\), \\(X_2\\), \\(\\ldots\\), \\(X_n\\), e \\(c\\) uma constante, e que \\(Y_i = X_i \\times c\\), para \\(i\\) \\(=\\) \\(1\\), \\(2\\), \\(\\ldots\\), \\(n\\), então a variância de \\(Y_i\\) é dado por: \\[\\begin{align*}\nS^2_Y & = \\frac{\\sum_{i = 1}^{n}(Y_i - \\bar{Y})^2}{n - 1}\\\\\n    & = \\frac{\\sum_{i = 1}^{n}[(X_i \\times c) - (\\bar{X} \\times c)]^2}{n - 1}\\\\\n    & = \\frac{\\sum_{i = 1}^{n}c^2(X_i - \\bar{X})^2}{n - 1}\\\\\n    & = c^2 \\times \\frac{\\sum_{i = 1}^{n}(X_i - \\bar{X})^2}{n - 1}, \\quad \\textrm{(Teorema 1.1, (I))}\\\\\n    & = c^2 \\times S^2_X.\n  \\end{align*}\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Medidas de dispersão</span>"
    ]
  },
  {
    "objectID": "cap04.html#desvio-padrão",
    "href": "cap04.html#desvio-padrão",
    "title": "4  Medidas de dispersão",
    "section": "4.3 Desvio padrão",
    "text": "4.3 Desvio padrão\nA variância apesar de ter resolvido alguns dos problemas mencionados anteriormente, para uma medida de dispersão, apresenta sua unidade ao quadrado da unidade da variável em estudo, isso significa que se tivermos usando uma variável na escala de metros, a dispersão dada pela variância estará na escala de área, isto é, em metros ao quadrado. Isso se torna difícil a percepção de dispersão quando observamos os dados. Dessa forma, surge a medida do desvio padrão, definida a seguir.\n\nDefinição 4.7: Desvio padrãoO desvio padrão é definido por: \\[\n\\begin{align}\n  \\sigma & = \\sqrt{\\sigma^2}, \\quad \\textrm{(População)}\n\\end{align}\n\\tag{4.18}\\] e \\[\n\\begin{align}\n    S & = \\sqrt{S^2}, \\quad \\textrm{(Amostra)}\n\\end{align}\n\\tag{4.19}\\] em que \\(\\sigma^2\\) e \\(S\\) representam as variâncias populacional e amostral, respectivamente, apresentadas nas Definições 4.4 e 4.5 para o caso de dados não agrupados, e Definição 4.6 na condição de dados agrupados.\n\n\nCom o desvio padrão, podemos verificar a medida de variabilidade na mesma unidade da variável. Cabe destacar que a expressão (4.18) mede a variabilidade das observações em torno da média populacional. Porém na prática, não conhecemos o parâmetro \\(\\mu\\) nem muito menos temos informações de todas as observações. Com isso usamos como estimador de \\(\\sigma\\), o desvio padrão amostral dado na expressão (4.19), que se baseia em apenas uma amostra. Vejamos o exemplo a seguir.\n\nExemplo 4.6Retornando ao Exemplo 4.2, podemos então calcular os desvios padrões dos grupos, que segue:\n\nDesvio padrão amostral para o grupo gA: \\[\\begin{align*}\n  S_{\\textrm{gA}} & = \\sqrt{1,959404} = 1,399787~unid.\n\\end{align*}\\]\nDesvio padrão amostral para o grupo gB: \\[\\begin{align*}\n  S_{\\textrm{gB}} & = \\sqrt{19,51007} = 4,41702~und.\n\\end{align*}\\]\nDesvio padrão amostral para o grupo gC: \\[\\begin{align*}\nS_{\\textrm{gC}} & =  \\sqrt{19,72232} = 4,440982~und.\n\\end{align*}\\]\n\nConsiderando que as unidades dos grupos são iguais, bem como as suas médias, podemos concluir que o grupo gA apresenta menor dispersão. Claro que esse resultado poderia ter sido observado pela variância. A diferença é que conseguimos entender na unidade da variável essa dispersão.\n\n\nContudo, quando iremos comparar grupos de dados e verificar qual grupo apresenta maior variabilidade, devemos ter muito cuidado ao usar o desvio padrão ou a variância, sob dois aspectos:\n\nOs grupos de observações devem estar na mesma unidade de mensuração;\nA média desses grupos devem ser iguais.\n\nO primeiro aspecto está muito claro, uma vez que não temos, por exemplo, como comparar uma unidade em gramas e saber se a dispersão desses dados é maior ou menor quando se compara com outro conjunto de dados cuja unidade esteja na escala de comprimento. O segundo aspecto está limitado devido a forma de como foram calculados o desvio padrão e a variância. A soma de seus desvios levam em consideração a média. Assim, quando comparamos dois desvios padrões de duas amostras de uma população, em que temos o desvio padrão \\(S^2_1 = 10~unid\\) para a amostra 1, e \\(S^2_2 = 20~unid\\) para a amostra 2. Não podemos afirmar que a amostra 2 apresenta maior dispersão que a amostra 1, isso porque não sabemos o quanto esse valor representa em relação a média. Supomos que a média da amostra 1 seja \\(\\bar{X}_1 = 100~unid\\) e para a amostra 2, seja \\(\\bar{X}_1 = 50~unid\\). Desse modo, observemos que para a amostra 1, o desvio padrão representa apenas 10% do valor da média. Já na amostra 2, o desvio padrão representa 40% da média, uma variação muito mais considerável, isto é, os dados na amostra 2 são muito mais dispersos em torno da média. Isso justifica então, a criação de uma medida de dispersão relativa à média, que será definida na próxima seção.\nVejamos algumas características do desvio padrão, que segue:\n\na unidade do desvio padrão está na mesma escala da unidade da variável em estudo;\nlimitada apenas as variáveis quantitativas;\numa vez que a média é sensível aos dados, o desvio padrão também é sensível, uma vez que esta depende da média;\nembora a variância amostral, \\(S^2\\) seja um estimador não viesado para a variância populacional \\(\\sigma^2\\), o desvio padrão amostral \\(S\\), que é derivado de \\(S^2\\), é um estimador viesado do desvio padrão populacional \\(\\sigma\\);\nassim como a variância, o desvio padrão é sempre uma medida positiva, exceto quando todos os valores são iguais que resultam em uma variância nula;\nassim como na variância, quanto mais próximo de zero o desvio padrão for, mas concentrado os dados estão em torno da média, ao passo que, à medida que o desvio padrão se distancia de zero, mas disperso os dados estão em torno da média.\n\nComplementando as características do desvio padrão, apresentamos algumas propriedades no Teorema 4.3, do qual iremos usar a Definição 4.7 como base, e as demais seguem de forma similar.\n\nTeorema 4.3: Propriedades do Desvio Padrão\nBaseado na Definição 4.7, e considerando \\(c\\) uma constante, então:\n\nSe para uma amostra \\(X_1\\), \\(X_2\\), \\(\\ldots\\), \\(X_n\\), o desvio padrão é dado por \\(S_X\\), então para uma transformação de \\(Y_i = X_i \\pm c\\), para \\(i\\) \\(=\\) \\(1\\), \\(2\\), \\(\\ldots\\), \\(n\\), então o novo desvio padrão não se altera, isto é, \\(S_Y = S_X\\).\nSe para uma amostra \\(X_1\\), \\(X_2\\), \\(\\ldots\\), \\(X_n\\), o desvio padrão é dado por \\(S_X\\), então para uma transformação de \\(Y_i = X_i \\times c\\), para \\(i\\) \\(=\\) \\(1\\), \\(2\\), \\(\\ldots\\), \\(n\\), então o novo desvio padrão é dado por \\(S_Y = S_X \\times c\\). Esse resultado vale também para a transformação \\(Y_i = X_i / m\\), sendo \\(m\\) também uma constante. Basta usar \\(c = 1 / m\\) e o resultado é o mesmo.\n\n\n\n\nProva\n\nConsiderando uma amostra \\(X_1\\), \\(X_2\\), \\(\\ldots\\), \\(X_n\\), e \\(c\\) uma constante, e que \\(Y_i = X_i \\pm c\\), para \\(i\\) \\(=\\) \\(1\\), \\(2\\), \\(\\ldots\\), \\(n\\), então o desvio padrão de \\(Y_i\\) é dado por:\n\n\\[\\begin{align*}\n    S_Y & = \\sqrt{\\frac{\\sum_{i = 1}^{n}(Y_i - \\bar{Y})^2}{n - 1}}\\\\\n        & = \\sqrt{\\frac{\\sum_{i = 1}^{n}[(X_i \\pm c) - (\\bar{X} \\pm c)]^2}{n - 1}}\\\\\n         & = \\sqrt{\\frac{\\sum_{i = 1}^{n}(X_i - \\bar{X})^2}{n - 1}}\\\\\n        & = S_X.\n  \\end{align*}\\]\n\nConsiderando uma amostra \\(X_1\\), \\(X_2\\), \\(\\ldots\\), \\(X_n\\), e \\(c\\) uma constante, e que \\(Y_i = X_i \\times c\\), para \\(i\\) \\(=\\) \\(1\\), \\(2\\), \\(\\ldots\\), \\(n\\), então a variância de \\(Y_i\\) é dado por: \\[\\begin{align*}\nS_Y & = \\sqrt{\\frac{\\sum_{i = 1}^{n}(Y_i - \\bar{Y})^2}{n - 1}}\\\\\n    & = \\sqrt{\\frac{\\sum_{i = 1}^{n}[(X_i \\times c) - (\\bar{X} \\times c)]^2}{n - 1}}\\\\\n    & = \\sqrt{\\frac{\\sum_{i = 1}^{n}c^2(X_i - \\bar{X})^2}{n - 1}}\\\\\n    & = \\sqrt{c^2\\frac{\\sum_{i = 1}^{n}(X_i - \\bar{X})^2}{n - 1}}, \\quad \\textrm{(Teorema 1.1, (I))}\\\\\n    & = c \\times \\sqrt{S^2_X},\\\\\n    & = c \\times S_X.\n  \\end{align*}\\]",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Medidas de dispersão</span>"
    ]
  },
  {
    "objectID": "cap04.html#coeficiente-de-variação",
    "href": "cap04.html#coeficiente-de-variação",
    "title": "4  Medidas de dispersão",
    "section": "4.4 Coeficiente de Variação",
    "text": "4.4 Coeficiente de Variação\nAs medidas de variabilidade tais como a variância e desvio padrão, são conhecidas como medidas de dispersão absoluta. Diante do que foi exposto no fim da seção anterior sobre alguns problemas do desvio padrão, apresentamos mais uma medida de dispersão, Definição 4.8, agora uma medida relativa chamada de Coeficiente de Variação (CV), do qual pode ser usada para comparar a variabilidade entre quaisquer grupo de dados.\n\nDefinição 4.8: Coeficiente de VariaçãoO coeficiente de variação é definido por: \\[\n\\begin{align}\n    CV_p & = \\frac{\\sigma}{\\mu} \\times 100, \\quad \\textrm{(População)}\n\\end{align}\n\\tag{4.20}\\] e \\[\n\\begin{align}\n    CV & = \\frac{S}{\\bar{X}} \\times 100, \\quad \\textrm{(Amostra)}\n\\end{align}\n\\tag{4.21}\\]\nem que \\(\\sigma\\) e \\(S\\) representam o desvio padrão populacional e amostral, respectivamente, apresentados na Definição 4.7, e \\(\\mu\\) e \\(\\bar{X}\\) representam a média populacional e amostral, respectivamente, Definição 3.1 para a condição de dados não agrupados, e Definição 3.2 para a condição de dados agrupados.\n\n\nApesar de não explicitarmos, como os desvios padrões populacional e amostral dependem das variâncias populacional e amostral na Definição 4.8, fica subtendido que o cálculo do CV para os dados agrupados (com ou sem intervalo de classes), usaremos a Definição 4.6 para o cálculo da variância. Da mesma forma, para calcularmos o CV para dados não agrupados, usaremos as Definições 4.4 e 4.5 para o cálculo das variâncias populacional e amostral, respectivamente. O coeficiente de variação permite comparar a dispersão de dois ou mais grupos com características completamente diferente e com médias diferentes. Vejamos o Exemplo 4.7, para ilustrar essa característica.\n\nExemplo 4.7Com a medida do coeficiente de variação, podemos comparar a dispersão dos dados da Tabela 2.1 com a dispersão do grupo gA da Tabela 4.1. Para o primeiro conjunto de dados, podemos calcular a média e o desvio padrão do número de erros encontrados em 20 conjuntos de caracteres, dados por: \\[\\begin{align*}\n    \\bar{X}_e & = \\frac{3 + 1 + \\ldots + 1}{20} = 1,7~\\textrm{erros},\n  \\end{align*}\\] e \\[\\begin{align*}\n    S_e & = \\sqrt{\\frac{3^2 + 1^2 + \\ldots + 1^2 - 1 / 20 \\times (3 + 1 + \\ldots + 1)^2}{19}}\\\\\n      & = 1,174286~\\textrm{erros},\n  \\end{align*}\\] respectivamente. No caso dos dados do grupo gA, nós já temos os resultados da média e desvio padrão, dados na Tabela 4.1 e no Exemplo 4.6, respectivamente. Desse modo, comparando a dispersão dos dois grupos pelo coeficiente de variação, temos:\n\n\n\n\n\n\n\nDados\nCoeficiente de Variação (\\(\\mathbf{CV}\\))\n\n\n\n\ngA\n\\(CV_{\\textrm{gA}} = \\frac{1,399787}{9,018686} \\times 100 = 15,52\\%\\)\n\n\nNúmero de erros\n\\(CV_{e} = \\frac{1,174286}{1,7} \\times 100 = 69,08\\%\\)\n\n\n\nNesse caso, percebemos que os dados de gA tem menor variabilidade do que os dados do número de erros, e com isso, esses dados são melhor representado pela sua média amostral quando se comparado com o outro grupo de dados.\n\n\nMesmo resolvendo alguns problemas existentes nas medidas variância e desvio padrão, o coeficiente de variação apresenta algumas características importantes, que seguem:\n\nO \\(CV\\) é adimensional e uma medida de dispersão relativa;\nEssa medida pode ser utilizada para comparar a dispersão entre grupos diferentes de dados;\nComo o \\(CV\\) é uma medida de dispersão relativa, isto é, o desvio padrão ponderado pela média. Isso significa que o \\(CV\\) calcula o quanto representa a dispersão (o desvio padrão) representa à média. Dessa forma, o \\(CV\\) se torna limitado a variáveis em que a escala de mensuração das observações em que fornece um zero absoluto ou uma origem significativa. Por exemplo, a temperatura em graus celsius (ºC), uma observação igual a 0ºC não significa ausência de temperatura, logo, o \\(CV\\) para esse tipo de variável não faz sentido. Já o a variável peso em quilos, isto é, o valor 0kg representa ausência de peso, de outro modo, esse tipo de variável permite magnitudes de valores na escala, tais como, uma observação de 40kg é o dobro de uma observação de 20kg. Assim, podemos utilizar o coeficiente de variação para verificar a dispersão da variável peso;\nO \\(CV\\) pode superar o 100%. Isso ocorre quando o desvio padrão é maior do a média. Dizemos que esses superdispersos, um exemplo, são dados de contagem que seguem uma distribuição de Poisson.\n\nAs propriedades do \\(CV\\) levam em consideração as propriedade de \\(\\bar{X}\\) e \\(S\\), que já foram demonstradas. Assim, ficam para estudo no Exercício proposto 5.1, a demonstração para as propriedades do \\(CV\\).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Medidas de dispersão</span>"
    ]
  },
  {
    "objectID": "cap04.html#erro-padrão-da-média",
    "href": "cap04.html#erro-padrão-da-média",
    "title": "4  Medidas de dispersão",
    "section": "4.5 Erro padrão da média",
    "text": "4.5 Erro padrão da média\nPara iniciarmos uma última ideia sobre medidas de dispersão, dentre as medidas básicas, vamos iniciar como motivação, a Definição 4.9.\n\nDefinição 4.9: Erro da média amostralSeja uma amostra \\(X_1\\), \\(X_2\\), \\(\\ldots\\), \\(X_n\\), de uma população com parâmetro \\(\\mu\\), que representa a média populacional, e seu estimador \\(\\bar{X} = \\sum_{i = 1}^{n} X_i / n\\), então definimos o erro da média amostral, denotado por \\(EA_{\\bar{X}}\\), da seguinte forma: \\[\n\\begin{align}\n  EA_{\\bar{X}} & = \\bar{X} - \\mu.\n\\end{align}\n\\tag{4.22}\\]\n\n\nA medida expressa em (4.22) representa o erro de assumirmos a média amostral como um representante da média populacional. O desvio padrão de \\(EA_{\\bar{X}}\\) é o que chamamos de erro padrão da média, definido a seguir.\n\nDefinição 4.10: Erro padrão da média (Populacional)Seja uma amostra \\(X_1\\), \\(X_2\\), \\(\\ldots\\), \\(X_n\\), de uma população cujos parâmetros \\(\\mu\\) e \\(\\sigma\\), representam a média e o desvio padrão populacional, respectivamente, então o erro padrão da média, denotada por \\(\\sigma_{\\bar{X}}\\), é definido como: \\[\n\\begin{align}\n    \\sigma_{\\bar{X}} & = \\frac{\\sigma}{\\sqrt{n}},\n\\end{align}\n\\tag{4.23}\\] em que \\(n\\) representa o tamanho da amostra.\n\n\nQuando fazemos um comparativo entre o desvio padrão amostral e o erro padrão da média, entendemos que a primeira medida reflete a variabilidade de cada observação em torno da média amostral. Já o erro padrão da média representa a variabilidade de cada média amostral de todas amostra possíveis, em relação a média populacional.\nDessa forma, surgem alguns problemas para determinar a variabilidade da média amostral em torno da média populacional usando a expressão (4.23). Primeiro, é praticamente impossível realizar todas as amostras possíveis de uma população para computar a sua média. Se isso é possível, não precisaremos de amostra, uma vez que temos todas as informações da população, e então, estamos diante de um censo. Os outros fatores, podemos destacar que na prática, realizamos apenas uma amostra para análise das informação, e que o desvio padrão populacional geralmente é desconhecido, e assim, torna-se inviável o cálculo de \\(\\sigma_{\\bar{X}}\\). Uma alternativa é usar o estimador \\(S\\) ao invés de \\(\\sigma\\), surgindo então um estimador para o erro padrão da média populacional, definido a seguir.\n\nDefinição 4.11: Erro padrão da média (Amostral)Seja uma amostra \\(X_1\\), \\(X_2\\), \\(\\ldots\\), \\(X_n\\), de uma população cujos parâmetros \\(\\mu\\) e \\(\\sigma\\), representam a média e o desvio padrão populacional, respectivamente, então o erro padrão da média, denotada por \\(\\sigma_{\\bar{X}}\\), é definido como: \\[\n\\begin{align}\n    S_{\\bar{X}} & = \\frac{S}{\\sqrt{n}},\n\\end{align}\n\\tag{4.24}\\] em que \\(n\\) representa o tamanho da amostra, e \\(S\\) é o desvio padrão da Definição 4.7.\n\n\nÉ fácil observar que à medida que \\(n \\to N\\), isto é, à medida que \\(n\\) aumenta, a média amostral tende a \\(\\mu\\), logo o \\(EA_{\\bar{X}} \\to 0\\). Isso significa que a média amostral é mais precisa porque se aproxima cada vez mais da média populacional. Assim, com apenas uma amostra poderemos ter uma estimativa do erro padrão da média, apresentado no Exemplo 4.8.\n\nExemplo 4.8\nRetornando ao Exemplo 4.2, podemos então calcular os erros padrões da média para as três amostras, que segue:\n\nErro padrão da média amostral para o grupo gA: \\[\\begin{align*}\n  S_{\\bar{X}_{\\textrm{gA}}} & = 1,399787 / \\sqrt{10} = 0,4665957~unid.\n\\end{align*}\\]\nErro padrão da média amostral para o grupo gB: \\[\\begin{align*}\n  S_{\\bar{X}_{\\textrm{gB}}} & = 4,41702 / \\sqrt{10} = 1,396784~und.\n\\end{align*}\\]\nErro padrão da média amostral para o grupo gC: \\[\\begin{align*}\nS_{\\bar{X}_{\\textrm{gC}}} & = = 4,440982 / \\sqrt{10} = 1,404362~und.\n\\end{align*}\\] \\end{itemize} Percebemos que a média de gA estima melhor o parâmetro \\(\\mu\\), uma vez que o erro padrão da média foi o menor dentre os demais.\n\n\n\nDesse modo, observamos que o erro padrão da média representa uma precisão com que a média amostral estimou o parâmetro \\(\\mu\\). Além do erro padrão da média, há diversos outros erros padrões para outros estimadores de parâmetros diversos, sendo abordado mais a frente. Além do mais, essa medida será largamente usada na teoria de estimação e de decisão, tanto para a construção de intervalos de confiança, como também no desenvolvimento de testes de hipóteses, sendo também abordado nos próximos capítulos.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Medidas de dispersão</span>"
    ]
  },
  {
    "objectID": "cap04.html#exercícios-propostos",
    "href": "cap04.html#exercícios-propostos",
    "title": "4  Medidas de dispersão",
    "section": "Exercícios propostos",
    "text": "Exercícios propostos\n\nExercício 4.1\nCom relação as propriedades do Coeficiente de Variação (CV), prove que:\n\nSe para uma amostra \\(X_1\\), \\(X_2\\), \\(\\ldots\\), \\(X_n\\), o coeficiente de variação, Definição 4.8, então para uma transformação de \\(Y_i = X_i \\pm c\\), para \\(i\\) \\(=\\) \\(1\\), \\(2\\), \\(\\ldots\\), \\(n\\) e \\(c\\) uma constante, então o novo coeficiente de variação é igual a \\(CV_Y = S_X / (\\bar{X} \\pm c) \\times 100\\), em que \\(\\bar{X}\\) e \\(S_X\\) são a média e o desvio padrão de \\(X_i\\), \\(i = 1, 2, \\ldots, n\\);\nSe para uma amostra \\(X_1\\), \\(X_2\\), \\(\\ldots\\), \\(X_n\\), o coeficiente de variação, Definição 4.8, então para uma transformação de \\(Y_i = X_i \\times c\\), para \\(i\\) \\(=\\) \\(1\\), \\(2\\), \\(\\ldots\\), \\(n\\) e \\(c\\) uma constante, então o novo coeficiente de variação não se altera, isto é \\(CV_Y = CV_X\\). Esse resultado vale também para a transformação \\(Y_i = X_i / m\\), sendo \\(m\\) também uma constante. Basta usar \\(c = 1 / m\\) e o resultado é o mesmo.\n\n\n\n\nSolução\n\nConsiderando uma amostra \\(X_1\\), \\(X_2\\), \\(\\ldots\\), \\(X_n\\), assumimos que \\(\\bar{X}\\) e \\(S_X\\) são a média e o desvio padrão, dado a transformação \\(Y_i = X_i \\pm c\\), para \\(i\\) \\(=\\) \\(1\\), \\(2\\), \\(\\ldots\\), \\(n\\) e \\(c\\) uma constante, podemos afirmar, pelos Teoremas 3.1 e 4.3, respectivamente, que a média e o desvio padrão de \\(Y_i\\), podem ser dadas por \\(\\bar{Y} = \\bar{X} \\pm c\\) e \\(S_Y = S_X\\), respectivamente. Dessa forma, sabendo que o coeficiente de variação de \\(X_i\\) é dado por \\(CV_X = S_X / \\bar{X}\\), então o coeficiente de variação de \\(Y_i\\) é: \\[\\begin{align*}\n     CV_Y & = \\frac{S_Y}{\\bar{Y}} \\\\\n   \\end{align*}\\]\n\n\n\n\nExercício 4.2A tabela abaixo apresenta a distribuição de frequências das notas (em pontos) obtidas num teste de matemática, realizado por 50 estudantes.\n\n\n\nNotas\n\\(\\mathbf{F_i}\\)\n\n\n\n\n0 \\(|\\)— 2\n4\n\n\n2 \\(|\\)— 4\n12\n\n\n4 \\(|\\)— 6\n15\n\n\n6 \\(|\\)— 8\n13\n\n\n8 \\(|\\)— 10\n6\n\n\n\nApresente o cálculo para todas as medidas de dispersão estudadas e as interprete.\n\n\n\nExercício 4.3Para uma amostra \\(X_1\\), \\(X_2\\), \\(\\ldots\\), \\(X_n\\) de tamanho \\(n\\). Desejamos usar a transformação \\(Y_i = \\beta_0 + \\beta_1X_i\\), para \\(i\\) \\(=\\) \\(1\\), \\(2\\), \\(\\ldots\\), \\(n\\), considerando \\(\\beta_0\\) e \\(\\beta_1\\) constantes. Então, apresente as relação entre as médias e os desvios padrões de \\(X\\) e \\(Y\\).\n\n\n\nExercício 4.4Sabemos que a conversão da temperatura de graus Celsius (°C) para a escala de Fahrenheit (°F) é dada por: \\(F = 9 / 5 \\times C + 32\\), considerando a variável \\(F\\) a temperatura em Fahrenheit, e \\(C\\) a temperatura em graus Celsius. Se medíssemos a temperatura de um peça no momento de fabricação, e verificássemos que em média a peça é fabricada com temperatura de \\(70\\)°C e variância de \\(2(^oC)^2\\), como poderíamos representar essas medidas na escala Fahrenheit?\n\n\n\nExercício 4.5Se tivéssemos estudando a variável temperatura em três escalas: graus Celsius, Fahrenheit e Kelvin, poderíamos calcular o coeficiente de variação para as três escalas? Explique.\n\n\n\nExercício 4.6Considere uma amostra \\(X_1\\), \\(X_2\\), \\(\\dots\\), \\(X_n\\) de tamanho \\(n\\), do qual conseguimos computar a média aritmética e variância amostral, sendo representadas por \\(\\bar{X}_n\\) e \\(S^2_n\\), respectivamente, e que esses índices representam que estas medidas foram calculadas baseadas em um tamanho de amostra \\(n\\). Por alguma situação precisamos adicionar mais uma variável a esta amostra, isto é, a variável \\(X_{n+1}\\). Como poderíamos calcular as medidas \\(\\bar{X}_{n+1}\\) e \\(S^2_{n+1}\\), partindo do pressuposto que só sabemos das informações \\(\\bar{X}_n\\), \\(S^2_n\\) e \\(X_{n+1}\\)? Em um segundo momento considere o Exemplo 2.1, os dados sem agrupamento de classes, de modo que foi realizado uma nova medição da temperatura do anel de vedação no acionamento do foguete Challenger, sendo aferido o valor \\(x_{37}=63\\)ºF, use os resultados obtidos e determine \\(\\bar{x}_{n+1}\\) e \\(s^2_{n+1}\\) após desse novo dado as observações.\n\n\n\nExercício 4.7Considere uma amostra \\(X_1\\), \\(X_2\\), \\(\\dots\\), \\(X_n\\) de tamanho \\(n\\), do qual conseguimos computar as medidas de posição \\(\\bar{X}\\), \\(Md(X)\\) e \\(Mo(X)\\), isto é, a média, mediana e moda, respectivamente, bem como a variância \\(S^2_X\\). Considere também as transformações \\(Y_i = X_i - \\bar{X}\\) e \\(Z_i = (X_i - \\bar{X}) / S\\), para \\(i\\) \\(=\\) \\(1\\), \\(2\\), \\(\\ldots\\), \\(n\\), sendo \\(S = \\sqrt{S^2}\\). Apresente as medidas de dispersão, desvio padrão e variância, para essas transformações, \\(Y\\) e \\(Z\\).\n\n\n\nExercício 4.8De acordo com o Código R 4.2, percebemos que o cálculo da variância para as variáveis quantitativas discretas e contínuas apresentam resultados diferentes quando os dados são agrupados e não agrupados em distribuição de frequências. No caso das variáveis quantitativas discretas, agrupar ou não agrupar não faz diferença no resultado do cálculo da variância. Já para o caso das variáveis quantitativas contínuas os resultados se apresentam diferentes. Por que isso ocorre? Se fosse para escolher a medida de dispersão da variância para o caso das variáveis quantitativas contínuas, seria melhor apresentar o resultado dos resultados não agrupados ou agrupados? Apresente uma breve discussão sobre essas indagações.\n\n\n\n\n\n\nFERREIRA, D. F. Estatística Básica. 2 Revisada ed. Lavras: Editora UFLA, 2009. p. 664",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Medidas de dispersão</span>"
    ]
  },
  {
    "objectID": "cap04.html#footnotes",
    "href": "cap04.html#footnotes",
    "title": "4  Medidas de dispersão",
    "section": "",
    "text": "Entendemos por dados discrepantes, as observações que estão distantes da massa de dados (maior parte dos dados). Esses dados quando influenciam as análises estatísticas, dizemos que estes dados são influentes.↩︎\nEntendemos por estimador uma função que depende apenas dos dados amostrais e que irá representar um parâmetro (característica populacional) desconhecida.↩︎\nDizemos que um estimador é viesado se a esperança matemática desse estimador é diferente do parâmetro de interesse.↩︎",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Medidas de dispersão</span>"
    ]
  },
  {
    "objectID": "cap05.html",
    "href": "cap05.html",
    "title": "5  Probabilidades",
    "section": "",
    "text": "5.1 Introdução\nApós finalizarmos as principais ideias sobre a Estatística Descritiva, Capítulos 1 a 4, iniciamos o assunto de probabilidade, como passos iniciais para a tomada de decisão por meio dos dados. Para isto, usaremos a Estatística Inferencial (Teoria da Estimação e Teoria da decisão), assuntos vistos nos Capítulos 9 e 10. Contudo, é imprescindível uma fundamentação teórica sobre a probabilidade, base para a tomada de decisão.\nA probabilidade vem aparecer como ramo da matemática no século XV, embora tenha surgido antes desse período. Entretanto, somente no século XVI, é que a teoria da probabilidade passa a ser estudada com profundidade, quando Jerónimo Cardano (1501-1576) passa a estudar problemas com os jogos de azar: cartas, dados, etc. Os jogadores de cassinos, tentavam encontrar meios de obter chances maiores de, por exemplo, ganhar um jogo, acertar um número ou uma carta. Daí surge a probabilidade para resolver esses problemas por meio dos matemáticos.\nJá a estatística inicialmente, tentava identificar determinados problemas do Estado, como o número de nascidos e de mortos, determinação do número de pessoas do sexo masculino e feminino, etc. Entretanto, apenas no início do século XX é que a probabilidade e a estatística passam a ser interligadas, isto é, a estatística agora necessita de técnicas probabilísticas para o estudo de dados.\nHoje, a Estatística tem como um dos objetivos entender características atribuíveis a população de estudo. Com um subconjunto (amostra) da população, a estatística tenta se aproximar dessas características (parâmetros) por meio da inferência, através dos estimadores (características atribuíveis a amostra). Entretanto, se basear numa amostra para entender a população, gera uma incerteza. E essa incerteza é medida por meio da teoria da probabilidade, pela qual toda a estatística é desenvolvida.\nInicialmente, faremos uma revisão sobre Teoria de conjuntos, já usando termos específicos dentro da probabilidade, como por exemplo, a definição de um Experimento aleatório, dentre outras. Isso porque se faz necessário o entendimento sobre o agrupamento de elementos, e a chance com que esses elementos podem ocorrer em um experimento.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Probabilidades</span>"
    ]
  },
  {
    "objectID": "cap05.html#teoconj",
    "href": "cap05.html#teoconj",
    "title": "5  Probabilidades",
    "section": "5.2 Introdução à teoria de conjuntos no contexto probabilístico",
    "text": "5.2 Introdução à teoria de conjuntos no contexto probabilístico\nQuando desejamos compreender algum fenômeno da natureza, tentamos estudá-lo por meio de um processo de observação chamado experimento. Para isso, definimos um experimento aleatório, Definição 5.1, a seguir.\n\nDefinição 5.1: Experimento AleatórioTodo experimento cujo resultado não pode ser previsto antes de sua execução, é chamado de experimento aleatório.\n\n\nVejamos os Exemplos 5.1, 5.2 e 5.3 para exemplificar um experimento aleatório.\n\nExemplo 5.1Lançar um dado equilibrado e observar o resultado obtido na face superior do dado.\n\n\n\nExemplo 5.2Observar o número de chamadas telefônicas que chegam a uma central telefônica em um determinado intervalo de tempo.\n\n\n\nExemplo 5.3Para a escolha ao acaso de uma lâmpada que acabou de sair do processo de fabricação, verificar o tempo de duração da lâmpada em funcionamento.\n\n\nEm um contexto aplicado, podemos nos interessar em estudar a resistência de um fio de cobre a uma determinada corrente. Para isso, replicamos diversas vezes esse fenômeno e medimos a resistência. Este é um exemplo do que chamamos de experimento. Para que esse experimento não tenha resultados inconsistentes, usamos muitas vezes um laboratório para tentar controlar outras variáveis que possam perturbar o experimento, isto é, medimos a resistência do fio, de modo que a maior influência dessa variável para o experimento, seja devida a corrente aplicada ao final. Por mais que limitemos as condições externas do experimento, surgem sempre variáveis não controláveis ao sistema que foge do controle do pesquisador nesses casos, que são as variáveis não controláveis, Figura 5.1. Por mais que repliquemos o experimento, em mesmas condições, veremos que a medida da resistência do fio não será igual, devido a essas variáveis não controláveis, e que isso reflete em um componente aleatório, e por consequência, dizemos que estes tipos de experimentos são chamados de experimentos aleatórios.\n\n\n\n\n\n\nFigura 5.1: Componente aleatória de um experimento aleatório.\n\n\n\nBaseado, nos exemplos anteriores, percebemos pelo Exemplo 5.1, que não sabemos de fato qual o número da face superior que ocorrerá após o lançamento do dado. Mas sabemos, quais os resultados possíveis, que são: \\(1\\), \\(2\\), \\(3\\), \\(4\\), \\(5\\) e \\(6\\). O conjunto de todos esses resultados, chamaremos de Espaço amostral, apresentado na Definição 5.2, a seguir.\n\nDefinição 5.2: Espaço amostralO conjunto de todos os resultados possíveis de um experimento, denotado por \\(\\Omega\\), é chamado de espaço amostral.\n\n\nCada um dos elementos do espaço amostral é representado por \\(\\omega\\). Na Definição 5.5, apresentaremos o significado de evento. Contudo, podemos antecipar como um subconjunto de \\(\\Omega\\). Assim, diremos que um determinado evento ocorrerá se o resultado do experimento estiver nesse evento. Existem duas relações entre eventos que usaremos constantemente ao longo do conteúdo, que são:\n\nContinência: \\(A \\subset B \\Leftrightarrow \\omega \\in A \\Rightarrow \\omega \\in B\\);\nEquivalência: \\(A = B \\Leftrightarrow A \\subset B \\textrm{ e } B \\subset A\\).\n\nE que fique claro, a relação de elemento para conjunto é de pertinência, isto é, \\(\\omega \\in A\\). Significa que \\(\\omega\\) é um elemento pertencente (ou membro) de \\(A\\). A relação entre conjuntos é uma relação de continência, isto é, \\(A \\subset B\\), significando que todo elemento de \\(A\\) é também elemento de \\(B\\).\nDe forma mais abrangente, poderíamos apresentar a relação da equivalência da seguinte forma:\n\nContinência: \\(A \\subseteq B\\).\n\nEsta representa difere da situação anterior da seguinte forma:\n\ndizemos que \\(A \\subset B\\), implica que \\(A\\) é um subconjunto estrito de \\(B\\), e que \\(B\\) contém pelo menos um elemento \\(\\omega\\) que não pertence a \\(A\\), logo \\(A\\) não pode ser igual \\(B\\);\ndizemos que \\(A \\subseteq B\\), implica que \\(A\\) é um subconjunto de \\(B\\), podendo \\(A\\) ser igual ou não \\(B\\), isto é, todos os elementos de \\(A\\) podem pertencer a \\(B\\) ou \\(B\\) pode ter elementos adicionais que não pertencem a \\(A\\), e daí \\(A\\) pode não ser igual a \\(B\\).\n\nRetornando a Definição 5.2, podemos apresentar um outro espaço amostral, para o experimento dado no Exemplo 5.4, a seguir.\n\nExemplo 5.4Um experimento lança três moedas honestas, e desejamos verificar a face superior dessas moedas. Sabemos que cada moeda apresenta duas faces: cara (H) e coroa (T). Dessa forma, o espaço amostral é dado por: \\[\\begin{eqnarray*}\n\\Omega&=&\\{(H,H,H),(H,H,T),(H,T,H),(H,T,T),\\\\\n&&(T,H,H),(T,H,T),(T,T,H),(T,T,T)\\}.\n\\end{eqnarray*}\\]\n\n\nContudo, como apresentamos a natureza das variáveis no Capítulo 1, definimos também a natureza dos espaços amostrais de acordo os seus resultados, do qual podemos apresentá-la na Definição 5.3.\n\nDefinição 5.3: Espaços amostrais discretos e contínuosUm espaço amostral é discreto se o conjunto dos possíveis resultados são finito ou infinito contável (ou enumerável). Um espaço amostral é dito contínuo se o conjunto dos possíveis resultados são infinitos não contável (ou não enumerável) .\n\n\nVejamos o Exemplo 5.5, retirado de Montgomery e Runger (2016), para distinguir espaços amostrais discretos e contínuos, apresentado a seguir.\n\nExemplo 5.5: Câmera FlashConsidere um experimento em que é selecionado uma câmera de telefone celular e se registra o tempo de recarga de um flash. Os resultados possíveis para o tempo dependem da resolução do temporizador e dos tempos máximo e mínimo de recarga. Entretanto, podemos definir inicialmente o espaço amostral em termos da reta real positiva (\\(\\mathbb{R}_+\\)), isto é, \\[\\begin{align*}\n  \\Omega = \\mathbb{R}_+  & = \\{ x ~:~ x &gt; 0\\}.\n\\end{align*}\\] Se soubermos que os tempos de recarga estão entre \\(1,5\\) e \\(5\\) segundos, podemos definir o espaço amostral da seguinte forma: \\[\\begin{align*}\n  \\Omega  & = \\{ x ~:~ 1,5 \\leq x \\leq 5\\}.\n\\end{align*}\\] Caso, consideremos o tempo de recarga como baixo, médio ou alto, reescrevemos o espaço amostral como: \\[\\begin{align*}\n  \\Omega & =  \\{baixo,~\\textrm{\\emph{médio}},~alto\\}.\n\\end{align*}\\] Por fim, podemos considerar apenas o fato da câmera satisfazer ou não as especificações do tempo de recarga mínimo, e assim, podemos assumir como resultados para esse espaço amostral: sim ou não, isto é, \\[\\begin{align*}\n  \\Omega & =  \\{sim,~\\textrm{\\emph{não}}\\}.\n\\end{align*}\\] Para as duas primeiras situações, temos exemplos de espaços amostrais contínuos, e nos dois últimos, exemplos de espaços amostrais discretos.\n\n\nEntretanto, também podemos ter um conjunto qualquer \\(A\\), que contém parte do elementos de \\(\\Omega\\), isto é, \\(A \\subset \\Omega\\), e que \\(A\\) passa a ser chamado de subconjunto de \\(\\Omega\\), apresentado na Definição 5.4.\n\nDefinição 5.4: SubconjuntoSe todo elemento do conjunto A é também elemento do conjunto B, então A é definido como um subconjunto de B, sendo representado \\(A\\subset B\\) ou \\(B\\supset A\\) (A está contido em B ou B contém A), em notação dizemos que: \\[\\begin{align*}\n  A \\subset B \\Leftrightarrow A \\subseteq B \\textrm{ e } A \\neq B.\n\\end{align*}\\]\n\n\nEssa definição pode ser aplicada também a subconjuntos de \\(\\Omega\\), como apresentado no Exemplo 5.6, a seguir.\n\nExemplo 5.6Sejam os subconjuntos de \\(\\Omega\\) do experimento aleatório apresentado no Exemplo 5.1, dos quais temos: \\[\nB=\\{1,2,3,4\\} \\ \\mbox{e} \\ A=\\{1,2,3\\},\n\\] então A é um subconjunto de B, pois, os elementos que contém em A, também contém em B.\n\n\n\nDefinição 5.5: EventoTodo subconjunto do espaço amostral (\\(\\Omega\\)), representado por letras latinas em maiúsculo, A, B, \\(\\ldots\\), é chamado de evento.\n\n\nVejamos o Exemplo 5.7, para um entendimento inicial sobre um evento, apresentado a seguir.\n\nExemplo 5.7Um evento retirado do espaço amostral do Exemplo 5.4 seria \\(A=\\{(H,H,H)\\), \\((H,H,T)\\), \\((H,T,T)\\}\\), ou seja, o evento em que dos três arremessos de moedas, tenha saído “cara” na primeira moeda.\n\n\nUm outro exemplo abordado em James (2004), pode exemplificar um evento dentro do círculo unitário, apresentado no Exemplo 5.8, a seguir.\n\nExemplo 5.8\nEscolher ao acaso um ponto no círculo de raio 1 centrado na origem. Então \\[\\begin{align*}\n      \\Omega & = \\textrm{círculo unitário } = \\{(x,y) \\in \\mathbb{R}^2:~ x^2 + y^2 \\leq 1\\}.\n    \\end{align*}\\] Vejamos alguns eventos para esse exemplo: \\[\\begin{align*}\n      A & = \\textrm{``distância entre o ponto escolhido e a origem é'' } \\leq 1/2 \\\\\n      B & = \\textrm{``distância entre o ponto escolhido e a origem é'' } \\geq  15\\\\\n      C & = \\textrm{``1ª Coordenada do ponto escolhido é maior que a 2ª}.\n    \\end{align*}\\] Se \\(\\omega = (x,y)\\) for um resultado do experimento, então \\(\\omega\\) pertencerá a \\(A\\) se, e somente se, \\(x^2 + y^2 \\leq 1/4\\). Pertencerá ao evento C se, e somente se, \\(x &gt; y\\). Nenhum ponto \\(\\omega\\) pertencerá a \\(B\\), como pode ser observado pela Figura 5.2. Logo, temos: \\[\\begin{align*}\n      A & =\\{(x,y) \\in \\Omega:~ \\sqrt{x^2 + y^2} \\leq 1/2\\}, \\\\\n      B & =\\emptyset = \\textrm{conjunto vazio}, \\\\\n      A & =\\{(x,y) \\in \\Omega:~ x &gt; y\\}. \\\\\n    \\end{align*}\\] Então, todo evento associado a este experimento pode ser identificado por um subconjunto do espaço amostral.\n\n\n\n\n\n\n\n\n\n\n\n(a) Evento A\n\n\n\n\n\n\n\n\n\n\n\n(b) Evento B\n\n\n\n\n\n\n\nFigura 5.2: Escolha do ponto em um círculo unitário.\n\n\n\n\n\nDiante, do que falamos sobre a definição de evento, podemos apresentar três eventos básicos: o evento certo, impossível e o elementar, apresentados na Definição 5.6, a seguir.\n\nDefinição 5.6: Evento certo, impossível e elementarSeja \\(\\Omega\\) o espaço amostral do experimento. Então dizemos que \\(\\Omega\\) é o evento certo, e \\(\\emptyset\\) é o evento impossível, e o evento \\(\\{\\omega\\}\\) é dito elementar.\n\n\nUma outra forma de definir o evento impossível é representá-lo como um conjunto vazio, apresentado na Definição 5.7, a seguir.\n\nDefinição 5.7: Conjunto VazioSe o conjunto A não contém nenhum elemento, então A é chamado de conjunto nulo ou conjunto vazio, ou seja, \\(A=\\varnothing\\) ou \\(A=\\{ \\ \\}\\), isto é, \\[\n\\begin{align}\n  A & = \\{\\omega \\in \\Omega: \\omega \\neq \\omega \\}.\n\\end{align}\n\\tag{5.1}\\]\n\n\nPodemos perceber que todo conjunto vazio é um subconjunto de qualquer evento não vazio do espaço amostral, como pode ser apresentado no Teorema 5.1.\n\nTeorema 5.1Considere o conjunto vazio, \\(\\emptyset\\), e um evento não vazio, \\(A\\), definido no espaço amostral, \\(\\Omega\\). Então \\(\\emptyset \\subseteq A\\).\n\n\n\nProvaVamos realizar a prova por contradição. Supomos que \\(\\emptyset {\\not\\subseteq} A\\). Isso significa que \\(\\exists \\omega: \\omega \\in \\emptyset \\textrm{ e } \\omega \\notin A\\), porém \\(\\omega \\in \\emptyset\\) é um absurdo, logo \\(\\emptyset \\subseteq A\\), o que conclui a prova.\n\n\nE ainda podemos concluir que se existe um conjunto vazio, ele é único, como pode ser apresentado no Corolário 5.1.\n\nCorolário 5.1Existe somente um conjunto vazio.\n\n\n\nProvaSuponha que exista dois conjuntos vazios, \\(\\emptyset_1\\) e \\(\\emptyset_2\\). Pelo Teorema 5.1, sabemos que \\(\\emptyset_1 \\subseteq \\emptyset_2\\), uma vez que \\(\\emptyset_1\\) é um conjunto vazio. Mas, também sabemos que \\(\\emptyset_2 \\subseteq \\emptyset_1\\), uma vez que \\(\\emptyset_2\\) é um conjunto vazio. Logo, pela equivalência de conjuntos (eventos), Definição 5.12, \\(\\emptyset_1 = \\emptyset_2\\), o que conclui a prova.\n\n\nEm algumas situações, podemos apresentar alguns eventos a partir da combinação de outros eventos. Dessa forma, se faz necessário apresentar algumas operações elementares de conjuntos e suas consequências, tais como a união, interseção, complemento, dentre outras definições abordadas a seguir. Inicialmente, apresentamos na Definição 5.8, a união de dois eventos.\n\nDefinição 5.8: União de dois eventosSejam A e B, dois eventos quaisquer de \\(\\Omega\\), então o conjunto de todos os elementos que estão em A ou B ou em ambos, é definido como o conjunto união de A e B, denotado por \\(A\\cup B\\), tal que, \\[\n\\begin{align}\n  A\\cup B & = \\{\\omega \\in \\Omega: ~\\omega \\in A \\textrm{ ou } \\omega \\in B\\}.\n\\end{align}\n\\tag{5.2}\\]\n\n\nVejamos o Exemplo 5.9, sobre a união de dois eventos, a seguir.\n\nExemplo 5.9Sejam os conjuntos: \\[\n    A=\\{1,2,3\\} \\ \\mbox{e} \\ B=\\{3,4,5,6\\},\n    \\] então \\[\n    A\\cup B=\\{1,2,3,4,5,6\\}.\n    \\]\n\n\nA Definição 5.9 apresenta a próxima propriedade de conjuntos, que é a interseção de de eventos, apresentada a seguir.\n\nDefinição 5.9: Interseção de dois eventosSejam A e B, dois eventos quaisquer de \\(\\Omega\\), então o conjunto que contém todos os elementos que estão em A e B, é definido como a interseção de A e B, denotado por \\(A\\cap B\\) ou \\(AB\\), tal que, \\[\n\\begin{align}\n  A \\cap B & = \\{\\omega \\in \\Omega: ~\\omega \\in A \\textrm{ e } \\omega \\in B\\}.\n\\end{align}\n\\tag{5.3}\\]\n\n\nDo Exemplo 5.9, temos que a intersecção de \\(AB = \\{3\\}\\).\n\nDefinição 5.10: Eventos Disjuntos ou mutuamente exclusivosSejam A e B, dois eventos quaisquer de \\(\\Omega\\), então estes são disjuntos ou mutuamente exclusivos quando não existir elementos em comum entre A e B, isto é, \\(A\\cap B = \\emptyset\\).\n\n\nVejamos o Exemplo 5.10, para entendermos sobre eventos disjuntos, apresentado a seguir.\n\nExemplo 5.10Sejam os eventos \\(A=\\{1,2,3,4\\}\\) e \\(B=\\{5,6\\}\\), então \\(A\\cap B=\\varnothing\\)\n\n\nEm seguida, apresentamos mais duas definições interessantes, que são os eventos coletivamente exaustivos (Definição 5.11) e eventos equivalentes (Definição 5.12), apresentados na sequência.\n\nDefinição 5.11: Eventos coletivamente exaustivosConsidere um conjunto de eventos em \\(\\Omega\\), se ao menos um evento ocorrer durante um dado experimento, dizemos que esses eventos são coletivamente exaustivos.\n\n\nNa sequência, segue a definição sobre eventos equivalentes.\n\nDefinição 5.12: Eventos equivalentesDois eventos \\(A\\) e \\(B\\) são definidos equivalentes, ou iguais, se \\(A\\subseteq B\\) e \\(B \\subseteq A\\).\n\n\n\nExemplo 5.11Sejam os conjuntos: \\[\nB=\\{1,2,3\\} \\ \\mbox{e} \\ A=\\{1,2,3\\},\n\\] então \\(A\\) é igual a \\(B\\), pois \\(A\\subset B\\) e \\(B \\subset A\\).\n\n\nUma relação de eventos que será muito importante para o estudo da teoria da probabilidade, é a definição de complemento, abordado a seguir.\n\nDefinição 5.13: Evento ComplementarSeja \\(A\\) um evento de \\(\\Omega\\). Então o complemento do evento A com respeito a \\(\\Omega\\), denotado por \\(\\overline{A}\\), \\(A^c\\), ou \\(\\Omega-A\\), é o subconjunto dos elementos de \\(\\Omega\\) exceto os elementos do evento A, isto é, \\[\n\\begin{align}\n  A^c & = \\{\\omega \\in \\Omega: ~ \\omega \\notin A\\}.\n\\end{align}\n\\tag{5.4}\\]\n\n\n\nExemplo 5.12Seja o espaço amostral \\(\\Omega\\) do experimento que consiste em arremessar três moedas honestas. Diremos que \\(H\\) consiste na face superior da moeda ser cara, e \\(T\\) coroa. Assim \\[\\begin{eqnarray*}\n\\Omega&=&\\{(H,H,H),(H,H,T),(H,T,H),(H,T,T),\\\\\n&&(T,H,H),(T,H,T),(T,T,H),(T,T,T)\\}.\n\\end{eqnarray*}\\] e um subconjunto de \\(\\Omega\\), cujo evento será aparecer cara na primeira moeda, dado por \\[A=\\{(H,H,H),(H,H,T),(H,T,H), (H,T,T)\\}.\\] Então o complemento de A será: \\[\\overline{A}=\\{(T,H,H),(T,H,T), (T,T,H), (T,T,T)\\}.\\]\n\n\n\nDefinição 5.14: Diferença de dois eventosSejam A e B dois eventos de \\(\\Omega\\). O conjunto de todos os elementos de \\(A\\) que não estão em \\(B\\), serão denotados por \\(A-B\\) ou \\(A\\setminus B\\), sendo definido por conjunto diferença, isto é, \\[\n\\begin{align}\n  A - B & = \\{\\omega \\in \\Omega: ~\\omega \\in A \\textrm{ e } \\omega \\notin B\\}.\n\\end{align}\n\\tag{5.5}\\]\n\n\nA Definição 5.14 pode ser confundida com a Definição 5.13, porém esta última se remete ao espaço amostral, e a diferença entre dois eventos se refere apenas a existência dos elementos de um evento que não estão em outro evento. Vejamos o Exemplo 5.13, e depois compare com o Exemplo 5.12, para elucidar essas duas definições.\n\nExemplo 5.13Sejam os conjuntos \\(A=\\{1,2,3,4\\}\\) e \\(B=\\{3,4\\}\\), então \\(A-B=\\{1,2\\}\\).\n\n\nPor fim, uma última definição é a partição de conjuntos, apresentado na Definição 5.15, a seguir.\n\nDefinição 5.15: Partição de \\(A\\)\nConsiderando uma sequência de eventos \\(\\{A_i\\}_{i = 1}^{n}\\)1, não vazios, é uma partição do evento \\(A\\), se e somente se,\n\n\\(A = \\bigcup_{i = 1}^{n}A_i\\);\n\\(\\{A_i\\}_{i = 1}^{n}\\) são mutuamente disjuntos, tais que \\(A_i \\cap A_j, ~\\forall i \\neq j\\).\n\n\n\nConsiderando que \\(A = \\Omega\\), dizemos que temos uma . A seguir, apresentamos algumas leis importantes para a teoria de conjuntos, que estabelece algumas propriedades. Vejamos o Teorema 5.2.\n\nTeorema 5.2\nConsidere três eventos \\(A\\), \\(B\\), e \\(C\\) definidos em \\(\\Omega\\), então segue que:\n\nLei comutativa: \\(A\\cup B = B \\cup A\\) e \\(A\\cap B = B \\cap A\\);\nLei associativa: \\(A \\cup (B\\cup C)=(A\\cup B)\\cup C\\);\nLei distributiva: \\(A \\cup (B \\cap C)=(A\\cup B)\\cap (A\\cup C)\\) e \\(A \\cap (B \\cup C)=(A\\cap B)\\cup (A\\cap C)\\);\nLei DeMorgan: \\((A \\cup B)^c = A^c \\cap B^c\\) e \\((A \\cap B)^c = A^c \\cup B^c\\).\n\n\n\n\nProva\nPara provar que dois conjuntos são iguais, devemos demonstrar que todo elemento que está em um conjunto, também está no outro, e vice-versa.\n\nSupomos que \\(\\omega \\in A \\cup B\\), portanto, \\(\\omega \\in A \\textrm{ ou } \\omega \\in B\\). Logo, \\(\\omega \\in B \\cup A\\). Da mesma forma, supomos que \\(\\omega \\in B \\cup A\\), portanto, \\(\\omega \\in B \\textrm{ ou } \\omega \\in A\\). Logo, \\(\\omega \\in A \\cup B\\). De forma resumida, podemos expressar essa prova da seguinte forma: \\(\\omega \\in A \\cup B \\Leftrightarrow \\omega \\in A \\textrm{ ou } \\omega \\in B \\Leftrightarrow \\omega \\in B \\cup A\\); Para a outra parte da prova, supomos que \\(\\omega \\in A \\cap B\\), portanto, \\(\\omega \\in A \\textrm{ e } \\omega \\in B\\). Logo, \\(\\omega \\in B \\cap A\\). Da mesma forma, supomos que \\(\\omega \\in B \\cap A\\), portanto, \\(\\omega \\in B \\textrm{ e } \\omega \\in A\\). Logo, \\(\\omega \\in A \\cap B\\). De forma resumida, podemos expressar essa prova da seguinte forma: \\(\\omega \\in A \\cap B \\Leftrightarrow \\omega \\in A \\textrm{ e } \\omega \\in B \\Leftrightarrow \\omega \\in B \\cap A\\), o que finaliza a prova da Lei comutativa;\nSupomos que \\(\\omega \\in A \\cup (B\\cup C)\\), portanto, \\(\\omega \\in A \\textrm{ ou } \\omega \\in B \\cup C\\), e que isso implica em \\(\\omega \\in A \\cup B \\textrm{ ou } \\omega \\in C\\). Logo, \\(\\omega \\in (A \\cup B) \\cup C\\). Da mesma forma, supomos que \\(\\omega \\in (A \\cup B) \\cup C\\), portanto, \\(\\omega \\in A \\cup B \\textrm{ ou } \\omega \\in C\\), e que isso implica em \\(\\omega \\in A \\textrm{ ou } \\omega \\in B \\cup C\\). Logo, \\(\\omega \\in A \\cup (B\\cup C)\\). De forma resumida, podemos expressar essa prova da seguinte forma: \\(\\omega \\in A \\cup (B\\cup C)\\) \\(\\Leftrightarrow \\omega \\in A\\) \\(\\textrm{ ou } \\omega \\in B \\cup C\\) \\(\\Leftrightarrow\\) \\(\\omega \\in A \\cup B \\textrm{ ou } \\omega \\in C\\) \\(\\Leftrightarrow\\) \\(\\omega \\in (A \\cup B) \\cup C\\), o que finaliza a prova da Lei associativa;\nSupomos que \\(\\omega \\in A \\cup (B \\cap C)\\), portanto, \\(\\omega \\in A \\textrm{ ou } \\omega \\in (B \\cap C)\\). Considerando que \\(\\omega \\in A\\), então \\(\\omega \\in (A \\cup B) \\textrm{ e } \\omega \\in (A \\cup C)\\), logo, \\(\\omega \\in (A \\cup B) \\cap (A \\cup C)\\). Considerando que \\(\\omega \\in (B \\cap C)\\), então \\(\\omega \\in B\\) e \\(\\omega \\in C\\). Logo, \\(\\omega \\in (A \\cup B) \\cap (A \\cup C)\\). Agora, assumimos que \\(\\omega \\in (A \\cup B)\\cap (A \\cup C)\\), portanto, \\(\\omega \\in (A \\cup B) \\textrm{ e } \\omega \\in (A \\cup C)\\). Isso significa que, ou \\(\\omega \\in A\\) ou \\(\\omega \\in (B \\cap C)\\), logo, \\(\\omega \\in A \\cup (B \\cap C)\\). Para a segunda parte, assumimos que \\(\\omega \\in A \\cap (B \\cup C)\\). Isso implica que \\(\\omega \\in A\\) e \\(\\omega \\in (B \\cup C)\\). Como \\(\\omega \\in A\\), então \\(\\omega \\in (A \\cap B)\\) e \\(\\omega \\in (A \\cap C)\\). Logo, \\(\\omega \\in (A \\cap B) \\cup (A \\cap C)\\). Agora, assumimos que \\(\\omega \\in (A \\cap B) \\cup (A \\cap C)\\), portanto, \\(\\omega \\in (A \\cap B)\\) ou \\(\\omega \\in (A \\cap C)\\). Se \\(\\omega \\in (A \\cap B)\\), então \\(\\omega\\) está em \\(A\\) e \\(B\\). Como \\(\\omega \\in B\\), então \\(\\omega \\in (B \\cup C)\\). Se \\(\\omega \\in (A \\cap C)\\), então \\(\\omega\\) está em \\(A\\) e \\(C\\). Como \\(\\omega \\in C\\), então \\(\\omega \\in (B \\cup C)\\). Logo, \\(\\omega \\in A \\cap (B \\cup C)\\), o que finaliza a prova da Lei distributiva.\nSupomos que \\(\\omega \\in (A \\cup B)^c\\), então \\(\\omega \\notin (A \\cup B)\\), isto é, \\(\\omega \\notin A\\) ou \\(\\omega \\notin B\\). Como \\(\\omega \\notin A\\) ou \\(\\omega \\notin B\\), então \\(\\omega \\in A^c\\) e \\(\\omega \\in B^c\\). Logo, \\(\\omega \\in A^c \\cap B^c\\). Agora, assumimos que \\(\\omega \\in A^c \\cap B^c\\). Isso implica que \\(\\omega \\in A^c\\) e \\(\\omega \\in B^c\\), de modo que ou \\(\\omega \\notin A\\) ou \\(\\omega \\notin B\\). Assim, \\(\\omega \\notin (A \\cup B)\\), e pela definição de evento complementar, concluímos que \\(\\omega \\in (A \\cup B)^c\\). De forma resumida, podemos expressar essa prova da seguinte forma: \\(\\omega \\in (A \\cup B)^c \\Leftrightarrow\\) \\(\\omega \\notin A \\textrm{ ou } \\omega \\notin B \\Leftrightarrow \\omega \\in A^c \\textrm{ e } \\omega \\in B^c \\Leftrightarrow \\omega \\in A^c \\cap B^c\\). Na segunda parte, assumimos que \\(\\omega \\in (A \\cap B)^c\\), então \\(\\omega \\notin (A \\cap B)\\). Assim, \\(\\omega \\notin A\\) e nem \\(\\omega \\notin B\\). Como consequência, \\(\\omega \\in A^c\\) ou \\(\\omega \\in B^c\\), logo \\(\\omega \\in A^c \\cup B^c\\). Da mesma forma, assumimos que \\(\\omega \\in A^c \\cup B^c\\), isto é, \\(\\omega \\in A^c\\) ou \\(\\omega \\in B^c\\). Isso implica que \\(\\omega \\notin (A \\cap B)\\). Usando a definição de evento complementar, logo \\(\\omega \\in (A \\cap B)^c\\), o que conclui a prova para a Lei DeMorgan. De forma resumida, podemos expressar essa prova da seguinte forma: \\(\\omega \\in (A \\cap B)^c \\Leftrightarrow \\omega \\notin (A \\cap B) \\Leftrightarrow\\) \\(\\omega \\notin A \\textrm{ e } \\omega \\notin B \\Leftrightarrow \\omega \\in A^c \\textrm{ ou } \\omega \\in B^c\\) \\(\\Leftrightarrow\\) \\(\\omega \\in A^c \\cup B^c\\).\n\n\n\nPara finalizar, apresentamos pelo Teorema 5.3, algumas identidades que serão importantes na teoria de conjuntos para o estudo sobre a probabildade.\n\nTeorema 5.3\nSejam os eventos \\(A\\) e \\(B\\) definidos no espaço amostral \\(\\Omega\\), não vazio. Então, apresentamos as seguintes identidades:\n\n\\(A\\cap A^c = \\emptyset\\);\n\\(A \\cup A^c = \\Omega\\);\n\\(\\Omega^c = \\emptyset\\);\n\\(\\emptyset^c = \\Omega\\);\n\\((A^C)^C=\\overline{(\\overline{A})}=A\\), em outras palavras, o complemento de \\(\\overline{A}\\) é igual a \\(A\\);\n\\(A\\Omega=A\\) (Elemento neutro);\n\\(A\\cup \\Omega=\\Omega\\);\n\\(A \\cap A = A\\) (Idempotência);\n\\(A\\varnothing=\\varnothing\\) (Elemento absorvente);\n\\(A\\cup \\varnothing = A\\);\n\\(A - B = A - (A \\cap B) = A \\cap B^c\\);\n\\(B = (B \\cap A) \\cup (B \\cap A^c)\\);\n\\(B - A = B \\cap A^c\\);\n\\(A \\cup B = A \\cup (B \\cap A^c)\\);\n\\(A \\cup B = (A^c \\cap B)\\cup (A \\cap B) \\cup (A \\cap B^c)\\).\n\n\n\n\nProva\nPara provar que dois conjuntos são iguais, devemos demonstrar que todo elemento que está em um conjunto, também está no outro, e vice-versa.\n\nVamos apresentar a prova por contradição. Suponha que \\(\\omega \\in A \\cap A^c \\neq \\emptyset\\), então \\(\\exists \\omega \\in A \\cap A^c: \\omega \\in A \\textrm{ e } \\omega \\in A^c\\). Mas por definição \\(A^c = \\{\\omega \\in \\Omega: \\omega \\notin A\\}\\), então a afirmação \\(\\exists \\omega \\in A \\cap A^c: \\omega \\in A \\textrm{ e } \\omega \\in A^c\\), é absurdo. Logo, \\(A \\cap A^c = \\emptyset\\). Vejamos a representação em diagrama de Venn, a seguir.\n\n\n\n\n\n\\(\\omega \\in A \\cup A^c \\Leftrightarrow \\omega \\in A \\textrm{ ou } \\omega \\in A^c \\Leftrightarrow \\omega \\in A \\textrm{ ou } \\omega \\notin A\\) \\(\\Leftrightarrow\\) \\(\\omega \\in \\Omega\\). Vejamos a representação em diagrama de Venn, a seguir.\n\n\n\n\n\nVamos apresentar a prova por contradição. Supomos que \\(\\Omega^c \\neq \\emptyset\\). Isso significa que \\(\\exists \\omega: \\omega \\in \\Omega^c \\textrm{ e } \\omega \\notin \\Omega\\), e isso é absurdo, pois \\(\\Omega\\) representa o conjunto de todos os resultados possíveis em um experimento. Logo, \\(\\Omega^c = \\emptyset\\);\nVamos provar por contradição. Supomos que \\(\\emptyset^c \\neq \\Omega\\). Isso implica que, \\(\\exists \\omega: \\omega \\in \\Omega \\textrm{ e }\\omega \\notin \\emptyset^c\\). Então, isso implica que \\(\\omega \\in \\emptyset\\), que é absurdo. Logo, \\(\\emptyset^c = \\Omega\\). Uma outra forma de apresentar essa prova é usar a definição de evento complementar, isto é, \\(A^c = \\Omega - A\\). Considerando \\(A = \\emptyset\\), então \\(\\emptyset^c = \\Omega - \\emptyset\\). Logo, \\(\\emptyset^c = \\Omega\\);\n\\(\\omega \\in (A^c)^c \\Leftrightarrow \\omega \\notin A^c \\Leftrightarrow \\omega \\in A\\);\n\\(\\omega \\in A \\cap \\Omega \\Leftrightarrow \\omega \\in A \\textrm{ e } \\omega \\in \\Omega \\Leftrightarrow \\omega \\in A\\), como pode ser observado pelo diagrama a seguir.\n\n\n\n\n\n\\(\\omega \\in A \\cup \\Omega \\Leftrightarrow \\omega \\in A \\textrm{ ou } \\omega \\in \\Omega \\Leftrightarrow \\omega \\in \\Omega\\), como pode ser visto no diagrama a seguir.\n\n\n\n\n\n\\(\\omega \\in A \\cap A \\Leftrightarrow \\omega \\in A \\textrm{ e } \\omega \\in A \\Leftrightarrow \\omega \\in A\\), como pode ser observado no diagrama a seguir.\n\n\n\n\n\nVamos apresentar a prova por contradição, isto é, vamos supor que \\(A \\cap \\emptyset \\neq \\emptyset\\), então \\(\\exists\\omega: \\omega \\in A \\cap \\emptyset\\). Assim, \\(\\omega \\in A\\) e \\(\\omega \\in \\emptyset\\). Porém, \\(\\omega \\in \\emptyset\\) é falso. Então \\(\\omega \\in A \\cap \\emptyset\\) é falso. Logo, \\(A \\cap \\emptyset = \\emptyset\\);\nConsiderando que \\(\\omega \\in A \\cup \\emptyset\\), então ou \\(\\omega \\in A\\) ou \\(\\omega \\in \\emptyset\\). Mas \\(\\omega \\in \\emptyset\\) é falso, logo \\(\\omega \\in A\\). Do mesmo modo se \\(\\omega \\in A\\), então \\(\\omega \\in A \\cup \\emptyset\\);\n\\(\\omega \\in (A - B)\\) \\(\\Leftrightarrow\\) \\(\\omega \\in\\) \\(A\\) \\(\\textrm{ e }\\) \\(\\omega\\notin B\\) \\(\\Leftrightarrow\\) \\(\\omega \\in A \\textrm{ e } \\omega \\notin (A \\cap B) \\Leftrightarrow A - (A \\cap B)\\). Da mesma forma, \\(\\omega \\in (A - B)\\) \\(\\Leftrightarrow\\) \\(\\omega \\in A\\) \\(\\textrm{ e }\\) \\(\\omega \\notin B \\Leftrightarrow \\omega \\in A \\textrm{ e } \\omega \\in B^c \\Leftrightarrow \\omega \\in A \\cap B^c\\). Vejamos o diagrama a seguir.\n\n\n\n\n\nConsiderando que \\(\\omega \\in B\\), então ou \\(\\omega \\in A\\) ou \\(\\omega \\in A^c\\). Se \\(\\omega \\in A\\), então \\(\\omega \\in (B \\cap A)\\). Se \\(\\omega \\in A^c\\), então \\(\\omega \\in (B \\cap A^c)\\). Logo, \\(\\omega \\in (B \\cap A)\\cup (B \\cap A^c)\\). Agora, considerando que \\(\\omega \\in (B \\cap A)\\cup (B \\cap A^c)\\), sabemos que \\(\\omega \\in (B \\cap A)\\) ou \\(\\omega \\in (B \\cap A^c)\\). Se \\(\\omega \\in (B \\cap A)\\), então \\(\\omega \\in B\\). Se \\(\\omega \\in (B \\cap A^c)\\), então \\(\\omega \\in B\\). Logo, \\(\\omega \\in B\\). Uma outra forma de provar mais facilmente essa identidade é usar a Lei distributiva (Teorema 5.2, III), isto é, \\((B \\cap A)\\cup (B \\cap A^c) = B \\cap (A \\cup A^c) = B \\cap \\Omega = B\\). Vejamos o diagrama de Venn para uma melhor elucidação, a seguir.\n\n\n\n\n\nBasta usar a propriedade VI desse teorema;\n\\(\\omega \\in (A \\cap B)\\) \\(\\Leftrightarrow\\) \\(\\omega \\in A \\textrm{ ou } \\omega \\in B\\) \\(\\Leftrightarrow\\) \\(\\omega \\in A \\textrm{ ou } \\omega \\in (B \\cap A^c)\\) \\(\\Leftrightarrow\\) \\(\\omega \\in A\\cup (B \\cap A^c)\\). Vejamos o diagrama a seguir.\n\n\n\n\n\n\\(\\omega \\in A \\cup B\\) \\(\\Leftrightarrow\\) \\(\\omega \\in A \\textrm{ ou } \\omega \\in B\\) \\(\\Leftrightarrow\\) \\(\\omega \\in (A \\cap B) \\textrm{ ou } \\omega \\in \\underbrace{(A^c \\cap B) \\cup (A \\cap B)}_{prop.~(XII)}\\) \\(\\Leftrightarrow\\) \\(\\omega \\in (A \\cap B) \\cup (A^c \\cap B) \\cup (A \\cap B)\\). Vejamos o diagrama a seguir.\n\n\n\n\n\n\nBaseado em tudo o que foi estudado sobre uma introdução à teoria de conjuntos, iremos a partir da próxima seção, contextualizar todas essas informações com o estudo sobre a medida de probabilidade.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Probabilidades</span>"
    ]
  },
  {
    "objectID": "cap05.html#defprobs",
    "href": "cap05.html#defprobs",
    "title": "5  Probabilidades",
    "section": "5.3 Definições de probabilidades",
    "text": "5.3 Definições de probabilidades\nApós um contexto sobre a teoria de conjuntos, iniciamos o contexto probabilístico, com o interesse de saber a chance de determinado elemento de um evento ocorrer como resultado de um experimento, ao invés de estar interessado nesse resultado. Isso tem total importância prática, pois é dessa forma, por exemplo, que prevemos determinados resultados de um fenômeno de interesse. Consideremos um evento \\(A\\) contido no espaço amostral \\(\\Omega\\), e desejamos associar ao evento \\(A\\) uma medida que assume valores entre 0 e 1, que chamamos de medida de probabilidade de \\(A\\), denotada por \\(P(A)\\). Assim, diremos que \\(P(A)\\) é a probabilidade de que o evento \\(A\\) ocorra no espaço amostral \\(\\Omega\\). De outro modo, a probabilidade do evento \\(A\\) representa a chance de ao menos um de seus elementos ocorrerem como resultado de um experimento. Voltando ao Exemplo 5.1, considerando que esse dado é equilibrado, e o evento \\(A\\subset \\Omega\\), então poderemos atribuir uma probabilidade para \\(A\\) da seguinte forma: \\[\\begin{align*}\n  P(A) & = \\frac{\\#A}{6} = \\frac{\\textrm{número de resultados favoráveis a }A}{\\textrm{número de resultados possíveis}}.\n\\end{align*}\\]\nEsta é a definição clássica de probabilidade quando \\(\\Omega\\) é finito. Entretanto, a probabilidade que o evento \\(A\\) ocorra no espaço amostral nem sempre é possível, devido a complexidade desses eventos. Retornando ao Exemplo 5.8, podemos interpretar a probabilidade de \\(A\\subset \\Omega\\) como: \\[\\begin{align*}\n  P(A) & = \\frac{\\textrm{área } A}{\\textrm{área }\\Omega} = \\frac{\\textrm{área } A}{\\pi},\n\\end{align*}\\] sendo a área de \\(A\\) bem definida. Segundo um teorema profundo da teoria da medida, não se pode definir \\(P(A)\\) para \\(A \\subset \\Omega\\) de modo que a área de \\(A\\) não esteja bem definida. A prova disso depende do Axioma da escolha. Um exemplo clássico desses eventos são os conjuntos de Vitali de \\(\\mathbb{R}\\), os quais não podemos atribuir nenhuma medida quando ela generaliza o comprimento de intervalos de \\(\\mathbb{R}\\). De fato é impossível atribuir comprimento a todos subconjuntos de \\(\\mathbb{R}\\) preservando a aditividade e invariância por translação.\nDessa forma, estaremos apenas interessados em eventos cuja área esteja bem definida, apresentada na Definição 5.16, a seguir.\n\nDefinição 5.16: Evento AleatórioTodo evento de \\(\\Omega\\) que podemos atribuir uma probabilidade, chamamos de evento aleatório.\n\n\nDefinimos a medida de probabilidade apresentada na Definição 5.17, a seguir.\n\nDefinição 5.17: Medida de Probabilidade\nSeja \\(\\Omega\\) o espaço amostral, então uma função \\(P\\), tal que \\(P:\\Omega \\to \\mathbb{R}\\), é chamada de medida de probabilidade ou probabilidade, aos eventos do espaço amostral satisfazendo os seguintes axiomas de Kolmogorov:\n\n(Normalização). \\(P(\\Omega)=1\\);\n(Não-negatividade). \\(0\\leq  P(A) \\leq 1\\), \\(\\forall \\ A \\subset \\Omega\\);\n(Aditividade). \\(P(A_1 \\cup A_2)=P(A_1) + P(A_2)\\), com \\(A_1 \\cap A_2 = \\emptyset\\), para \\(A_1, ~A_2 \\subset \\Omega\\).\n\n\n\nAssim como mencionado por Montgomery e Runger (2016), os axiomas não determinam probabilidades, mas capacitam a calcular facilmente as probabilidade de alguns eventos, a partir do conhecimento de outras probabilidades. Na realidade, a probabilidade se baseia no conhecimento do sistema em estudo.\nPoderíamos ampliar o Axioma} [\\(iii\\)], Definição 5.17, da seguinte forma:\nAxioma [iii\\(^*\\)]. (Aditividade finita). Se \\(\\{A_i\\}_{i = 1}^{n}\\) é uma sequência disjunta dois a dois de eventos em \\(\\Omega\\), então \\(P\\left(\\bigcup_{i = 1}^nA_i\\right)=\\sum^{n}_{ i = 1} P(A_i)\\).}\nPara isso, basta considerarmos \\(A_2 = \\bigcup_{i = 1}^{n-1}A_i\\). Para \\(n \\to \\infty\\), podemos generalizar esse Axioma da seguinte forma:\nAxioma [iii\\(^{**}\\)]. (\\(\\sigma\\)-Aditividade). Se \\(\\{A_i\\}_{i \\geq 1}\\)2 é uma sequência disjunta dois a dois em \\(\\Omega\\), então \\(P\\left(\\bigcup_{i = 1}^\\infty A_i\\right)=\\sum^{\\infty}_{ i = 1} P(A_i)\\).}\nPodemos verificar que o Axioma [iii\\(^{**}\\)] implica nos Axioma [iii\\(^{*}\\)] e [iii], apresentado no Teorema 5.4.\n\nTeorema 5.4: \\(\\sigma\\)-adivitividade implica em aditividade finitaO Axioma [iii\\(^{**}\\)] implica nos Axioma [iii\\(^{*}\\)] e [iii], isto é, se \\(P\\) é \\(\\sigma\\)-aditiva, então é finitamente aditiva.\n\n\n\nProvaSupondo satisfeito o Axioma [iii\\(^{**}\\)], seja uma sequência de eventos \\(\\{A_i\\}_{i = 1}^{n} \\subset \\Omega\\), e que \\(P(\\emptyset) = 0\\) (Teorema 5.6, \\(ii\\)), então\n\\[\\begin{align*}\n        P(\\Omega) = P(\\Omega \\cup \\emptyset \\cup \\emptyset \\cup \\ldots\n        ) = P(\\Omega) + P(\\emptyset) + P(\\emptyset) + \\ldots.\n\\end{align*}\\]\nDefinimos \\(A_i = \\emptyset\\), para \\(i = n + 1, n + 2, \\ldots\\). Como \\(A_1, A_2, \\ldots\\) são disjuntos, então\n\\[\\begin{align*}\n        P\\left(\\bigcup^{n}_{i = 1}A_i\\right)& = P\\left(\\bigcup^{\\infty}_{i = 1}A_k\\right)\\\\\n        & = \\sum^{\\infty}_{i = 1}P(A_i)\\\\\n        & = \\sum^{n}_{i = 1}P(A_i) + P(\\emptyset) + P(\\emptyset) + \\ldots\\\\\n        & = \\sum^{n}_{i = 1}P(A_i),\n\\end{align*}\\] o que conclui a prova.\n\n\nUm quarto Axioma, pode ser complementado sobre a medida de probabilidade James (2004), que segue:\nAxioma [iv]. (Continuidade do vazio). Se a sequência \\(\\{A_i\\}_{i \\geq 1}\\), em que \\(A_i \\subset \\Omega ~\\forall i \\in \\mathbb{N}^{+}\\), decrescer para o vazio, então \\(\\lim\\limits_{i \\to \\infty}P(A_i) \\to 0\\).\nEste axioma indica que se \\(\\{A_i\\}_{i \\geq 1}\\) decrescer para o vazio, isto é \\(A_i \\downarrow \\emptyset\\), significa que \\(A_i \\supset A_{i + 1}~\\forall i\\in \\mathbb{N}^{+}\\), ou seja, \\(\\{A_i\\}_{i \\geq 1}\\) decresce, e \\(\\bigcap_{i \\geq 1}A_i = \\emptyset\\).\n\nTeorema 5.5: Equivalência dos Axiomas [\\(iv\\)] e [\\(iii^{**}\\)]Dados os axiomas de Kolmogorov, Definição 5.17, o Axioma [iv] é equivalente ao Axioma [iii\\(^{**}\\)], isto é, uma probabilidade finitamente aditiva é uma probabilidade se, e somente se, é contínua no vazio.\n\n\n\nProva\n\nSupomos o Axioma [iii\\(^{**}\\)]. Seja uma sequência de eventos \\(\\{A_i\\}_{i \\geq 1} \\subset \\Omega\\), tais que \\(A_i \\downarrow \\emptyset\\). Vamos provar que \\(\\lim\\limits_{i \\to \\infty}P(A_i) \\to 0\\). Considere\n\n\\[\\begin{align*}\n        A_1 = (A_1 - A_2) \\cup (A_2 - A_3) \\cup \\ldots = \\bigcup_{i = 1}^{\\infty}(A_i - A_{i + 1}),\n\\end{align*}\\] pelo diagrama:\n\n\n\nAs regiões \\(A_i - A_{i + 1}\\) são disjuntas, uma vez que a sequência é decrescente. Considere também que \\(\\Omega\\) é fechado para diferenças. Pelo Axioma [iii\\(^*\\)], temos\n\\[\\begin{align*}\n        P(A_1) &  = P\\left(\\bigcup^{\\infty}_{i = 1}(A_i - A_{i + 1})\\right) = \\sum_{i = 1}^{\\infty} P(A_i - A_{i + 1}),\n\\end{align*}\\] portanto a série é convergente e \\[\\begin{align*}\n    \\sum_{i = 1}^{\\infty} P(A_i - A_{i + 1}) & = \\sum_{i = 1}^{n - 1} P(A_i - A_{i + 1}) + P(\\emptyset) + P(\\emptyset) + P(\\emptyset) + \\ldots\\\\\n        & = \\sum_{i = 1}^{n - 1} P(A_i - A_{i + 1}) \\stackrel[n \\to \\infty]{}{\\to} P(A_1).\n\\end{align*}\\] Pela aditividade finita, \\[\\begin{align*}\n        P(A_i - A_{i + 1}) & = P(A_i) - P(A_{i + 1}),\n\\end{align*}\\] e portanto, \\[\\begin{align*}\n        P(A_1) & = \\lim\\limits_{n \\to \\infty}\\sum_{i = 1}^{n - 1}[P(A_i) - P(A_{i + 1})]\\\\\n        & = \\lim\\limits_{n \\to \\infty}\\left\\{[P(A_1) - P(A_2)] + [P(A_2) - P(A_3)] + \\ldots \\right. \\\\\n        & \\quad \\left. \\ldots + [P(A_{n-1}) - P(A_n)]\\right\\}\\\\\n        & = \\lim\\limits_{n \\to \\infty}\\left[P(A_1) - \\centernot{\\color{red}{P(A_2)}} + \\centernot{\\color{red}{P(A_2)}} - \\centernot{\\color{red}{P(A_3)}} + \\ldots \\right.\\\\\n        & \\quad \\left. \\ldots + \\centernot{\\color{red}{P(A_{n-1})}} - P(A_n)\\right]\\\\\n        & = \\lim\\limits_{n\\to \\infty} [P(A_1) - P(A_n)],\n\\end{align*}\\] Logo, \\(P(A_n) \\to 0\\).\n\nSupomos o Axioma [iv] e seja a sequência decrescente \\(\\{A_i\\}_{i \\geq 1}\\) de eventos disjuntos. Vamos provar que \\(P\\left(\\bigcup_{i = 1}^{\\infty}A_k\\right) = \\sum_{i = 1}^{\\infty}P(A_i)\\). Seja \\(A = \\bigcup_{i = 1}^{\\infty}A_i\\), então\n\n\\[\\begin{align*}\n        A &  = \\left(\\bigcup_{i = 1}^{n}A_i \\right)\\cup \\left(\\bigcup_{i = n + 1}^{\\infty}A_i \\right)\n\\end{align*}\\] e como a \\(\\sigma\\)-aditividade implica em aditividade finita, Teorema 5.4, temos que \\[\\begin{align*}\n        P(A) & = \\sum_{i = 1}^{n}P(A_i) + P\\left(\\bigcup_{i = n + 1}^{\\infty}A_i \\right).\n\\end{align*}\\] Seja \\(B_n = \\bigcup_{i = n + 1}^{\\infty}A_i\\), então \\(B_n\\downarrow \\emptyset\\) e portanto \\(P(B_n) \\to 0\\) (Pelo Axioma [iv]). Logo, \\[\\begin{align*}\n    \\sum_{i = 1}^{n}P(A_i)& \\stackrel[n \\to \\infty]{\\rightarrow}{}P(A),\n\\end{align*}\\] isto é, \\(P(A) = \\sum_{i = 1}^{\\infty}P(A_k)\\), como queríamos demonstrar.\n\n\nPor fim, o Corolário 5.2 apresenta as relações entre os Axiomas apresentados sobre a medida de probabilidade, a seguir.\n\nCorolário 5.2\nOs dois seguintes sistemas de axiomas são equivalentes:\n\n\n\n\n\n\n\nSistema I:\nAxiomas [i], [ii], [iii\\(^{**}\\)],\n\n\nSistema II:\nAxiomas [i], [ii], [iii\\(^{*}\\)] e [iv].\n\n\n\n\n\n\nProvaO sistema I é equivalente aos Axiomas [i], [ii], [iii\\(^{*}\\)] e [iii\\(^{**}\\)], pois já vimos que o Axiomas [iii\\(^{**}\\)] implica no Axiomas [iii\\(^{*}\\)], Teorema 5.4. Agora, usando o Teorema 5.5, provamos que o Axioma 3 implica no Axioma 4, e a prova é concluída.\n\n\nVejamos o Exemplo 5.14, para elucidar a definição de probabilidade, a seguir.\n\nExemplo 5.14: Montgomery e Runger (2016)Uma peça moldada de injeção é igualmente provável de ser obtida, a partir de qualquer uma das oito cavidades de um molde.\n\nQual é o espaço amostral?\nQual é a probabilidade de a peça ser proveniente da cavidade 1 ou 2?\nQual é a probabilidade de a peça não ser proveniente nem da cavidade 3 nem da 4?\n\nNesse caso, (a) o espaço amostral é \\(\\Omega = \\{1, 2, 3, 4, 5, 6, 7, 8\\}\\). Como a peça moldada de injeção é igualmente provável, então (b) a probabilidade de a peça ser proveniente da cavidade 1 ou 2, é dada por: \\[\\begin{align*}\n  P(\\{1\\} \\cup \\{2\\}) & = P(\\{1\\}) + P(\\{2\\}), \\quad \\textrm{(Eventos disjuntos)}\\\\\n                      & = 1 / 8 + 1 / 8\\\\\n                      & = 2 / 8.\n\\end{align*}\\] Por fim, (c) a probabilidade de a peça não ser proveniente nem da cavidade 3 nem da 4, é dada por: \\[\\begin{align*}\n  P(\\{3\\}^c \\cap \\{4\\}^c) & = P[(\\{3\\} \\cup \\{4\\})^c], \\quad \\textrm{(Lei DeMorgan}\\\\\n                          & = 1 - P(\\{3\\} \\cup \\{4\\}), \\quad \\textrm{(Evento complementar)}\\\\\n                          & = 1 - [P(\\{3\\}) + P( \\{4\\})], \\quad \\textrm{(Eventos disjuntos)}\\\\\n                          & = 1 - [1 / 8 + 1 /8]\\\\\n                          & = 1 - 2 /8\\\\\n                          & = 6 / 8.\n\\end{align*}\\]\n\n\nO ítem (c) do Exemplo 5.14 exigiria um conhecimento sobre algumas propriedades da medida de probabilidade como consequência das propriedades da teoria de conjuntos abordadas na seção anterior, mas que serão abordadas a seguir.\nApesar da definição formal sobre a probabilidade, há duas formas para atribuir probabilidades aos elementos do espaço amostral, que em algumas situações são aplicáveis, que seguem:\n\nA primeira delas, consiste na atribuição de probabilidades, baseando-se em características teóricas da realização do fenômeno, chamado de probabilidade clássica ou a priori; formalmente, se um experimento aleatório obtiver resultados mutuamente exclusivos e igualmente prováveis, e se \\(n_A\\) desses resultados têm um atributo \\(A\\), então, a probabilidade de acontecer \\(A\\) é a fração \\(n_A/n\\). Mais ainda, Laplace define a probabilidade de um acontecimento como sendo o quociente entre o número de casos favoráveis e o número de casos possíveis, supondo todos equiprováveis. A principal limitação é que os eventos tenham que ser igualmente prováveis.\nUma outra maneira de obter probabilidades é através das frequências de ocorrências, também conhecida como probabilidade frequentista ou a posteriori, em que a probabilidade de um dado acontecimento pode ser medida observando a frequência relativa do mesmo acontecimento numa sucessão numerosa de provas ou experiências, idênticas e independentes. A principal limitação é que os eventos possam repetir-se indefinidamente nas mesmas circunstâncias.\n\n\nExemplo 5.15Um lançamento de um dado, temos o espaço amostral \\(\\Omega=\\{1,~2,~3,~4,\\) \\(5,~6\\}\\). Considere também que o dado foi construído de forma homogênea e com medidas rigorosamente simétricas, não havendo qualquer razão para privilegiar essa ou aquela face. Logo, podemos considerar \\(P(X=1)=P(X=2)=P(X=3)=\\ldots=P(X=6)=1/6\\), fato que se enquadra na probabilidade clássica ou a priori.\n\n\n\nExemplo 5.16Suponha que seja conhecida a frequência de cada possível elemento do espaço amostral, \\(\\Omega\\). Se sorteamos aleatoriamente um elemento dessa população, a probabilidade de sortear esse ou aquele elemento será a sua respectiva frequência relativa, fato que se enquadra no tipo de probabilidade frequentista ou a posteriori.\n\n\n\n5.3.1 Propriedades\nVejamos algumas propriedades da medida de probabilidade, consequências dos Teoremas 5.2 e 5.3, a seguir.\n\nTeorema 5.6: Propriedades de \\(P\\)\nSeja \\(P\\) uma medida de probabilidade associada a sequênia de eventos aleatórios \\(A_i \\in \\Omega\\), \\(\\forall i \\in \\mathbb{N}\\). Então são válidas as seguintes propriedades:\n\n(Complemento) \\(P(A)=1-P(A^c)\\);\n\\(P(\\emptyset)=0\\);\n\\(P(B)=P(A\\cap B)+P(A^c\\cap B)\\);\n(Monotonicidade) Se \\(A \\subseteq B\\), então \\(P(A)\\leq P(B)\\);\n\\(P(A\\cup B)= P(A)+P(B) - P(A\\cap B)\\);\n(Limitante Superior) \\(0 \\leq P(A) \\leq 1\\);\n(Continuidade da probabilidade) Se \\(A_i \\downarrow A\\), então \\(P(A_i) \\downarrow P(A)\\). Se \\(A_i \\uparrow A\\), então \\(P(A_i) \\uparrow P(A)\\).\n(Desigualdade de Boole) \\(P(\\bigcup^{\\infty}_{i=1}A_i)\\leq \\sum^{\\infty}_{i=1}P(A_i)\\);\n(subaditividade) \\(P(\\bigcup^{n}_{i=1}A_i)\\leq \\sum^{n}_{i=1}P(A_i)\\);\n(Desigualdade de Bonferroni) \\(P(\\bigcap_{i = 1}^{n}A_i) \\geq 1 - \\sum_{i = 1}^{n}P(A_i^c)\\)\n(Inclusão-Exclusão) \\(P(\\bigcup_{i = 1}^{n}A_i)\\) \\(=\\) \\(\\sum_{i = 1}^{n}P(A_i)\\) \\(-\\) \\(\\sum_{i &lt; j}^{n}P(A_i \\cap A_j)\\) \\(+\\) \\(\\sum_{i &lt; j &lt; k}^{n}P(A_i \\cap A_j \\cap A_k)\\) \\(-\\) \\(\\ldots + (-1)^{n + 1}P(\\cap_{i = 1}^{n} A_n)\\).\n\n\n\n\nProva\n\nSabemos que \\(A\\cup A^c=\\Omega\\), Teorema 5.3 (\\(i\\)), e que estes eventos são disjuntos, então\n\n\\[\\begin{eqnarray*}\n    P(A\\cup A^c)&=&P(A)+P(A^c)\\\\\n    1 &=& P(A)+P(A^c)\\\\\n    P(A) &=& 1 - P(A^c);\n\\end{eqnarray*}\\]\n\nSabemos que \\(\\Omega\\) e \\(\\emptyset\\) são eventos disjuntos. Assim, \\[\\begin{eqnarray*}\nP(\\Omega\\cup \\emptyset)&=&P(\\Omega)+P(\\emptyset)\\\\\n1 &=& 1+P(\\emptyset)\\\\\nP(\\emptyset) &=& 0,\n\\end{eqnarray*}\\] o que conclui a prova;\nPodemos observar que \\(B=\\{A\\cap B\\}\\cup \\{A^c\\cap B\\}\\), Teorema 5.3 (\\(xii\\)), e que \\(\\{A\\cap B\\}\\) e \\(\\{A^c\\cap B\\}\\) são disjuntos. Portanto,\n\n\\[\\begin{eqnarray*}\n        P(B) &=& P(\\{A\\cap B\\}\\cup \\{A^c\\cap B\\})\\\\\n        &=& P(A\\cap B) + P(A^c\\cap B),\n\\end{eqnarray*}\\] como esperado;\n\nSe \\(A\\subset B\\), então \\(A\\cap B = A\\). Usando \\((i)\\), temos \\[\\begin{eqnarray*}\nP(B) & = & P(A\\cap B)+P(A^c\\cap B) \\\\\n& = & P(A)+P(A^c\\cap B) \\geq P(A),\n\\end{eqnarray*}\\] como queríamos demonstrar.\nObservando a seguinte identidade encontrada no Teorema 5.3 (\\(XV\\)), isto é,\n\n\\[\\begin{align*}\n    A\\cup B = & (A \\cap B^c)\\cup (A \\cap B) \\cup (A^c \\cap B),\n\\end{align*}\\] união de eventos disjuntos, que pode ser observado pelo diagrama de Venn, então \\[\n\\begin{align}\n    P(A\\cup B) &= P(A \\cap B^c) + P(A \\cap B) + P(A^c \\cap B).\n\\end{align}\n\\tag{5.6}\\]\nPor (\\(iii\\)) sabemos que \\(P(A) = P(B\\cap A)+P(B^c\\cap A)\\), assim \\[\n\\begin{align}\n  P(B^c\\cap A) = P(A) - P(B\\cap A).\n\\end{align}\n\\tag{5.7}\\] Ainda, temos que \\(P(B) = P(A\\cap B)+P(A^c\\cap B)\\) o que implica \\[\n\\begin{align}\n  P(A^c\\cap B) = P(B) - P(A\\cap B).\n\\end{align}\n\\tag{5.8}\\] Portanto, substituindo (5.7) e (5.8) em (5.6), obtemos \\[\\begin{eqnarray*}\n    P(A\\cup B) &=& P(A) + P(B) - P(A \\cap B),\n\\end{eqnarray*}\\] o que conclui a prova;\n\nPela Definição 5.17, usando o Axioma da Não-aditividade, a prova é imediata;\nVamos supor que \\(A_i \\downarrow A\\), isto é, \\(A_i \\supset A_{i + 1}\\) e \\(\\bigcap\\limits_{i \\geq 1} A_i = A\\). Então \\(P(A_i) \\geq P(A_{i + 1})\\) pelo item (iv), e \\((A_i - A) \\downarrow \\emptyset \\Rightarrow P(A_i - A) \\to 0\\) pela continuidade do vazio. Pela aditividade finita \\(P(A_i - A) = P(A_i) - P(A)\\), e como \\(\\{P(A_i)\\}_{i\\in \\mathbb{N}}\\) é decrescente, logo \\(P(A_i)\\downarrow P(A)\\). Agora, se \\(A_i \\uparrow A\\), isto é, \\(A_i \\subset A_{i + 1}\\) e \\(\\bigcup\\limits_{i \\geq 1} A_i = A\\), então \\(A^c_i \\downarrow A^c\\), logo \\(P(A^c_i) \\downarrow P(A^c) \\Rightarrow 1 - P(A_i)\\downarrow 1 - P(A)\\). Portanto, \\(P(A_i)\\uparrow P(A)\\), como queríamos demonstrar;\nVamos inicialmente criar uma sequência disjunta \\(A^*_1,A^*_2,\\ldots,\\) com a propriedade \\(\\bigcup^{\\infty}_{i=1}A^*_i=\\bigcup^{\\infty}_{i=1}A_i\\). Definimos \\[\nA^*_1=A_1, \\qquad A^*_i=A_i \\cap \\left(\\bigcup^{i-1}_{j=1}A_j\\right)^c, \\quad i=2,3,\\ldots.\n\\] É fácil perceber que \\[\nP\\left(\\bigcup^{\\infty}_{i=1}A_i\\right)= P\\left(\\bigcup^{\\infty}_{i=1}A^*_i\\right)=\\sum^{\\infty}_{i=1} P(A^*_i),\n\\] onde a última igualdade segue, pois \\(A^*_i\\) são disjuntos. Observemos que pela construção, \\(A^*_i\\subseteq A_i\\), portanto, pela propriedade (\\(iv\\)), \\(P(A^*_i)\\leq P(A_i)\\), logo \\[\n\\sum^{\\infty}_{i=1}P(A^*_i) \\leq \\sum^{\\infty}_{i=1}P(A_i).\n\\] Concluindo a prova, \\[\\begin{eqnarray*}\n    P\\left(\\bigcup^{\\infty}_{i=1}A_i\\right) = \\sum^{\\infty}_{i=1} P(A^*_i) &\\leq& \\sum^{\\infty}_{i=1}P(A_i);\n\\end{eqnarray*}\\]\nAssumindo que \\(A_{n+i} = \\emptyset\\) para todo \\(i = 1, 2, \\ldots\\), então a propriedade (\\(vii\\)) implica na propriedade (\\(viii\\)), o que conclui a prova.\nPela Lei DeMorgan, Teorema 5.2 (\\(iv\\)), podemos generalizar a equivalência: \\((\\cap^{n}_{i = 1}A_i)^c =   \\cup^{n}_{i = 1}A_i^c\\), e como consequência temos que \\(\\cap^{n}_{i = 1}A_i = (\\cup^{n}_{i = 1}A_i^c)^c\\) (Teorema 5.3, \\(v\\)). Ainda pelo Teorema 5.3 (\\(ii\\)), \\(\\Omega = (\\cup^{n}_{i = 1}A_i^c) \\cup (\\cup^{n}_{i = 1}A_i^c)^c\\). Portanto, podemos afirmar que  \\[\n\\begin{align}\n  P(\\Omega) & = P(\\cup^{n}_{i = 1}A_i^c) + (\\cup^{n}_{i = 1}A_i^c)^c \\quad \\textrm{(eventos disjuntos)} \\nonumber\\\\\n  1      & = P(\\cup^{n}_{i = 1}A_i^c) + (\\cup^{n}_{i = 1}A_i^c)^c. \\quad \\textrm{(Def. 5.17, axioma $i$)}\n\\end{align}\n\\tag{5.9}\\]  Logo, pela expressão (5.9) e as equivalências apresentadas anteriormente, temos que \\[\n\\begin{align}\nP(\\cap^{n}_{i = 1}A_i) = 1 - P(\\cup^{n}_{i = 1}A_i^c).\n\\end{align}\n\\tag{5.10}\\] Pela subaditividade, propriedade (\\(viii\\)), observamos que \\[\n\\begin{align}\nP(\\cup^{n}_{i=1}A_i^c)\\leq \\sum^{n}_{i=1}P(A_i^c).\n\\end{align}\n\\tag{5.11}\\] Portanto, substituindo (5.10) em (5.11), temos \\[\\begin{align*}\n1- P(\\cap_{i = 1}^{n}A_i) & \\leq \\sum_{i = 1}^{n}P(A_i^c)\\\\\n-P(\\cap_{i = 1}^{n}A_i) & \\leq - 1 + \\sum_{i = 1}^{n}P(A_i^c) \\quad \\times (-1)\\\\\nP(\\cap_{i = 1}^{n}A_i) & \\geq 1 - \\sum_{i = 1}^{n}P(A_i^c),\\\\\n\\end{align*}\\] o que se conclui a prova;\nVamos apresentar duas provas:\n\nPrimeira demonstração\n\nPrimeiro para \\(n = 2\\), temos a propriedade \\((iv)\\) do Teorema 5.6, isto é, \\[\n\\begin{align}\nP(A_1 \\cup A_2) & = P(A_1)+P(A_2) - P(A_1\\cap A_2)\n\\end{align}\n\\tag{5.12}\\]\nPara \\(n = 3\\), vamos considerar \\(A = \\{A_1 \\cup A_2\\}\\), e que \\[\n\\begin{align}\n      P(A_1 \\cup A_2 \\cup A_3) & = P(A \\cup A_3) \\nonumber\\\\\n      & = P(A) + P(A_3) - P(A \\cap A_3).\n\\end{align}\n\\tag{5.13}\\]\n\nSegue que \\(P(A) = P(A_1 \\cup A_2)  =  P(A_1)+P(A_2) - P(A_1\\cap A_2)\\) e que \\[\n\\begin{align}\n        P(A \\cap A_3) & = P[(A_1 \\cup A_2) \\cap A_3] \\nonumber\\\\\n        & = P[(A_1 \\cap A_3) \\cup (A_2 \\cap A_3)] \\nonumber\\\\\n        & = P(A_1 \\cap A_3) + P(A_2 \\cap A_3)\\\\\n        & \\quad - P(A_1 \\cap A_2 \\cap A_3) \\nonumber\n\\end{align}\n\\tag{5.14}\\]\nSubstituindo as expressões (5.45) e (5.14) em (5.39), logo \\[\\begin{align*}\n        P(A_1 \\cup A_2 \\cup A_3) & = P(A_1)+ P(A_2) + P(A_3) - P(A_1\\cap A_2)\\\\\n                                 & \\quad -  P(A_1 \\cap A_3) -  P(A_2 \\cap A_3)\\\\\n        & \\quad + P(A_1 \\cap A_2 \\cap A_3).\n\\end{align*}\\]\n\nPara \\(n = 4\\), já apresentando o resultado direto, temos \\[\n\\begin{align}\n      P(A_1 \\cup A_2 \\cup A_3 \\cup A_4) &  = \\sum_{i = 1}^{4}P(A_i) - \\sum_{1\\leq i &lt; j}^{4}P(A_i \\cap A_j) +\\nonumber\\\\\n      & \\quad + \\sum_{1 \\leq i &lt; j &lt; k}^{4}P(A_i \\cap A_j \\cap A_k) + \\nonumber\\\\\n      & \\quad - P(\\cap_{i = 1}^{4}A_i).\n\\end{align}\n\\tag{5.15}\\]\nPara \\(n = 5\\), já apresentando o resultado direto, temos \\[\n\\begin{align}\n      P\\left(\\bigcup_{i = 1}^{5}A_i\\right) &  = \\sum_{i = 1}^{5}P(A_i) - \\sum_{1 \\leq i &lt; j}^{5}P(A_i \\cap A_j) +\\nonumber \\\\\n      & \\quad + \\sum_{1 \\leq i &lt; j &lt; k}^{5}P(A_i \\cap A_j \\cap A_k) +\\nonumber\\\\\n      & \\quad - \\sum_{1 \\leq i &lt; j &lt; k &lt; l}^{5}P(A_i \\cap A_j \\cap A_k \\cap A_l) +\\nonumber\\\\\n      & \\quad + P(\\cap_{i = 1}^{5}A_i).\n\\end{align}\n\\tag{5.16}\\]\n\nObserve que a última expressão para a união das probabilidades alterna o sinal à medida que \\(n\\) aumenta, isto é, quando \\(n\\) é par, a interseção de todos os eventos é subtraída. Quando \\(n\\) é ímpar, a interseção de todos os eventos é somada. Assim, para um \\(n\\) qualquer induzindo pela expressão (5.16), temos\n\\[\\begin{align*}\n        P\\left(\\bigcup_{i = 1}^{n}A_i\\right) &  = \\sum_{i = 1}^{n}P(A_i) - \\sum_{1 \\leq i &lt; j}^{n}P(A_i \\cap A_j) + \\nonumber\\\\\n        & \\quad  + \\sum_{1 \\leq i &lt; j &lt; k}^{n}P(A_i \\cap A_j \\cap A_k) - \\ldots\\nonumber\\\\\n        & \\quad \\ldots +(-1)^{n + 1}P(\\cap_{i = 1}^{n} A_i).\n\\end{align*}\\]\nSegunda demonstração\nPara uma segunda demonstração, vamos provar para \\(n - 1\\) eventos e induzir para \\(n\\). Considere a probabilidade da união de eventos \\(\\{A_i\\}_{i = 1}^{n}\\), isto é, \\[\n\\begin{align}\n        P\\left(\\bigcup_{i = 1}^{n}A_i\\right) & = P\\left( \\bigcup_{i = 1}^{n-1}A_i \\cup A_n\\right)\\nonumber\\\\\n        & = P\\left( \\bigcup_{i = 1}^{n-1}A_i \\right) + P\\left(A_n\\right) - P\\left( \\bigcup_{i = 1}^{n-1}A_i \\cap A_n\\right) \\nonumber\\\\\n        & = \\left[\\sum_{i = 1}^{n-1}P(A_i) - \\sum_{1 \\leq i &lt; j}^{n-1}P(A_i \\cap A_j)+\\right. \\nonumber\\\\\n        & \\quad +\\left.\\sum_{1 \\leq i &lt; j &lt; k}^{n-1}P(A_i \\cap A_j \\cap A_k) - \\ldots\\right.\\nonumber\\\\\n        & \\quad \\left.\\ldots + (-1)^{(n - 1) + 1}P\\left(\\cap_{i =1}^{n-1}A_i\\right)\\right]+ \\nonumber\\\\\n        & \\quad +P\\left(A_n\\right) - P\\left( \\bigcup_{i = 1}^{n-1}A_i \\cap A_n\\right).\n\\end{align}\n\\tag{5.17}\\] Observe que  \\[\n\\begin{align}\n        P\\left( \\bigcup_{i = 1}^{n-1}A_i \\cap A_n\\right) & = \\sum_{i = 1}^{n-1}P(A_i\\cap A_n) - \\sum_{1 \\leq i&lt;j}^{n-1}P[(A_i\\cap A_n)\\cap (A_j\\cap A_n)] +\\nonumber\\\\\n        & \\quad  \\ldots + (-1)^{(n-1) + 1}P\\left(\\bigcap_{i = 1}^{n-1}(A_i\\cap A_n)\\right) \\nonumber\\\\\n        & = \\sum_{i = 1}^{n-1}P(A_i\\cap A_n) - \\sum_{1 \\leq i&lt;j}^{n-1}P(A_i\\cap A_j \\cap A_n) +  \\ldots \\nonumber \\\\\n        & \\quad +(-1)^{n-1}\\sum_{1 \\leq i_1 &lt; \\ldots &lt; i_{n-2}}^{n-1}P(\\cap^{n-2}_{j = 1} A_{i_{j}}\\cap A_n)+\\nonumber\\\\\n        & \\quad + (-1)^{(n-1) + 1}P\\left(\\cap_{i = 1}^{n}A_i\\right).\n\\end{align}\n\\tag{5.18}\\]  Então, a expressão \\(P\\left( \\bigcup_{i = 1}^{n-1}A_i \\cap A_n\\right)\\) recebe o sinal negativo, e portanto iremos substituir (5.18) em (5.32), levando em consideração a substituição do sinal, que segue  \\[\n\\begin{align}\nP\\left(\\bigcup_{i = 1}^{n}A_i\\right) & = \\left[\\sum_{i = 1}^{n-1}P(A_i) - \\sum_{1 \\leq i &lt; j}^{n-1}P(A_i \\cap A_j) + \\sum_{1 \\leq i &lt; j &lt; k}^{n-1}P(A_i \\cap A_j \\cap A_k) - \\ldots\\right.\\nonumber\\\\\n    & \\quad \\left. \\ldots + (-1)^{(n - 1) + 1}P\\left(\\cap_{i =1}^{n-1}A_i\\right)\\right]+ P\\left(A_n\\right) - \\left[\\sum_{i = 1}^{n-1}P(A_i\\cap A_n) - \\right. \\nonumber\\\\\n    & \\quad \\left. - \\sum_{1 \\leq i&lt;j}^{n-1}P(A_i\\cap A_j \\cap A_n)  + \\ldots + (-1)^{n-1}\\times \\right. \\nonumber\\\\\n    & \\quad \\left. \\times \\sum_{1 \\leq i_1 &lt; \\ldots &lt; i_{n-2}}^{n-1}P(\\cap^{n-2}_{j = 1} A_{i_{j}}\\cap A_n) + (-1)^{(n-1) + 1}P\\left(\\cap_{i = 1}^{n}A_i\\right) \\right]  \\nonumber\\\\\n    & = \\sum_{i = 1}^{n-1}P(A_i) + P\\left(A_n\\right) - \\sum_{1 \\leq i &lt; j}^{n-1}P(A_i \\cap A_j) - \\sum_{i = 1}^{n-1}P(A_i\\cap A_n) + \\nonumber\\\\\n    & \\quad + \\sum_{i &lt; j &lt; k}^{n-1}P(A_i \\cap A_j \\cap A_k) +\\sum_{1 \\leq i&lt;j}^{n-1}P(A_i\\cap A_j \\cap A_n) + \\ldots\\nonumber\\\\\n    & \\quad \\ldots + (-1)^{n-1}\\sum_{1 \\leq i_1 &lt; \\ldots &lt; i_{n-2}}^{n-1}P(\\cap^{n-2}_{j = 1} A_{i_{j}}\\cap A_n) +\\nonumber\\\\\n    & \\quad \\ldots + (-1)^{(n - 1) + 1}P\\left(\\cap_{i =1}^{n-1}A_i\\right) + (-1)^{(n-1) + 1}P\\left(\\cap_{i = 1}^{n}A_i\\right)\n\\end{align}\n\\tag{5.19}\\] \nNesse momento, precisamos verificar algumas equivalências:\n\nPrimeira equivalência:\n\n\\[\n\\begin{align}\n    \\sum_{i = 1}^{n-1}P(A_i) + P\\left(A_n\\right) & = P(A_1) + \\ldots + P(A_{n-1}) + P(A_n) \\nonumber\\\\\n    & = \\sum_{i = 1}^{n}P(A_i).\n\\end{align}\n\\tag{5.20}\\]\n\nSegunda equivalência:  \\[\n\\begin{align}\n  \\sum_{1 \\leq i &lt; j}^{n-1}P(A_i \\cap A_j) + \\sum_{i = 1}^{n-1}P(A_i\\cap A_n) & =  \\left[P(A_1 \\cap A_2) + \\ldots + P(A_1 \\cap A_{n-1}) +\\right. \\nonumber\\\\\n  & \\quad + P(A_2 \\cap A_3) + \\ldots + P(A_2 \\cap A_{n-1}) + \\ldots \\nonumber\\\\\n  & \\quad \\left. \\quad + P(A_{n-2}\\cap A_{n-1})\\right] + \\left[ P(A_1 \\cap A_n) +  \\right. \\nonumber\\\\\n  & \\quad \\left.  + P(A_2 \\cap A_n) + \\ldots +  P(A_{n-1} \\cap A_{n}) + \\right] \\nonumber\\\\\n  & = \\sum_{1 \\leq i &lt; j}^{n}P(A_i \\cap A_j).\n\\end{align}\n\\tag{5.21}\\] \nTerceira equivalência:\n\n\\[\n\\begin{align}\n        \\sum_{i &lt; j &lt; k}^{n-1}P(A_i \\cap A_j \\cap A_k) +\\sum_{1 \\leq i&lt;j}^{n-1}P(A_i\\cap A_j \\cap A_n) & =  \\sum_{i &lt; j &lt; k}^{n}P(A_i \\cap A_j \\cap A_k)\n\\end{align}\n\\tag{5.22}\\]\n\nDemais equivalências: os demais termos apresentados em (5.19) seguem as mesmas ideias das equivalências apresentadas anteriormente, exceto o último termo \\((-1)^{(n-1) + 1}P\\left(\\cap_{i = 1}^{n}A_i\\right)\\).\n\nPortanto, substituindo as expressões (5.20), (5.21) e (5.22) em (5.19), chegamos ao resultado esperado \\[\\begin{align*}\n  P(\\bigcup_{i = 1}^{n}A_i) & = \\sum_{i = 1}^{n}P(A_i) - \\sum_{i &lt; j}^{n}P(A_i \\cap A_j) + \\sum_{i &lt; j &lt; k}^{n}P(A_i \\cap A_j \\cap A_k) - \\ldots \\\\\n  & \\quad \\dots + (-1)^{n + 1}P(\\cap_{i = 1}^{n} A_n),\n\\end{align*}\\] o que conclui a prova.\n\n\nOs resultados apresentados no Teorema 5.6 como propriedades da medida de probabilidade, nos auxilia em diversos problemas de uma forma geral, como condições elementares apresentadas nas sete primeiras propriedades, condições limitantes nas propriedades de (\\(viii\\)) a (\\(x\\)), e a condição de união de uma sequência de eventos. Esta última necessitação de um exemplo teórico mais simples para a sua elucidação, apresentada no Exemplo 5.17.\n\nExemplo 5.17: Princípio da inclusão-exclusão\nApós termos apresentado nas propriedades da probabilidade, Teorema 5.6 (\\(xi\\)), a propriedade da união de \\(n\\) eventos, vamos elucidar uma dedução mais simples para \\(n = 4\\), que segue:\n\\[\n\\begin{align}\n    P\\left( \\bigcup^{4}_{i = 1}A_i\\right) & = P\\left( \\bigcup^{3}_{i = 1}(A_i \\cup A_4)\\right) \\nonumber\\\\\n    & =  P\\left( \\bigcup^{3}_{i = 1}A_i\\right) +  P\\left(A_4\\right) - P\\left( \\bigcup^{3}_{i = 1}A_i \\cap A_4\\right).\n\\end{align}\n\\tag{5.23}\\]\nDeduzindo os termos individuais em (5.23), temos \\[\n\\begin{align}\n  P\\left( \\bigcup^{3}_{i = 1}A_i\\right) &= \\sum_{i = 1}^{3}P(A_i) - \\sum_{1 \\leq i &lt; j}^{3}P(A_i \\cap A_j) + P(\\cap_{i = 1}^{3}A_i).\n\\end{align}\n\\tag{5.24}\\]\nDeduzindo o outro termo, temos\n \\[\n\\begin{align}\n    P\\left( \\bigcup^{3}_{i = 1}A_i \\cap A_4\\right) &= \\sum_{i = 1}^{3}P(A_i \\cap A_4) - \\sum_{1 \\leq i &lt; j}^{3}P(A_i \\cap A_j \\cap A_4) + P(\\cap_{i = 1}^{4}A_i).\n\\end{align}\n\\tag{5.25}\\] \nSubstituindo (5.24) e (5.25) em (5.23), obtemos  \\[\n\\begin{align}\n  P\\left( \\bigcup^{4}_{i = 1}A_i\\right) & = \\left[\\sum_{i = 1}^{3}P(A_i) - \\sum_{1 \\leq i &lt; j}^{3}P(A_i \\cap A_j) + P(\\cap_{i = 1}^{3}A_i) \\right] +  P\\left(A_4\\right) - \\nonumber \\\\\n  & \\quad - \\left[\\sum_{i = 1}^{3}P(A_i \\cap A_4) - \\sum_{1 \\leq i &lt; j}^{3}P(A_i \\cap A_j \\cap A_4) + P(\\cap_{i = 1}^{4}A_i) \\right] \\nonumber \\\\\n  & = \\sum_{i = 1}^{3}P(A_i) + P\\left(A_4\\right) - \\sum_{1 \\leq i &lt; j}^{3}P(A_i \\cap A_j) - \\sum_{i = 1}^{3}P(A_i \\cap A_4) + \\nonumber\\\\\n  & \\quad + P(\\cap_{i = 1}^{3}A_i) + \\sum_{1 \\leq i &lt; j}^{3}P(A_i \\cap A_j \\cap A_4) - P(\\cap_{i = 1}^{4}A_i).\n\\end{align}\n\\tag{5.26}\\] \nDevemos observar as seguintes equivalências:\n\nPrimeira equivalência:\n\n\\[\n\\begin{align}\n  \\sum_{i = 1}^{3}P(A_i) + P\\left(A_4\\right) & = P(A_1) + P(A_2) + P(A_3) + P(A_4) \\nonumber \\\\\n  & = \\sum_{i = 1}^{4}P(A_i);\n\\end{align}\n\\tag{5.27}\\]\n\nSegunda equivalência:  \\[\n\\begin{align}\n\\sum_{1 \\leq i &lt; j}^{3}P(A_i \\cap A_j) + \\sum_{i = 1}^{3}P(A_i \\cap A_4) & =   [P(A_1\\cap A_2) + P(A_1\\cap A_3) +\\\\\n& \\quad P(A_2\\cap A_3)]+ [P(A_1\\cap A_4) +\\\\\n& \\quad + P(A_2\\cap A_4) + P(A_3\\cap A_4)]\\\\\n& = \\sum_{1 \\leq i &lt; j}^{4}P(A_i \\cap A_j);\n\\end{align}\n\\tag{5.28}\\] \nTerceira equivalência: para este caso, observando a última parte do resultado em (5.19), isto é,  \\[\\begin{align*}\n\\ldots + (-1)^{n-1}\\sum_{1 \\leq i_1 &lt; \\ldots &lt; i_{n-2}}^{n-1}P(\\cap^{n-2}_{j = 1} A_{i_{j}}\\cap A_n) + \\ldots + (-1)^{(n - 1) + 1}P\\left(\\cap_{i =1}^{n-1}A_i\\right);\n\\end{align*}\\]  a parte similar para o exemplo se refere a seguinte equivalência:  \\[\n\\begin{align}\nP(\\cap_{i = 1}^{3}A_i) + \\sum_{1 \\leq i &lt; j}^{3}P(A_i \\cap A_j \\cap A_4) & = [P(A_1\\cap A_2 \\cap A_3)] + \\\\\n&  \\quad + [P(A_1\\cap A_2 \\cap A_4) +\\\\\n& \\quad + P(A_1\\cap A_3 \\cap A_4) + \\\\\n& \\quad + P(A_2 \\cap A_3 \\cap A_4)] \\\\\n& = \\sum_{1 \\leq i &lt; j &lt; k}^{4}P(A_i \\cap A_j \\cap A_k).\n\\end{align}\n\\tag{5.29}\\]  Substituindo as equivalências em (5.26), logo  \\[\\begin{align*}\nP\\left( \\bigcup^{4}_{i = 1}A_i\\right) & = \\sum_{i = 1}^{4}P(A_i) - \\sum_{1 \\leq i &lt; j}^{4}P(A_i \\cap A_j) + \\sum_{1 \\leq i &lt; j &lt; k}^{4}P(A_i \\cap A_j \\cap A_k) - P(\\cap_{i = 1}^{4}A_i),\n\\end{align*}\\]  resultado igual ao que apresentamos em (5.16).\n\n\n\nPercebemos ainda no Teorema 5.6 que a propriedade (\\(xi\\)) é uma generalização da propriedade (\\(v\\)). Ao passo que a condição de uma sequência de eventos serem disjuntos dois a dois, Definição 5.10, temos \\[\n\\begin{align}\n  P\\left(\\bigcup^{\\infty}_{i = 1}A_i\\right) = \\sum_{i = 1}^{\\infty}P(A_i).\n\\end{align}\n\\tag{5.30}\\] Se considerarmos \\(A_i = \\emptyset\\) para todo \\(i = n + 1, n + 2, \\ldots\\), então restringimos a probabilidade de uma soma finita, isto é, \\[\n\\begin{align}\n  P\\left(\\bigcup^{n}_{i = 1}A_i\\right) = \\sum_{i = 1}^{n}P(A_i),\n\\end{align}\n\\tag{5.31}\\] uma vez que \\(P(\\emptyset) = 0\\) (Teorema 5.6, \\(ii\\)). Por fim, para a situação de termo apenas dois eventos, o resultado é o Axioma (\\(iii\\)) da Definição 5.17. Vejamos mais um exemplo, a seguir.\n\nExemplo 5.18: Retirado de Devore (2006)Uma empresa de eletricidade oferece uma taxa vitalícia de energia a qualquer lar cuja utilização de energia esteja abaixo de \\(240\\)~kWh durante um determinado mês. Represente por \\(A\\) o evento de um lar selecionado aleatoriamente em um comunidade que não excede a utilização da taxa vitalícia em janeiro e por \\(B\\) o evento análogo para o mês de julho (\\(A\\) e \\(B\\) se referem ao mesmo lar). Suponha que \\(P(A) = 0,8\\), \\(P(B) = 0,7\\) e \\(P(A \\cup B) = 0,9\\). Calcule:\n\n\\(P(A \\cap B)\\);\nA probabilidade de a quantia da taxa vitalícia ser excedida em exatamente um dos dois meses. Descreva esse evento em termos de \\(A\\) e \\(B\\).\n\nConsidere, \\[\\begin{align*}\n  A & = \\{\\omega \\in \\Omega: \\omega = \\textrm{``lar X que não excede 240kWh em janeiro''}\\}, \\\\\n  B & = \\{\\omega \\in \\Omega: \\omega = \\textrm{``lar X que não excede 240kWh em julho''}\\}.\\\\\n\\end{align*}\\]\nIsso ocorre porque os eventos não são disjuntos, uma vez que os dois eventos consistem no mesmo lar X, em ser selecionado. Assim, usando a propriedade (\\(v\\)) do Teorema 5.6, podemos obter \\(P(A \\cap B)\\), dado por: \\[\n\\begin{align}\n  P(A\\cap B) & = P(A) + P(B) - P(A \\cup B) \\nonumber\\\\\n             & =  0,8 + 0,7 - 0,9 \\nonumber\\\\\n             & = 0,6.\n\\end{align}\n\\tag{5.32}\\] No caso do ítem (b), o evento que representa o lar X de a quantia vitalícia ser excedida em exatamente um dos dois meses por ser representado por: \\((A^c \\cap B) \\cup (A \\cap B^c)\\), uma vez que,\n\\[\\begin{align*}\n  A^c  = \\{\\omega \\in \\Omega: \\omega = \\textrm{``lar X que exceder 240kWh em janeiro''}\\}, \\\\\n  B^c  = \\{\\omega \\in \\Omega: \\omega = \\textrm{``lar X que exceder 240kWh em julho''}\\}.\\\\\n\\end{align*}\\]\nPodemos ainda observar pelo Teorema 5.3 (prop. XV), que \\(A \\cup B = (A^c \\cap B)\\cup (A \\cap B) \\cup (A \\cap B^c)\\), e que cada um dos eventos dentro do parêntese são disjuntos dois a dois, logo, \\[\\begin{align*}\n  P(A \\cup B) & = P[(A^c \\cap B)\\cup (A \\cap B) \\cup (A \\cap B^c)]\\\\\n              & = P[(A^c \\cap B) \\cup (A \\cap B^c)] + P(A \\cap B).\n\\end{align*}\\] Desse modo, percebemos que \\(P[(A^c \\cap B) \\cup (A \\cap B^c)] = P(A \\cup B) - P(A \\cap B)\\), logo, \\[\\begin{align*}\n  P[(A^c \\cap B) \\cup (A \\cap B^c)] & = 0,9 - 0,6 = 0,3.\n\\end{align*}\\]\n\n\n\nExemplo 5.19Usando os resultados do Exemplo 5.18, podemos calcular a probabilidade de \\(A^c\\), usando a propriedade (\\(i\\)) do Teorema 5.6, ou seja: \\[\\begin{align*}\n  P(A^c) & = 1 - 0,8 = 0,2.\n\\end{align*}\\] Isso representa a chance do exceder a energia acima de 240kWh, em janeiro.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Probabilidades</span>"
    ]
  },
  {
    "objectID": "cap05.html#ind&probcond",
    "href": "cap05.html#ind&probcond",
    "title": "5  Probabilidades",
    "section": "5.4 Eventos independentes e probabilidade condicional",
    "text": "5.4 Eventos independentes e probabilidade condicional\nNessa seção, iremos apresentar iniciar com uma motivação, por meio do Exemplo 5.20, uma abordagem sobre dois assuntos muito interessantes na probabilidade, que são a independência de eventos e a modificação do espaço amostral, dada uma informação antecipada, e qual a implicância dessas informações para a probabilidade de um evento ocorrer.\n\nExemplo 5.20\nPaulo é um jovem empreendedor e quer abrir seu próprio negócio. Ele observou que o mercado de sandálias era lucrativo. Então resolveu abrir uma fábrica de sandálias. Devido a dificuldade financeira, resolveu comprar três máquinas de sandálias usadas. As informações anteriores sobre estas máquinas dadas pelo proprietário foram:\n\n\n\nMáquina\nProduto\nTotal da produção\n\n\n\n\nM1 & Pantufas\n50%\n1%\n\n\nM2\nSandálias baixas\n40%\n\n\nM3\nSandálias de couro\n10%\n\n\n\nSurgiu as seguintes indagações:\n\nDo total de sandálias produzidas, qual a probabilidade de Paulo produzir uma sandália com defeito?\nPensando em aumentar o lucro da fábrica, Paulo pensa e substituir uma das máquinas, qual seria sua decisão?\n\nSerá que a máquina M1 que produz mais sandálias e consequentemente tem maior desgaste, deve ser trocada primeiro?\nOu será que apesar da máquina M3 ter menor produção, é a que gera mais defeito por sandália, deve ser trocada primeiro?\n\n\n\n\nMuitas vezes nos deparamos com situações em que antes da realização de algum experimento, temos alguma informação adicional. Queremos saber o quanto que essa informação pode afetar a medida de probabilidade. Assim, apresentamos a Definição 5.18, que define a probabilidade condicional, a seguir.\n\nDefinição 5.18: Probabilidade condicionalDados dois eventos \\(A\\) e \\(B\\) definidos em \\(\\Omega\\), então a probabilidade condicional do evento \\(A\\) dado que ocorreu o evento \\(B\\), denotado por \\(P(A|B)\\), é definida por: \\[\n\\begin{equation}\n    P(A|B) = \\frac{P(A \\cap B)}{P(B)},\n\\end{equation}\n\\tag{5.33}\\] para \\(P(B) &gt; 0\\).\n\n\nBaseado no problema de Paulo, denotemos o evento \\(D\\) as sandálias produzidas com defeitos pela empresa, \\(M_1\\) o evento que representa as sandálias produzidas pela máquina \\(M_1\\), \\(M_2\\) o evento que representa as sandálias produzidas pela máquina \\(M_2\\) e \\(M_3\\) o evento que representa as sandálias produzidas pela máquina \\(M_3\\). Assim, percebemos que a probabilidade do evento \\(D\\) não pode ser observada facilmente, pois o defeito dos produtos produzidos pelas máquinas está condicionado a cada máquina. Desse modo podemos representar, a probabilidade desses defeitos da seguinte forma: \\(P(D|M_1) = 0,01\\), \\(P(D|M_2) = 0,02\\), e \\(P(D|M_3) = 0,03\\). Essas probabilidades apresentam uma alteração no espaço amostral para cada evento, porque esses resultados mostram a chance de defeito do produto, dado o conhecimento de que máquina foi produzido, é o que chamamos de restrição do espaço amostral.\nEssa restrição do espaço amostral, pode nos questionar se de fato a probabilidade condicional, de fato, é uma medida de probabilidade. Para isso, apresentamos o Teorema 5.7, na sequência.\n\nTeorema 5.7: \\(P(A|B)\\) é uma medida de probabilidadeSejam \\(A\\) e \\(B\\) eventos aleatórios, tal que \\(P(B)&gt;0\\), e considere \\(Q: \\Omega\\rightarrow [0,1]\\) definida por \\[\n  Q(A) = P(A|B) = \\frac{P(A\\cap B)}{P(B)},\n\\] que é a probabilidade condicional de \\(A\\) dado \\(B\\). Então \\(Q\\) é também uma medida de probabilidade.\n\n\n\nProva\nPara verificarmos se \\(Q(.)\\) é uma medida de probabilidade, devemos assumir que \\(Q\\) satisfaz os axiomas de Kolmogorov, isto é,\n\nAxioma 1: \\[\\begin{align*}\n      Q(\\Omega) &= \\frac{P(\\Omega \\cap B)}{P(B)}\\\\\n      &= \\frac{P(B)}{P(B)}\\\\\n      &= 1.\n\\end{align*}\\]\nAxioma 2: como \\(P\\) é uma medida de probabilidade, então \\[\n\\forall A \\in \\Omega: \\quad Q(A) \\geq 0.\n\\]\nAxioma 3: Sejam dois eventos \\(A_1\\) e \\(A_2\\), disjuntos, então \\[\\begin{align*}\n      Q(A_1 \\cup A_2) &= \\frac{P[(A_1 \\cup A_2) \\cap B]}{P(B)}\\\\\n      &= \\sum^{2}_{i=1}\\frac{P[(A_1 \\cap B) \\cup (A_2 \\cap B)]}{P(B)},~~ \\textrm{Teorema 5.2 (III)}\\\\\n      &= Q(A_1) + Q(A_2).\n\\end{align*}\\] o que conclui a prova.\n\n\n\nComo sequência de importantes resultados sobre propriedades da probabilidade, apresentamos o Teorema 5.8, que será importante para resultados muito utilizados na área aplicada, como o Teorema de Bayes, apresentado na sequência.\n\nTeorema 5.8: Regra do produto de probabilidadeSeja os eventos não vazios \\(A_1,A_2,\\ldots,A_n\\) em \\(\\Omega\\), com \\(P(\\bigcap^{n}_{i=1}A_i)&gt;0\\), então a probabilidade do produto desses eventos é dado por \\[\n    P(\\bigcap^{n}_{i=1}A_i)=P(A_1)P(A_2|A_1)\\ldots P(A_n|\\bigcap^{n}_{i=1}A_i).\n\\]\n\n\n\nProvaPor indução, consideremos \\(n=2\\). Assim, pela Definição 5.18, temos \\[\\begin{eqnarray*}\n    P(A_2|A_1)=\\frac{P(A_1\\cap A_2)}{P(A_1)}\\\\\n    P(A_1\\cap A_2)=P(A_1)P(A_2|A_1),\n\\end{eqnarray*}\\] em que \\(P(A_1\\cap A_2)=P(A_1)P(A_2|A_1)\\) e \\(P(A_1)&gt;0\\). Agora para \\(n=k\\), generalizamos a indução, \\[\\begin{eqnarray*}\n    P(A_1\\cap A_2\\cap \\ldots \\cap A_{k})&=& P[(A_1A_2\\ldots A_{k-1}) \\cap A_{k}],\n\\end{eqnarray*}\\] pela Definição 5.18, temos \\[\\begin{align*}\n        P\\left[\\bigcap^{k-1}_{i=1}A_i\\cap A_k\\right]&=P[(A_1A_2\\ldots A_{k-1})]P(A_{k}|A_1A_2\\ldots A_{k-1})\n\\end{align*}\\] podendo ser reescrito como \\[\\begin{align*}\n    P\\left[\\bigcap^{k-1}_{i=1}A_i\\cap A_k\\right]&=\\underbrace{P(A_1A_2\\ldots A_{k-2})P(A_{k-1}|A_1A_2\\ldots A_{k-2})}_{P(A_1A_2\\ldots A_{k-1})}\\times\\\\\n        &\\quad \\times P(A_{k}|A_1A_2\\ldots A_{k-1}).\n\\end{align*}\\] Assim, usando a indução sucessivas vezes, chegaremos a expressão \\[\\begin{align*}\n    P(A_1 A_2 \\ldots \\cap A_{k})&=P(A_1)P(A_2|A_1)\\ldots P(A_{k-1}|A_1A_2\\ldots A_{k-2})\\times\\\\\n    &\\quad \\times P(A_{k}|A_1A_2\\ldots A_{k-1}).\n\\end{align*}\\] Observe que por hipótese, todos os condicionamentos da expressão do lado direito, têm probabilidades positivas, pois contém \\(\\bigcap^{n}_{i=1}A_i\\), o que conclui a prova.\n\n\nAntes de falarmos sobre o teorema da lei da probabilidade total, será interessante fazer a definição sobre a partição de \\(\\Omega\\), apresentada na Definição 5.19, a seguir.\n\nDefinição 5.19: Partição de \\(\\Omega\\)Se a sequência \\(A_1, A_2, \\ldots,\\) são disjuntos dois a dois, não vazios, e \\(\\bigcup^{\\infty}_{i=1}A_i=\\Omega\\), então dizemos que essa sequência forma uma partição de \\(\\Omega\\).\n\n\nEntretanto, para calcular a probabilidade de uma sandália está com defeito, isto é \\(P(D)\\), independente de qual máquina a produziu, usamos o Teorema 5.9, a seguir.\n\nTeorema 5.9: Teorema da probabilidade totalSeja uma sequência de eventos \\(A_1, A_2, \\ldots, A_n\\) de \\(\\Omega\\), disjuntos, tal que \\(\\bigcup^{n}_{i = 1}A_i = \\Omega\\), e \\(B\\) um evento de \\(\\Omega\\), não vazio, então a probabilidade de \\(B\\) é dada por: \\[\n\\begin{eqnarray}\n    P(B) = \\sum_{i = 1}^{n}P(B|A_i)P(A_i),\n\\end{eqnarray}\n\\tag{5.34}\\] para \\(P(A_i) &gt; 0\\), sendo \\(i = 1, 2, \\ldots, n\\).\n\n\n\nProvaSabendo que \\(A_i \\cap_{i \\neq j} A_j\\) e que \\(\\bigcup^{n}_{i = 1}B\\cap A_i = \\Omega\\), então \\(\\bigcup_{i = 1}^{n} B\\cap A_i = B\\) e os \\(B\\cap A_i\\) são também disjuntos. Dessa forma, \\[\\begin{align*}\n    P(B) = & P\\left(\\bigcup_{i = 1}^{n} B\\cap A_i\\right) \\\\\n         = & \\sum_{i = 1}^{n}  P(B\\cap A_i) \\qquad (B\\cap A_i\\textrm{ disjuntos)}\\\\\n         = & \\sum_{i = 1}^{n}P(B|A_i)P(A_i) \\qquad \\textrm{ (Teorema 5.8)}\n\\end{align*}\\] como queríamos provar.\n\n\nRetornando ao cálculo da probabilidade \\(P(D)\\), no Exemplo 5.21 apresentamos como o Teorema 5.9 soluciona esse problema, a seguir.\n\nExemplo 5.21Voltando ao problema de Paulo, como \\(P(M_1) = 0,50\\), \\(P(M_2) = 0,40)\\) e \\(P(M_3) = 0,10\\), então a probabilidade de uma sandália ter defeito é \\[\\begin{align*}\n    P(D) = & \\sum_{i = 1}^{3}P(D|M_i)P(M_i)\\\\\n    = & P(D|M_1)P(M_1) + P(D|M_2)P(M_2) + P(D|M_3)P(M_3)\\\\\n    = & 0,01 \\times 0,50 + 0,02 \\times 0,40 + 0,03 \\times 0,10\\\\\n    = & 0,016.\n\\end{align*}\\]\n\n\nNesse momento, surge uma importante definição na Estatística e Probabilidade, que é a independência de eventos, apresentada na Definição 5.20. A ideia da independência é uma característica probabilística, e isto significa, que se dois eventos forem independentes, então a probabilidade de um evento ocorrer não é influenciado pela ocorrência ou não do outro evento. A implicância da pressuposição da independência em problemas práticos na estatística podem ser resolvidos de forma trivial, devido as técnicas probabilísticas serem resolvidas de forma mais facilmente.\n\nDefinição 5.20: Independência de dois eventos\nConsidere o espaço amostral \\(\\Omega\\). Dois eventos \\(A\\) e \\(B\\) de \\(\\Omega\\) são independentes se satisfaz ao menos uma das seguintes condições:\n\n\\(P(A \\cap B) = P(A)P(B)\\);\n\\(P(A|B) = P(A)\\), para \\(P(B) &gt; 0\\);\n\\(P(B|A) = P(B)\\), para \\(P(A) &gt; 0\\).\n\n\n\nÉ fácil mostrar que (I) implica em (II), (II) implica em (III), e (III) implica em (I).\n\\((i) \\to (ii)\\): Se \\(P(A\\cap B) = P(A)P(B)\\), então\n\\[\\begin{align*}\n  P(A|B) = \\frac{P(AB)}{P(A)} = \\frac{P(A)P(B)}{P(B)} = P(A), \\quad \\textrm{para } P(B) &gt; 0;\n\\end{align*}\\]\n\\((ii) \\to (iii)\\): Se \\(P(A|B) = P(A)\\), então \\[\\begin{align*}\n  P(B|A) = \\frac{P(BA)}{P(A)} = \\frac{P(A|B)P(B)}{P(A)} = P(B), \\quad \\textrm{para } P(A) &gt; 0;\n\\end{align*}\\]\n\\((iii) \\to (i)\\): Se \\(P(B|A) = P(B)\\), então \\[\\begin{align*}\n  P(AB) = P(B|A)P(A) = P(B)P(A), \\textrm{para } P(A) &gt; 0.\n\\end{align*}\\]\nA intuição para independência na Definição 5.20 fica justificada pelo fato de que \\(A\\) é independente de \\(B\\) tanto na ocorrência quanto a não ocorrência de \\(B\\) e isso não muda em nada a probabilidade da ocorrência de \\(A\\), isto é, \\(P(A|B) = P(A)\\) e \\(P(A|B^c) = P(A)\\). Essas duas expressões significam que \\[\\begin{align*}\n  P(A\\cap B) & = P(B)P(A|B) = P(B)P(A)\\\\\n  P(A\\cap B^c) & = P(B^c)P(A|B^c) = P(B^c)P(A).\n\\end{align*}\\]\nEntretanto, a independência entre dois eventos não implica em independência coletiva. Vejamos o Exemplo 5.22, a seguir.\n\nExemplo 5.22Sejam os resultados possíveis de um dado honesto, cujo espaço amostral é \\(\\Omega = \\{1, 2, 3, 4, 5, 6\\}\\). Considere um evento que representa o conjunto dos números ímpares desse espaço amostral, \\(A = \\{1, 3, 5\\}\\), e outro evento que consite nos múltiplos de 3, \\(B = \\{3, 6\\}\\). A probabilidade de \\(A\\) é \\(P(A) = 1/2\\), a probabilidade de B é \\(P(B) = 1/3\\), e a probabilidade da interseção entre A e B é \\(P(A \\cap B) = 1/6\\). Veja que dado que o evento B ocorra, ou não ocorra \\(B^c = \\{1, 2, 4, 5\\}\\), a probabilidade do evento A é a mesma, veja: \\[\\begin{align*}\n  P(A|B) & = \\frac{1/6}{1/3} = 1/2\\\\\n  P(A|B^c) & = \\frac{2/6}{4/6} = 1/2.\n\\end{align*}\\] Que é o mesmo que entender que \\(P(A) \\times P(B) = 1/6 = P(A\\cap B)\\). Logo, \\(A\\) e \\(B\\) são eventos independentes.\n\n\n\nExemplo 5.23Seja um experimento cujo objetivo é verificar a face superior de um tetraedro, isto é, \\(\\Omega = \\{1, 2, 3, 4\\}\\). Sejam os eventos em \\(\\Omega\\), \\(A = \\{1, 4\\}\\), \\(B = \\{2, 4\\}\\) e \\(C = \\{3, 4\\}\\). Considerando o tetraedro honesto e que cada valor é equiprovável, assim \\(P(A) = P(B) = P(C) = 1/2\\). Observamos que estes eventos são independentes dois a dois, isto é, \\(P(A\\cap B) = 1/4 = P(A)P(B)\\), \\(P(A\\cap C) = 1/4 = P(A)P(C)\\) e \\(P(B\\cap C) = 1/4 = P(B)P(C)\\). Porém, \\(P(A\\cap B \\cap C) = 1/4 \\neq P(A) P(B) P(C)\\). Logo, os eventos A, B e C não são independentes três a três.\n\n\nPara uma definição mais geral sobre a independência de eventos, apresentamos a Definição 5.21, a seguir.\n\nDefinição 5.21: Independência de eventosConsidere o espaço amostral \\(\\Omega\\). Uma sequência de eventos \\(A_1, A_2, \\ldots, A_n\\) de \\(\\Omega\\) são independentes se e somente se: \\[\n\\begin{align}\n    P(A_i \\cap A_j) & = P(A_i)P(A_j), \\quad \\textrm{para } i \\neq j; \\nonumber\\\\\n    P(A_i \\cap A_j \\cap A_k) & = P(A_i)P(A_j)P(A_k), \\quad \\textrm{para } i \\neq j \\neq k; \\nonumber\\\\\n    \\vdots &  \\nonumber\\\\\n    P(\\cap_{i = 1}^{n} A_i) & = \\prod_{i = 1}^{n}P(A_i).\n\\end{align}\n\\tag{5.35}\\]\n\n\nPaulo poderia indagar, se os eventos \\(M_i\\) e \\(D\\) são independentes ou dependentes. Contudo, pela Definição 5.20, temos que \\[\\begin{align*}\nP(D|M_i) & \\neq P(D) = 0,016 \\Rightarrow D \\textrm{ e } M_i \\textrm{, para } i = 1, 2, 3,\n\\end{align*}\\] logo, não são independentes.\n\nExemplo 5.24: Efeito de multiplicidadeRetomando as propriedades da probabilidade, Teorema 5.6, e agora com a abordagem da ideia de independência de eventos, Definição 5.21, um importante problema na área da estatística é o uso de comparações simultâneas (hipóteses), assunto previamente abordado no Capítulo 10 para uma única comparação. Entendemos por hipótese (\\(H_i\\)) uma afirmação realizada pelo pesquisador sobre uma determinada população. O objetivo de um teste é rejeitar a hipótese estudada. Mas como tudo em estatística não há certeza, a probabilidade de rejeitarmos uma hipótese verdadeira é dada por \\(\\alpha\\), isto é, o nível de significância do teste. Essa decisão é chamada de erro tipo I, e representaremos neste exemplo, pelo evento \\(H_i^c\\). Quando aplicamos simultaneamente \\(n\\) comparações, queremos garantir que o nível de significância global do teste de hipóteses seja no máximo \\(\\alpha\\). Esta área da estatística é chamada de procedimento de comparação múltipla.\nMuitos procedimentos ou testes que se baseiam nesse tipo de problema usam como referência a taxa de erro por experimento, que representa a probabilidade de ao menos uma hipótese verdadeira ser rejeitada. Para isso, pensemos em \\(n = 10\\) comparações (hipóteses) verdadeiras e independentes, \\(H_i\\), \\(i =1, 2, \\ldots, 10\\). A probabilidade de cada comparação não ser rejeitada é dada por \\(P(H_i) = 1 -\\alpha\\). Ao passo que, a probabilidade de cada hipótese verdadeira ser rejeitada erroneamente, evento \\(H_i^c\\), é dada por \\(P(H_i^c) = \\alpha\\). Assim, a probabilidade de ao menos uma comparação ser erroneamente rejeitada é dada por: \\[\n\\begin{align}\n    P\\left(\\bigcup^{10}_{i = 1}H_i^c\\right) & = 1 - P\\left(\\bigcap^{10}_{i = 1}H_i\\right).\n\\end{align}\n\\tag{5.36}\\] Vamos usar a ideia do evento complementar, isto é, a probabilidade de termos ao menos uma comparação rejeitada erroneamente é o mesmo que calcularmos a probabilidade do espaço amostral (\\(\\Omega\\)) menos a probabilidade de nenhuma comparação ser rejeitada erroneamente, que representa a interseção \\(\\cap^{10}_{i = 1}H_i\\).\nPara observarmos que isso é verdade, vamos simplificar para \\(n = 2\\). Vejamos, \\[\\begin{align*}\n  P(H_1^c \\cup H_2^c) & = P(H_1^c) + P(H_2^c) - P(H_1^c \\cap H_2^c) \\quad \\textrm{(independentes)}\\\\\n  &= P(H_1^c) + P(H_2^c) - P(H_1^c)P(H_2^c)\\\\\n  &= \\alpha + \\alpha - \\alpha \\times \\alpha\\\\\n  &= 2\\alpha - \\alpha^2,\n\\end{align*}\\] isto é, \\[\\begin{align*}\n    P(H_1^c \\cup H_2^c) & = 1 - P(H_1 \\cap H_2) \\quad \\textrm{(independentes)}\\\\\n    &= 1 - P(H_1)P(H_2)\\\\\n    &= 1 - (1 - \\alpha)(1 - \\alpha)\\\\\n    &= 1 - (1^2 - 2\\alpha + \\alpha^2)\\\\\n    &= 2\\alpha - \\alpha^2,\n\\end{align*}\\] ou ainda \\[\\begin{align*}\n    P[(H_1^c \\cap H_2)\\cup (H_1 \\cap H_2^c)\\cup (H_1^c \\cap H_2^c)] & = P(H_1^c \\cap H_2) + P(H_1 \\cap H_2^c) + \\\\\n    & \\quad + P(H_1^c \\cap H_2^c)~\\textrm{(disj. e indep.)}\\\\\n    &= P(H_1^c)P(H_2) + P(H_1)P(H_2^c)\\\\\n    & \\quad  + P(H_1^c) P(H_2^c)\\\\\n    &= \\alpha(1 - \\alpha) + (1 - \\alpha)\\alpha + \\alpha^2\\\\\n    &= 2\\alpha - \\alpha^2.\n\\end{align*}\\] Esses resultados foram possíveis porque a condição de independência existente nos eventos também implica em independência nos eventos complementares, Teorema 5.12. Retornando a expressão (5.36), e a condição de independência, obtemos \\[\\begin{align*}\n    P\\left(\\bigcup^{10}_{i = 1}H_i^c\\right) & = 1 - (1 - \\alpha)^{10}.\n\\end{align*}\\]\nSe considerássemos \\(\\alpha = 0,05\\), a probabilidade do erro tipo I por experimento é de 0,4013, isto é, \\(P\\left(\\cup^{10}_{i = 1}H_i^c\\right) = 0,4013\\). Fixando \\(\\alpha = 0,05\\) e variando o número de testes, podemos perceber pela Figura 5.3 que a taxa de erro por experimento aumenta rapidamente. Esse é o efeito de multiplicidade, um problemas dos procedimentos de comparações múltiplas. Os testes são desenvolvimentos tentando controlar esse tipo de problema, porque baseado no exemplo anterior para \\(n = 10\\), a chance de termos ao menos uma decisão errada de rejeitar uma hipótese verdadeira, quando achávamos que era de 0,05 na realidade foi de 0,4013, muito maior.\n\n\n\n\n\n\nFigura 5.3: Representação da taxa de erro por experimento em comparações simultâneas, em relação ao número de testes.\n\n\n\nNão aceitarmos a independência das comparações, podemos usar a desigualdade de Boole, Teorema 5.6 (\\(viii\\) e \\(ix\\)), e afirmar que no máximo a taxa de erro por experimento, para \\(\\alpha = 0,05\\) e \\(n = 10\\), é dada por:\n\\[\\begin{align*}\n  P\\left(\\bigcup^{10}_{i = 1}H_i^c\\right) & \\leq \\sum_{i = 1}^{10} P(H_i^c)\\\\\n                                          & \\leq n \\times \\alpha\\\\\n                                          & \\leq 10 \\times 0,05\\\\\n                                          & \\leq 0,5,\n\\end{align*}\\] que de fato é verdade, pois \\(0,4013 &lt; 0,5\\). Ou ainda, pela desigualdade de Bonferroni, Teorema 5.6 (\\(x\\)), dizemos que ao menos a probabilidade de todas as decisões serem corretas, isto é, de não rejeitarmos hipóteses verdadeiras simultaneamente, é ao menos\n\\[\\begin{align*}\n  P\\left(\\bigcap^{10}_{i = 1}H_i\\right) & \\geq 1 - \\sum_{i = 1}^{10}P(H_i^c)\\\\\n                                        & \\geq 1 - 10\\times 0,05\\\\\n                                        & \\geq 0,5.\n\\end{align*}\\]",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Probabilidades</span>"
    ]
  },
  {
    "objectID": "cap05.html#teobayes",
    "href": "cap05.html#teobayes",
    "title": "5  Probabilidades",
    "section": "5.5 Teorema de Bayes",
    "text": "5.5 Teorema de Bayes\nA grande questão agora é qual a máquina que Paulo deveria substituir com o propósito de aumentar seu lucro na empresa. A ideia será calcular \\(P(M_i|D)\\), isto é, dado um defeito na sandália qual a probabilidade de vindo da máquina \\(i\\)? A maior probabilidade será a máquina substituída. Entretanto, ainda não temos ferramenta para resolver essa resposta. Para isso, apresentamos o seguinte Teorema 5.10 a seguir.\n\nTeorema 5.10: Teorema de BayesConsidere o espaço amostral \\(\\Omega\\). Considere uma sequência de eventos \\(A_1, A_2, \\ldots, A_n\\) de \\(\\Omega\\), disjuntos, tal que \\(\\bigcup^{n}_{i = 1}A_i = \\Omega\\), e \\(B\\) um evento de \\(\\Omega\\), então a probabilidade de \\(A_k\\), para \\(k = 1, 2, \\ldots, n\\), dado que ocorreu o evento \\(B\\), denotado por \\(P(A_k|B)\\), é dado por: \\[\n\\begin{eqnarray}\n    P(A_k|B) = \\frac{P(B|A_k)P(A_k)}{\\sum_{i = 1}^{n}P(B|A_i)P(A_i)}, \\qquad k = 1, 2, \\ldots, n,\n\\end{eqnarray}\n\\tag{5.37}\\] para \\(P(A_k) &gt; 0\\) e \\(P(A_i) &gt; 0\\), sendo \\(i = 1, 2, \\ldots, n\\).\n\n\n\nProvaPara um \\(i\\) qualquer, temos \\[\\begin{align*}\n    P(A_i|B) &= \\frac{P(A_i\\cap B)}{P(B)}\\\\\n    \\textrm{ou} &\\\\\n    P(B|A_i) &= \\frac{P(B \\cap A_i)}{P(A_i)}.\n\\end{align*}\\] Isto implica que \\[\n    P(A_i\\cap B) = P(B)P(A_i|B) = P(A_i)P(B|A_i).\n\\] Pela lei da probabilidade total, a probabilidade de \\(B\\) pode ser dada por \\(P(B)\\) = \\(\\sum^{\\infty}_{i=1}\\) \\(P(A_i)\\) \\(P(B|A_i)\\). Portanto, \\[\nP(A_i| B) = \\frac{P(A_i)P(B|A_i)}{\\sum^{\\infty}_{i=1}P(A_i)P(B|A_i)},\n\\] prova concluída.\n\n\nTal é a sua importância, que um dos ramos de estudo da inferência estatística é baseado nesse teorema. O Teorema de Bayes fornece uma atualização do conhecimento já existente \\(P(A_k)\\), conhecido como “a priori”, por meio da ocorrência do evento \\(B\\). Essa atualização é a probabilidade “a posteriori” \\(P(A_k|B)\\).\nCom esse resultado, Paulo agora pode tomar uma decisão mais plausível, isto é, dado um defeito numa determinada sandália produzida na fábrica, qual a probabilidade desta ter sido produzida em cada uma das máquinas? \\[\\begin{align*}\n    P(M_1|D) = \\frac{0,01 \\times 0,50}{0,016} = 0,3125\\\\\n    P(M_2|D) = \\frac{0,02 \\times 0,40}{0,016} = 0,5000\\\\\n    P(M_3|D) = \\frac{0,03 \\times 0,10}{0,016} = 0,1875\\\\\n\\end{align*}\\] A tomada de decisão será substituir a máquina \\(M_2\\). Poderíamos ter tomado uma decisão equivocada se não fosse o teorema de Bayes.\nDevemos abrir uma discussão que ocorre muito frequente entre as Definições 5.10 e 5.20, isto é, eventos disjuntos e independência. Nas próprias definições, percebemos a distinção clara entre as características. A primeira se remete a eventos (conjuntos), e a segunda é uma condição probabilística dos eventos. Contudo, em determinados problemas ainda há muita confusão ao tentar resolvê-los. Assim, apresentemos o Teorema 5.11, a seguir.\n\nTeorema 5.11: Eventos disjuntos e independentesConsidere \\(A\\) e \\(B\\), dois eventos \\(\\Omega\\). Se \\(A\\cap B = \\emptyset\\) (eventos disjuntos), então \\(A\\) e \\(B\\) são independentes apenas, se e somente se, um dos eventos tiver probabilidade 0.\n\n\n\nProvaConsiderando que o evento \\(A\\) tenha probabilidade 0, isto é, \\(P(A) = 0\\), implica que \\(A = \\emptyset\\). Assim, \\(P(A\\cap B) = P(\\emptyset\\cap B) = P(\\emptyset) = 0\\). A condição de independência entre os dois eventos existe se \\(P(A)P(B) = P(A\\cap B)\\), e isso ocorre de fato, \\(P(A)P(B) = P(\\emptyset)P(B) = 0\\times P(B) = 0 = P(A\\cap B)\\), o que completa a prova.\n\n\nCaso esses eventos não tenham probabilidade \\(0\\), a condição \\(A \\cap B = \\emptyset\\) implica que estes são dependentes. Vejamos o Exemplo 5.25 adaptado de Morettin (2010), para elucidar essas definições.\n\nExemplo 5.25: Adaptado de Morettin (2010)A tabela abaixo dá a distribuição das probabilidade dos quatro tipos sanguíneos, numa certa comunidade.\n\n\n\nTipo sanguíneo\nA\nB\nAB\nO\n\n\n\n\nProbabilidade de ter o tipo especificado\n0,2\n\n\n\n\n\nProbabilidade de não ter o tipo especificado\n\n0,9\n0,95\n\n\n\n\nCalcular a probabilidade de que:\n\num indivíduo, sorteado ao acaso nessa comunidade, tenha o tipo O;\num indivíduo, sorteado ao acaso nessa comunidade, tenha o tipo A e tipo B ao mesmo tempo. Podemos afirmar, que estes são independentes?\ndois indivíduos, sorteados ao acaso nessa comunidade, tenham tipo A e tipo B, nessa ordem;\num indivíduo, sorteado ao acaso nessa comunidade, não tenha o tipo B ou não tenha o tipo AB.\n\nVejamos que os tipos sanguíneos são mutuamente exclusivos e formam a partição do espaço amostral, uma vez que não existe outro tipo sanguineo além dos informados e que não há indivíduo com dois tipos sanguíneos. Assim,\n\nConsideremos o evento A, os indivíduos da comunidade especificado do tipo sanguíneo A, tal que, \\(A = \\{\\omega_A \\in \\Omega: \\omega_A \\in A\\}\\); o evento B, os indivíduos da comunidade especificado do tipo sanguíneo B, tal que, \\(B = \\{\\omega_B \\in \\Omega: \\omega_B \\in B\\}\\); o evento \\(AB\\), os indivíduos da comunidade especificado do tipo sanguíneo AB, tal que, \\(AB = \\{\\omega_{AB} \\in \\Omega: \\omega_{AB} \\in AB\\}\\); o evento \\(O\\), os indivíduos da comunidade especificado do tipo sanguíneo O, tal que, \\(O = \\{\\omega_O \\in \\Omega: \\omega_O \\in O\\}\\). Desse modo, o espaço amostral é dado por \\(\\Omega = \\{\\omega_A, ~\\omega_B, ~\\omega_{AB}, ~\\omega_O\\}\\), cujos elementos de \\(\\omega\\) devem estar apenas em um dos eventos anteriores, e que a união de todos os elementos desses formam o espaço amostral, logo esses eventos formam uma partição do espaço amostral (Definição 5.19). Observe também que os elementos não são equiprováveis, como mostrado na tabela de probabilidades na própria questão. Assim, \\(P(\\Omega)\\) \\(=\\) \\(P(A)\\) \\(+\\) \\(P(B)\\) \\(+\\) \\(P(AB)\\) \\(+\\) \\(P(O)\\) \\(\\Rightarrow\\) \\(1\\) \\(=\\) \\(0,2000\\) \\(+\\) \\(0,1000\\) \\(+\\) \\(0,0500\\) \\(+\\) \\(P(O)\\) \\(\\Rightarrow\\) \\(P(O)\\) \\(=\\) \\(0,6500\\);\nEste ítem merece uma atenção. Como os eventos \\(A\\) e \\(B\\) são multumente exclusivos, logo \\(P(A \\cap B) = 0\\), e estes não são independentes pois nenhum tem probabilidade 0 (Teorema 5.11), logo \\(A\\) e \\(B\\) são eventos dependentes;\nDiferentemente do espaço amostral anterior, neste temos uma combinação de 16 possibilidades a cardinalidade de \\(\\Omega\\), uma vez que temos 4 possibilidades para o primeiro indivíduo e mais 4 possibilidades para o segundo indivíduo, isto é, \\(\\Omega\\) \\(=\\) \\(\\{(\\omega_A, \\omega_A)\\), \\((\\omega_A, \\omega_B)\\), \\((\\omega_A, \\omega_{AB})\\), \\((\\omega_A, \\omega_O)\\), \\((\\omega_B, \\omega_A)\\), \\((\\omega_B, \\omega_B)\\), \\((\\omega_B, \\omega_{AB})\\), \\((\\omega_B, \\omega_O)\\), \\((\\omega_{AB}, \\omega_A)\\), \\((\\omega_{AB}, \\omega_B)\\), \\((\\omega_{AB}, \\omega_{AB})\\), \\((\\omega_{AB},\\) \\(\\omega_O)\\), \\((\\omega_O, \\omega_A)\\), \\((\\omega_O, \\omega_{B})\\), \\((\\omega_O, \\omega_{AB})\\), \\((\\omega_O, \\omega_O)\\) \\(\\}\\). Uma vez determinada as probabilidades de especificação em indivíduos diferentes, a probabilidade de especificar o tipo sanguíneo A em um indivíduo da comunidade não interfere em nada na probabilidade de especificar o tipo sanguíneo de um outro indivíduo dessa mesma comunidade (Uma ressalva é válida, no sentido também que estamos desconsiderando indivíduos consanguíneos, isto é, com grau de parentesco). Assim, a probabilidade de especificar o tipo sanguíneo desses dois indivíduos simultaneamente é \\(P(A)\\times P(B) = 0,2000 \\times 0,1000 = 0,0200\\). De outro modo, temos que: \\[\\begin{align*}\n      P(A \\cap B) & = P(\\{\\omega_A, ~\\omega_B\\})\\\\\n                  & = P(\\underbrace{\\omega_A \\in A}_{\\textrm{Indivíduo I}} \\textrm{ e } \\underbrace{\\omega_B \\in B}_{\\textrm{Indivíduo II}})\\\\\n                  & = P(\\omega_A \\in A) \\times P(\\omega_B \\in B)\\\\\n                  & = P(A) \\times P(B)\\\\\n                  & = 0,2000 \\times 0,0100\\\\\n                  & = 0,0200;\n\\end{align*}\\]\nAgora os eventos “não ter o tipo sanguíneo especificado” não implica que os eventos sejam mutuamente exclusivos pelo fato dos eventos “ter o tipo sanguíneo especificado” terem sido disjuntos. Veja, o evento não ter o tipo sanguínio AB e o evento não ter o tipo sanguíneo B, pode existir indivíduos comum a estes dois eventos, por exemplo, um indivíduo do tipo sanguíneo A ou O, e a probabilidade destes não é zero, logo, os eventos não ter o tipo sanguínio AB e não ter o tipo sanguíneo B não são disjuntos. Entretanto, esses eventos são independentes, pois a probabilidade de um evento não influencia na probabilidade do outro. Assim, \\[\n\\begin{align}\n      P[(AB)^c \\cup B^c] & = P[(AB)^c] + P(B^c) - P[(AB)^c \\cap B^c] \\nonumber\\\\\n      & = 0,9500 + 0,9000 - P[(AB)^c \\cap B^c].\n\\end{align}\n\\tag{5.38}\\]\n\nVejamos o evento \\((AB)^c = A\\cup B \\cup O\\) e o evento \\(B^c = A\\cup AB \\cup O\\). A interseção entre estes é \\((AB)^c \\cap B^c = A\\cup O\\), em que A e O são disjuntos, assim, \\[\n\\begin{align}\n     P[(AB)^c \\cap B^c] & = P(A\\cup O) = P(A) + P(O) \\nonumber\\\\\n                        & = 0,20 + 0,65 = 0,85.\n\\end{align}\n\\tag{5.39}\\] Substituindo (5.39) em (5.38), segue que \\[\n\\begin{align*}\n  P[(AB)^c \\cup B^c] & = 0,95 + 0,90 - 0,85 = 1.\n\\end{align*}\n\\] De outro modo, \\[\n\\begin{align}\n  P[(AB)^c \\cup B^c] & = P[(AB \\cap B)^c]  \\quad \\textrm{(Lei DeMorgan)}\\nonumber\\\\\n  & = 1 - P[(AB \\cap B)] \\quad \\textrm{(Evento complementar)} \\nonumber\\\\\n  & = 1 - 0 \\quad \\textrm{(Evento disjunto)} \\nonumber\\\\\n  & = 1.\n\\end{align}\n\\tag{5.40}\\] Ao final, temos a tabela completada da seguinte forma:\n\n\n\n\n\n\n\n\n\n\nTipo sanguíneo\nA\nB\nAB\nO\n\n\n\n\nProbabilidade de ter o tipo especificado\n0,20\n0,10\n0,05\n0,65\n\n\nProbabilidade de não ter o tipo especificado\n0,80\n0,90\n0,95\n0,35\n\n\n\nVale a pena discutirmos sobre a independência nessa situação. Quan-do falamos na especificação do tipo sanguínio é fato que um mesmo elemento não pode ser especificado em dois ou mais tipos sanguíneo. Fica claro que os eventos A, AB, B e O, são disjuntos. Agora, será que a probabilidade de especificar, por exemplo, o tipo sanguíneo A, não interfere na probabilidade do tipo sanguíneo B, ou qualquer um outro tipo sanguíneo? Observe que uma vez especificado a probabilidade de um determinado tipo sanguíneo, por exemplo, tipo A, não haverá mais chances de ele ter o tipo sanguíneo B, logo a probabilidade de B ocorrer é 0. Assim, a condição de ter especificado o tipo sanguíneo A alterou a probabilidade de especificar o tipo sanguíneo B. Logo estes eventos são dependentes.\n\n\nPodemos ainda expressar mais dois teoremas para complementar as afirmações feitas no Exemplo 5.25, e suas implicações em relação aos eventos serem independentes e eventos disjuntos. Inicialmente, apresentamos o Teorema 5.12 como uma implicância da independência de eventos, a seguir.\nPodemos ainda expressar mais dois teoremas para complementar as afirmações feitas no Exemplo 5.25, e suas implicações em relação aos eventos serem independentes e eventos disjuntos. Inicialmente, apresentamos o Teorema 5.12 como uma implicância da independência de eventos, a seguir.\n\nTeorema 5.12\nSe A e B são eventos independentes, não vazio, definidos em \\(\\Omega\\), então\n\n\\(A\\) e \\(B^c\\) também são independentes;\n\\(A^c\\) e \\(B\\) também são independentes;\n\\(A^c\\) e \\(B^c\\) também são independentes.\n\n\n\n\nProvaUsando as seguintes equivalências: \\[\n  P(A) = P(A\\cap B) + P(A\\cap B^c),\n\\tag{5.41}\\]\n\\[\nP(A^c) = P(A^c\\cap B) + P(A^c \\cap B^c),\n\\tag{5.42}\\]\n\\[\nP(B) = P(B\\cap A) + P(B \\cap A^c), \\textrm{ e }\n\\tag{5.43}\\]\n\\[\nP(B^c) = P(B^c\\cap A) + P(B^c\\cap A^c),\n\\tag{5.44}\\] e a condição de que \\(P(A\\cap B) = P(A)P(B)\\) (independentes), então usando (5.41) temos \\[\\begin{align*}\n  P(A\\cap B^c) & = P(A) - P(A)P(B)\\quad \\textrm{(Independência)}\\\\\n                  & = P(A)[1 - P(B)] = P(A)P(B^c),\n\\end{align*}\\] o que prova o ítem (a). Usando (5.43) pelo mesmo raciocínio, provamos o ítem (b). Usando o resultado do ítem (a), já provado, e a condição de independência na expressão (5.44), temos \\[\\begin{align*}\n  P(A^c \\cap B^c) & = P(B^c) - P(B^c)P(A)\\\\\n                  & = P(B^c)[1 - P(A)] = P(B^c)P(A^c),\n\\end{align*}\\] o que prova o ítem (c), concluindo assim, a prova do teorema.\n\n\nPor fim, o Teorema 5.13 apresenta uma implicância sobre eventos disjuntos, a seguir.\n\nTeorema 5.13Sejam dois eventos A e B em \\(\\Omega\\). Se \\(A\\cap B = \\emptyset\\), então \\(A^c \\cap B^c \\neq \\emptyset\\), a menos que A e B sejam partição do espaço amostral.\n\n\n\nProvaConsidere \\(A\\cap B = \\emptyset\\) e que \\[\n\\begin{align}\n      A \\cup B & = (A\\cap B^c) \\cup (A\\cap B) \\cup (A^c \\cap B) \\nonumber\\\\\n               & = (A\\cap B^c) \\cup (A^c \\cap B) \\nonumber\\\\\n               & \\neq \\Omega \\quad \\textrm{(A e B não são partição do espaço amostral)}.\n\\end{align}\n\\tag{5.45}\\]\nUsando a Lei de Morgan \\(A^c\\cap B^c = (A\\cup B)^c\\), logo percebemos pela expressão (5.45) que \\(A^c\\cap B^c \\neq \\emptyset\\), o que completa a prova.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Probabilidades</span>"
    ]
  },
  {
    "objectID": "cap05.html#valeatoria",
    "href": "cap05.html#valeatoria",
    "title": "5  Probabilidades",
    "section": "5.6 Variável Aleatória",
    "text": "5.6 Variável Aleatória\nEm estatística, avaliamos um experimento não pelos eventos em si, mas por uma função definida no espaço amostral, que associa o evento a um número real. Chamamos essa função de variável aleatória, denotada por uma letra maiúscula, \\(X\\) ou \\(X(.)\\). Por exemplo, no Exemplo 5.24 verificamos o efeito de multiplicidade de \\(n\\) comparações, e ao invés de computarmos a probabilidade da taxa de erro tipo I por experimento observando o evento \\(\\cup^{n}_{i = 1}H_i^c\\) , isto é, \\(P(\\cup^{n}_{i = 1}H_i^c)\\), podemos olhar para uma variável aleatória \\(X(\\omega)\\) que contabiliza o número de erros possíveis, isto é, \\(\\{X \\geq 1\\}\\). Considerando que o suporte de \\(X\\) seja \\(\\{0, 1, 2, \\ldots, n\\}\\), então a probabilidade pode ser expressa como \\(P(X \\geq 1)\\), tornando mais simples a notação para o cálculo desejado. O necessário é entender o modelo probabilístico de \\(X\\), que será abordado posteriormente.\nAlguns autores criticam o termo “variável aleatória”, já que a mesma é uma função. Como essa definição ficou conhecida com esse nome, seria um equívoco tentar renomeá-la, do qual é apresentada na Definição 5.22, a seguir.\n\nDefinição 5.22: Variável AleatóriaSeja o espaço amostral \\(\\Omega\\) de um experimento, então uma função \\(X: \\Omega \\to \\mathbb{R}\\) é chamada de variável aleatória, isto é, considerando \\(\\omega \\in \\Omega\\), então a variável aleatória, \\(X(\\omega)\\), é uma função com domínio em \\(\\Omega\\) e imagem no conjunto dos reais \\(B\\), tal que \\(B = \\{x \\in \\mathbb{R}: X(\\omega) = x,~\\omega \\in \\Omega\\}\\).\n\n\nConsideramos \\(X\\) uma variável aleatória discreta, quando \\(B\\) representa um conjunto contável (ou enumerável) de valores (finito ou infinito). Por outro lado, se \\(B\\) for um conjunto não contável (ou não enumerável), \\(X\\) será denominada de variável aleatória contínua. O fato é que, independente da natureza da variável aleatória, ela induz a um novo espaço amostral na reta real.\n\nExemplo 5.26\nPara explicar a definição de uma variável aleatória será considerado o exemplo, no qual duas variedades de uma espécie \\(A\\) (\\(A_1\\), \\(A_2\\)) e três de outra espécie \\(E\\) (\\(E_1\\), \\(E_2\\) e \\(E_3\\)) são disponibilizados para uma pesquisa. Uma amostra de duas variedades (\\(n=2\\)) é extraída. O espaço amostral dos resultados desse experimento, segue,\n\\[\n\\Omega=\\left\\lbrace \\begin{array}{ccccc}\n(A_1,A_2) & (A_1,E_1) & (A_1,E_2) & (A_1,E_3) & (A_2,E_1)\\\\\n(A_2,E_2) & (A_2,E_3) & (E_1,E_2) & (E_1,E_3) & (E_2,E_3)\n\\end{array}\n\\right\\rbrace.\n\\]\nSe for considerado o número de variedades da espécie \\(A\\) na amostra sorteada, percebemos que os valores encontrados são: \\(0\\), \\(1\\) e \\(2\\). É possível associar a esses valores alguns pontos do espaço amostral \\(\\Omega\\), formando subconjuntos que seguem:\n\n\n\n\n\n\n\n\\(\\mathbf{X}(\\omega)\\)\nEventos (\\(\\mathbf{C_i}\\))\n\n\n\n\n\\(0\\)\n\\(C_1 = \\{(E_1,E_2)\\), \\((E_1,E_3)\\), \\((E_2,E_3)\\}\\)\n\n\n\\(1\\)\n\\(C_2 = \\{(A_1,E_1)\\), \\((A_1,E_2)\\), \\((A_1,E_3), (A_2,E_1), (A_2,E_2),(A_2,E_3)\\}\\)\n\n\n\\(2\\)\n\\(C_3 = \\{(A_1,A_2)\\}\\)\n\n\n\n\n\nNo Exemplo 5.26, criamos uma partição do espaço amostral (\\(\\Omega\\)) e associamos com um outro espaço amostral induzido (\\(\\Omega_X\\)), por meio da variável aleatória \\(X\\), como pode ser apresentado na Figura 5.4.\n\n\n\n\n\n\nFigura 5.4: Espaço amostral e espaço amostral induzido pela variável aleatória \\(X\\).\n\n\n\nPara o exemplo do experimento do sorteio das duas variedades, definindo-se \\(X\\) como sendo a variável aleatória relativa a contagem de variedades da espécie \\(A\\), verificamos que os valores possíveis para \\(x\\) são: \\(0\\), \\(1\\), \\(2\\). É comum representar a variável por \\(X\\) (letra maiúscula) e os seus valores ou realizações por \\(x\\) (a respectiva letra minúscula).\n\nDefinição 5.23: Realização de uma variável aleatóriaDado um \\(\\omega \\in \\Omega\\), então \\(x = X(\\omega) \\in \\mathbb{R}\\) representa a realização da variável aleatória \\(X\\).\n\n\nConsiderando ainda o Exemplo 5.26, os pontos de \\(\\Omega\\) são equiprováveis, então a probabilidade de \\(X\\) assumir um dado valor \\(x\\) será denotado por \\(P_X(X=x)\\), \\(P(X=x)\\), \\(p_X(x)\\) ou \\(p_i\\) com \\(i=1,2,\\ldots\\). O primeiro caso, servirá para diferenciar \\(P_X(.)\\) uma probabilidade induzida por \\(X\\) quando estivermos relacionando com a probabilidade dos eventos equivalentes do espaço amostral. Para este último, usaremos apenas a notação \\(P(.)\\) sendo denominada também de função de probabilidade de \\(X\\), para o caso da variável discreta. Quando não tivermos fazendo essa relação, usaremos a probabilidade para \\(X\\) apenas como \\(P(X = x)\\), por exemplo. As duas últimas notações (\\(p_X(x)\\) ou \\(p_i\\)), serão usadas quando estivermos nos referindo a probabilidade associadas as variáveis aleatórias discretas, que a chamaremos de função de probabilidade.\nSupondo que desejamos calcular a probabilidade de \\(C_3\\) ocorrer, temos: \\[\n\\begin{align}\n  P(C_3) & = P(\\{\\omega \\in \\Omega: \\omega \\in C_3\\}) \\nonumber\\\\\n         & = P(\\{(A_1,A_2)\\}) \\nonumber\\\\\n         & = \\frac{\\#\\{(A_1,A_2)\\}}{\\#\\Omega} = \\frac{1}{10}.\n\\end{align}\n\\tag{5.46}\\]\nVamos observar que de modo equivalente iremos calcular a probabilidade do evento \\(C_3\\) agora olhando para a variável \\(X\\), tal que \\(P(C_3) = p_X(2) = P(X = 2)\\), que segue,\n\\[\n\\begin{align}\n  p_X(2) = P_X(X = 2) & = P_X(D), \\quad (D = \\{2\\}\\textrm{, Figura 5.4)   } \\nonumber\\\\\n                    & = P_X(\\{x \\in \\Omega_X: X(\\omega) \\in D, ~\\omega \\in \\Omega\\}) \\nonumber\\\\\n                    & = P(X^{-1}(2))\\nonumber\\\\\n                    & = P(\\{\\omega \\in \\Omega: X(\\omega) = 2\\})\\nonumber\\\\\n                    & = P(\\{\\omega \\in \\Omega: \\omega \\in C_3\\})\\nonumber\\\\\n                    & = P(\\{(A_1,A_2)\\})\\nonumber\\\\\n                    & = P(C_3)\\nonumber\\\\\n                    & = \\frac{1}{10}, \\quad \\textrm{(resultado 5.46)}.\n\\end{align}\n\\tag{5.47}\\]\nPortanto, a partir de agora em diante, iremos calcular as probabilidades dos eventos a partir da variável aleatória. Para um mesmo espaço amostral, é possível associar outras variáveis aleatórias. No exemplo anterior considerado, poderíamos pensar em uma variável aleatória \\(Y\\) que representasse o número de espécies da variedade \\(E\\). %A função de probabilidade de \\(X\\) define a distribuição de probabilidade dessa variável aleatória, porque \\(X\\) é uma variável aleatória discreta.\nDessa forma, a distribuição de probabilidade pode ser vista como uma correspondência que associa as probabilidades aos valores de uma variável aleatória, que é função do espaço amostral, definida na próxima seção.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Probabilidades</span>"
    ]
  },
  {
    "objectID": "cap05.html#distx",
    "href": "cap05.html#distx",
    "title": "5  Probabilidades",
    "section": "5.7 Distribuição de \\(X\\)",
    "text": "5.7 Distribuição de \\(X\\)\nSabemos que uma variável aleatória \\(X\\), é função dos possíveis resultados \\(\\omega \\in \\Omega\\), e que estes possíveis resultados assumem diferentes valores com diferentes probabilidades. Assim, \\(w\\) é aleatório, e por consequência \\(X\\) também, como já falado anteriormente. Por isso, a variável por ser aleatória, a probabilidade de \\(X\\) assumir um determinado valor \\(x\\) ou está em uma determinada região do espaço amostral induzido, passa a ser importante. Assim, apresentamos a relação entre \\(X\\) e sua probabilidade \\(P(.)\\) por meio da Definição 5.24, a seguir.\n\nDefinição 5.24: Distribuição de \\(X\\)O conjunto de probabilidades \\[\nP_X(X(\\omega) \\in B) = P(\\{w \\in \\Omega: X(\\omega) \\in B,~B \\subset \\mathbb{R}\\}),\n\\] para todos os subconjuntos de \\(B \\in \\Omega_X\\), em que \\(B\\) é um subconjunto do espaço amostral induzido, é a distribuição de uma variável aleatória \\(X\\).\n\n\nRetornando ao Exemplo 5.26, apresentamos a distribuição de \\(X\\) no Exemplo 5.27.\n\nExemplo 5.27\nConsiderando que \\(X\\) representa o número de variedades da espécie \\(A\\), apresentamos a distribuição de \\(X\\):\n\n\n\n\\(X\\)\n\\(0\\)\n\\(1\\)\n\n\n\n\n\\(P(X = x)\\)\n\\(3/10\\)\n\\(6/10\\)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Probabilidades</span>"
    ]
  },
  {
    "objectID": "cap05.html#fda",
    "href": "cap05.html#fda",
    "title": "5  Probabilidades",
    "section": "5.8 Função de distribuição (FD ou FDA)",
    "text": "5.8 Função de distribuição (FD ou FDA)\nPara entendermos o comportamento estatístico de uma variável aleatória, temos que definir sua função de distribuição, em que são caracterizados por eventos da forma \\(B = (-\\infty,x]\\).\n\nDefinição 5.25: Função de distribuição de \\(X\\)A função de distribuição (FD) ou função de distribuição acumulada (FDA) de uma variável aleatória \\(X\\), é definida por \\[\nF_X(x)=P(X\\in (-\\infty,x])=P(X \\leq x), \\ x\\in\\mathbb{R}.\n\\]\n\n\nPara que não haja confusão sobre função de distribuição a qual está relacionada com a variável aleatória \\(X\\), usamos o subscrito \\(F_X\\). Para entendermos melhor sobre a função de distribuição, mostraremos suas propriedades.\n\nTeorema 5.14: Propriedades da função de distribuição\nUma função de distribuição de uma variável aleatória \\(X\\) obedece as seguintes propriedades:\n\n\\(\\lim_{x\\rightarrow\\infty}F_X(x)=1\\) e \\(\\lim_{x\\rightarrow -\\infty}F_X(x)=0\\);\n\\(F_X(x)\\) é uma função não decrescente, isto é, \\(F_X(x)\\leq F_X(y)\\) sempre que \\(x\\leq y\\), \\(\\forall x,y \\in \\mathbb{R}\\);\n\\(F_X(x)\\) é contínua à direita, ou seja, para um número \\(x\\), \\(\\lim_{x_n\\downarrow x}F_X(x_n)\\downarrow F_X(x)\\).\n\n\n\n\nProva\n\nAplicando a continuidade da probabilidade (Teorema 5.6, \\(vii\\)). Observe que para \\(x_n\\downarrow -\\infty\\), os eventos \\([X\\leq x_n]=\\{w\\in\\Omega:X(w)\\leq x_n\\}\\) têm como o limite o conjunto vazio. Logo \\(F_X(x_n)=P(X\\leq x_n)\\downarrow 0\\). Tomando \\(x_n\\uparrow\\infty\\), os eventos \\([X\\leq x_n]\\uparrow\\Omega\\) e, portanto \\(F_X(x_n)=P(X\\leq x_n)\\uparrow 1\\);\nNote que \\([X\\leq x]\\subset [X\\leq y]\\) sempre que \\(x\\leq y\\) (Teorema 5.6, \\(iv\\)). Logo as probabilidades satisfazem à desigualdade: \\[\nF_X(x)=P(X\\leq x)\\leq P(X\\leq y)=F_X(y).\n\\] Como \\(x\\) e \\(y\\) são arbitrários, concluímos que \\(F\\) é não decrescente.\nSeja \\(x\\in\\mathbb{R}\\) e considere uma sequência \\(\\{x_n,\\ n\\in\\mathbb{N}^{+}\\}\\) tal que \\(x_n\\downarrow x\\), ou seja, os \\(x_n\\)’s se aproximam de \\(x\\) pela direita ou por valores superiores a \\(x\\). Então, \\([X\\leq x_n]\\downarrow [X\\leq x]\\), e assim, \\(F_X(x_n)\\downarrow F_X(x)\\). Como o resultado vale para qualquer \\(x\\), a propriedade está verificada.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Probabilidades</span>"
    ]
  },
  {
    "objectID": "cap05.html#natva",
    "href": "cap05.html#natva",
    "title": "5  Probabilidades",
    "section": "5.9 Natureza das variáveis aleatórias",
    "text": "5.9 Natureza das variáveis aleatórias\nSe \\(X\\) é uma variável aleatória definida em \\(\\Omega\\), estamos interessados em calcular probabilidade de eventos que envolvem \\(X\\), isto é, \\(P(w\\in\\Omega:X(w)\\in B)\\) com \\(B \\subset \\mathbb{R}\\). A forma que essas probabilidades são calculadas depende da natureza particular de \\(X\\).\n\n5.9.1 Variável aleatória discreta\nFormalmente, definimos\n\nDefinição 5.26: Variável Aleatória DiscretaSeja o espaço amostral \\(\\Omega\\) de um experimento, então a função \\(X: \\Omega \\to \\mathbb{R}\\) é chamada de variável aleatória discreta se imagem é um subconjunto contável \\(B\\), finito ou infinito dos reais, tal que \\(B = \\{x \\in \\mathbb{R}: X(\\omega) = x,~\\omega \\in \\Omega\\}\\).\n\n\nNa realidade, dizer que os valores que a variável aleatória discreta assume em \\(\\mathbb{R}\\) é dizer que \\(Im(X(w)) \\in B\\).\n\nExemplo 5.28\nSuponha que haja alguma chance de um bit transmitido de um canal digital com erro. Consideremos um bit com erro representado pela letra \\(E\\), e um bit recebido sem erro, representado por \\(B\\). Levando em consideração que a transmissão dos bits no canal digital sejam independentes, estamos interessados em verificar nos próximos 3 bits quantos estarão com erro. Desse modo, podemos assumir que o espaço amostral desse experimento é representado da seguinte forma: \\[\\begin{align*}\n\\Omega = \\{(BBB), (EBB), (BEB), (BBE), (EEB), (EBE), (BEE), (EEE)\\}.\n\\end{align*}\\] A variável aleatória representa o número de bits errados nos próximos três transmitidos. Assim, esta função assume em um conjunto \\(B\\) nos reais, tal que: \\[\\begin{align*}\nB = \\{0, 1, 2, 3\\}.\n\\end{align*}\\] Por exemplo, se \\(\\omega = (BBB)\\) implica que \\(X((BBB)) = 0\\). Observamos na Tabela 5.1, os demais casos. Logo, como a variável assume valores em um conjunto \\(B\\) contável, dizemos que \\(X\\) é uma variável aleatória contínua.\n\n\n\nTabela 5.1: Espaço amostral e induzido pela variável aleatória discreta \\(X\\).\n\n\n\n\n\n\\(\\omega \\in  \\Omega\\)\n\\(X(\\omega) \\in B\\)\n\n\n\n\n\\((BBB)\\)\n\\(0\\)\n\n\n\\((EBB)\\)\n\\(1\\)\n\n\n\\((BEB)\\)\n\\(1\\)\n\n\n\\((BBE)\\)\n\\(1\\)\n\n\n\\((EEB)\\)\n\\(2\\)\n\n\n\\((EBE)\\)\n\\(2\\)\n\n\n\\((BEE)\\)\n\\(2\\)\n\n\n\\((EEE)\\)\n\\(3\\)\n\n\n\n\n\n\n\n\n\n5.9.1.1 Função de probabilidade (FP)\nA probabilidade dos valores de \\(X\\) que pertencem a \\(B\\) é dada por \\[\\begin{eqnarray*}\n    P(X\\in B)&=& P(X=x_1\\textrm{ ou }X=x_2\\textrm{ ou }\\ldots)\\\\\n    &=& P(X=x_1)+P(X=x_2)+\\ldots = \\sum_{x\\in B}p_X(x),\n\\end{eqnarray*}\\] em que \\(p_X(x)\\), \\(x\\in \\mathbb{R}\\), é a função de probabilidade de \\(X\\), definida por \\(p_X(x)=P(X=x)\\). Assim, a probabilidade de um evento envolvendo \\(X\\) é encontrado pela sumarização das funções de probabilidades dos conjuntos de pontos favoráveis ao evento. Em particular, a função de probabilidade determina as probabilidades de os valores possíveis que \\(X\\) possa assumir.\nDessa forma, podemos definir a função de probabilidade da variável aleatória discreta \\(X\\), a seguir.\n\nDefinição 5.27: Função de ProbabilidadeSeja \\(X\\) uma variável aleatória discreta, então sua função de probabilidade, \\(p_X:\\mathbb{R}\\rightarrow [0,1]\\), é definida por: \\[\np_X(x)= P_X(X=x) = P(X=x) = P(\\{w\\in\\Omega:X(w)=x\\}),   \n\\] sendo \\(\\sum_xP_X(x)=1\\).\n\n\nEssa definição nos permite observar que para valores distintos de \\(X\\), se o seu suporte é o conjunto \\(\\mathcal{X}=\\{x_1,x_2,\\ldots\\}\\), então \\(\\Omega=\\bigcup_{n}\\{w:X(w)=x_n\\}=\\bigcup_{n}\\{X=x_n\\}\\) e \\(\\{X=x_i\\}\\cap\\{X=x_j\\}=\\emptyset\\) para \\(i\\neq j\\). Logo, \\(1=P(\\Omega)=\\sum_np_X(x_n)\\).\nDe outra forma, definimos\n\nDefinição 5.28: Suporte de \\(X\\) (v.a. discreta)O suporte de uma variável aleatória discreta, denotado por \\(\\mathcal{X}\\), tal que \\(\\mathcal{X} \\subset \\mathbb{R}\\) é dado por \\[\n\\begin{align}\n  \\mathcal{X} & = \\{x:~ p_X(x) &gt; 0\\}.\n\\end{align}\n\\tag{5.48}\\]\n\n\nIsso significa que as realizações de \\(X\\), Definição 5.23, pertencem a \\(\\mathcal{X}\\), e que o suporte é a imagem de \\(X\\) contida nos reais tais que a probabilidade de cada elemento ocorrer é maior que zero. Ao passo que, qualquer elemento fora do suporte de \\(X\\), isto é, \\(x \\in \\mathcal{X}^c\\), tem probabilidade nula. Vejamos o Exemplo 5.29, para um melhor entendimento de tudo o que falamos.\n\nExemplo 5.29Retornando ao exemplo das variedades, Exemplo 5.26, podemos apresentar a distribuição de probabilidade da variável \\(X\\), número de variedades da espécie A na amostra sorteada, \\(n=2\\). Cada ponto do espaço amostral amostral foi considerado como equiprovável.\n\n\n\n\n\n\n\n\\(\\mathbf{X}\\): número de variedades de \\(\\mathbf{A}\\)\n\\(\\mathbf{p_X(x)}\\): probabilidade\n\n\n\n\n0\n3/10\n\n\n1\n6/10\n\n\n2\n1/10\n\n\n\nDessa forma, o suporte de \\(X\\) é \\(\\mathcal{X} = \\{0, 1, 2\\}\\), e cada elemento é uma realização da variável aleatória. Qualquer valor fora do suporte de \\(X\\) tem probabilidade zero, por exemplo, \\(p_X(3) = 0\\).\n\n\nA representação gráfica da função de probabilidade é dada por meio do gráfico de hastes ou bastão, para representar a discretização das realizações no suporte de \\(X\\), Figura 5.5.\n\n\n\n\n\n\nFigura 5.5: Representação gráfica da função de probabilidade para os dados do Exemplo 5.29.\n\n\n\n\n\n5.9.1.2 FDA para as variáveis aleatórias discretas\nAnteriormente, afirmamos que a distribuição de \\(X\\) é dada por \\(P(X(\\omega) \\in B)\\), em que \\(B \\in \\mathbb{R}\\). Existe um caso especial, em que \\(B = (-\\infty, x]\\), em que \\(x \\in \\mathbb{R}\\). Assim, dizemos que \\(P(X(\\omega) \\in (\\infty, x])\\) representa a função de distribuição ou função de distribuição acumulada (FD ou FDA), e em notação temos \\(F_X(x) = P(X(\\omega) \\in (\\infty, x])\\). Para o caso das variáveis aleatórias discretas, usaremos a definição de função de probabilidade (Definição 5.28), sendo apresentada na Definição 5.29, a seguir.\n\nDefinição 5.29: Função de distribuição de uma v.a. discretaA função de distribuição de uma variável aleatória discreta \\(X\\) é a função \\(F_X:\\mathbb{R}\\rightarrow [0,1]\\), definida por \\[\nF_X(x)=P(X\\leq x)=\\sum_{x}p_X(x),\n\\] para todo \\(x\\in\\mathbb{R}\\).\n\n\nEssa função de distribuição tem a forma de escada sendo descontínua nos valores assumidos pela variável aleatória \\(X\\), Figura 5.6.\n\n\n\n\nCódigo R 5.1: FDA de uma variável aleatória discreta.\n\n\n# Anexando o pacote ao caminho de busca\nlibrary(leem)\n# Funcao de probabilidade\nshowcdf(prop = NULL)\n\n\n\n\n\n\n\n\n\n\nFigura 5.6: Gráfico da função de distribuição de \\(X\\).\n\n\n\n\n\nOutro ponto importante é que \\(x\\in\\mathbb{R}\\), isto é, \\(x\\) não necessariamente é elemento do suporte de \\(X\\). Percebemos na Figura 5.6, por exemplo, qualquer valor de \\(x\\) tal que \\(x_2 \\leq x &lt; x_3\\), \\(F_X(x) = F_X(x_2)\\). E percebemos que o suporte de \\(X\\) não contém um \\(x\\), tal que \\(x_2 &lt; x &lt; x_3\\). Logo, \\(P(X = x) = 0\\) neste ponto. A função de distribuição nos informa que devemos somar apenas as probabilidades para as realizações até \\(x \\in \\mathbb{R}\\). Para isto, olhamos para \\(\\mathcal{X}\\) e verificamos quais as realizações até \\(x\\) e somamos as suas probabilidades para o cômputo de \\(F_X(x)\\). Vejamos o Exemplo 5.30.\n\nExemplo 5.30\nConsidere um estudo hipotético do qual desejamos imunizar 1000 pessoas em uma comunidade rural da doença da COVID-19, por meio de uma determinada vacina. Supomos que sejam aplicados 5 doses em cada pessoa, em períodos espaçados, dessa vacina. A cada dose aplicada, as pessoas passam por uma série de avaliações para a verificar se adquiriu imunidade ou não. Caso se verifique a imunidade em uma determinada dose aplicada, esta pessoa não irá tomar a dose subsequente; caso contrário, seguirá tomando as doses subsequentes, até a 5ª dose. Os resultados completos, são apresentados a seguir.\n\n\n\nDoses\n1\n2\n3\n4\n5\n\n\nFrequência\n230\n270\n300\n120\n80\n\n\n\nConsiderando uma pessoa dessa comunidade sorteada ao acaso, poderíamos estar interessados em saber qual a probilidade dela ter recebido 2 doses? usando a ideia da probabilidade frequentista, a probabilidade desejada é de \\(270/1000\\) $= $ \\(0,27\\). Podemos assim obter a função de probabilidade para a variável aleatória número de doses recebidas, que também pode ser observado pela Figura 5.7, da seguinte forma:\n\n\n\nDoses\n1\n2\n3\n4\n5\n\n\n\\(p_i\\)\n0,23\n0,27\n0,30\n0,12\n0,08\n\n\n\n\n\n\n\n\n\nFigura 5.7: Função de probabilidade do número de doses da COVID-19, aplicados em 1000 pessoas.\n\n\n\nPela função de distribuição, podemos responder, por exemplo, a chance de uma determinada pessoa dessa população ter tomado até duas doses, da seguinte forma:\n\\[\n    F_X(2)=P(X\\leq 2)=P(X=1)+P(X=2)=0,50.\n\\]\nApesar da escolha de \\(x\\) ter sido sempre um número inteiro até agora, esse valor fica inalterado no intervalo \\([2,3)\\). Isto significa que, \\(F_X(2,3)\\), \\(F_X(2,45)\\) ou \\(F_X(2,99)\\) têm os mesmos valores que \\(F_X(2)\\). Por isso, escrevemos \\[\n    F_X(x)=P(X\\leq x)=0,50, \\ \\ \\textrm{para} \\ \\ 2\\leq x &lt; 3.\n\\]\nPor fim, apresentamos a função de distribuição para todo \\(x\\), como também o gráfico dessa função, Figura 5.8.\n\\[\n    F_X(x)=\\left\\lbrace  \\begin{array}{lcl}\n        0,& \\textrm{se}& x&lt;1;\\\\\n        0,23, & \\textrm{se} & 1\\leq x &lt;2;\\\\\n        0,50, & \\textrm{se} & 2\\leq x &lt; 3;\\\\\n        0,80, & \\textrm{se} & 3\\leq x &lt; 4;\\\\\n        0,92, & \\textrm{se} & 4\\leq x &lt; 5;\\\\\n        1, & \\textrm{se} & x\\geq 5.\n    \\end{array}\\right.\n\\]\n\n\n\n\n\n\nFigura 5.8: Função de distribuição do número de doses da COVID-19, aplicados em 1000 pessoas.\n\n\n\n\n\nAlém de mostrarmos o gráfico da FDA para um variável aleatória discreta, apresentamos as propriedades do Teorema 5.14 no Código R 5.2. Primeiro, na Figura Figura 5.9 verificamos a primeira propriedade do Teorema 5.14. Na Figura 5.10, conseguimos observar a segunda propriedade. Com a representação gráfica, fica mais fácil entender a implicância dos resultados encontrados no referido teorema. Observe na Figura 5.11 o porquê da \\(F_X\\) ser contínua à direita. Por exemplo, vamos assumir o ponto \\(a = 2\\) na Figura 5.8. Considerando que \\[\\begin{align*}\n  \\lim_{x \\to a^{+}}F(x) = F(a) = F(2) = 0,50.\n\\end{align*}\\] Logo, \\(F_X(x)\\) em \\(a\\) é contínua à direita. Ao passo que \\[\\begin{align*}\n  \\lim_{x \\to a^{-}}F(x) = 0,23 \\neq F(a) = F(2) = 0,50.\n\\end{align*}\\] Logo, \\(F_X(x)\\), em \\(a\\), não é contínua à esquerda.\n\n\n\n\nCódigo R 5.2: Propriedades da FDA de uma variável aleatória discreta.\n\n\n# Anexando o pacote leem\nlibrary(leem)\n# Propriedade 1\nshowcdf(prop = 1)\n\n\n\n\n\n\n\n\n\n\nFigura 5.9: Propriedade (\\(i\\)) do Teorema 5.14 para FDA de uma v.a. discreta.\n\n\n\n\n\n\n# Propriedade 1\nshowcdf(prop = 2)\n\n\n\n\n\n\n\nFigura 5.10: Propriedade (\\(ii\\)) do Teorema 5.14 para FDA de uma v.a. discreta.\n\n\n\n\n\n\n# Propriedade 1\nshowcdf(prop = 3)\n\n\n\n\n\n\n\nFigura 5.11: Propriedade (\\(iii\\)) do Teorema 5.14 para FDA de uma v.a. discreta.\n\n\n\n\n\nUma característica interessante é que da distribuição de probabilidade obtemos a função de distribuição e vice-versa, do qual apresentamos a seguir.\n\nTeorema 5.15: Relação entre \\(p_X\\) e \\(F_X\\)Considerando uma variável aleatória discreta \\(X\\), Definição 5.26, então a função de distribuição (\\(F_X\\)) pode ser obtida a partir da função de probabilidade (\\(p_X\\)), e vice-versa.\n\n\n\nProva\nSeja o suporte de \\(X\\) dado por \\(\\mathcal{X} = \\{x_1, x_2, \\ldots\\}\\), então:\n\nsupomos o conhecimento de \\(p_X(x)\\). Logo, \\(F_X(x) = \\sum\\limits_{x_i \\leq x}p_X(x_i) = \\sum\\limits_{x_i \\leq x}P_X(X = x_i)\\);\nsupomos o conhecimento de \\(F_X(x_i)\\), \\(\\forall x_i \\in \\mathcal{X}\\). Logo, \\(p_X(x_i) = F_X(x_i) - \\lim\\limits_{\\epsilon \\to 0}F_X(x_i - \\epsilon)\\), para \\(\\epsilon &gt; 0\\).\n\n\n\n\n\n\n5.9.2 Variável aleatória contínua\nObservamos que seria muito restritivo definir apenas variáveis aleatórias cujo resultado da função assumisse apenas em um conjunto contável. Por isso, uma outra natureza de variável aleatória modela situações cuja função assume em um conjunto infinito não contável dos reais, do qual apresentamos na Definição 5.30.\n\nDefinição 5.30: Variável Aleatória ContínuaSeja o espaço amostral \\(\\Omega\\) de um experimento, então a função \\(X: \\Omega \\to \\mathbb{R}\\) é chamada de variável aleatória contínua, se a sua imagem é um subconjunto \\(B\\), infinito não enumerável dos reais, e que \\[\\begin{align*}\n    P(X = x) = 0,\n\\end{align*}\\] para todo \\(x \\in \\mathbb{R}\\).\n\n\nExistem diversos exemplos de variáveis aleatórias contínuas, tais como: a carga (\\(g/cm\\)) em uma viga de uma determinada construção civil, a concentração de um corante (\\(g/l\\)) para fabricação de tintas, diâmetro de roldanas (\\(mm\\)) em uma máquina desenvolvida para o processo de conformação a frio com o objetivo de melhorar as propriedades ótimas de um fio de arame, dentre outras.\nAgora, supomos que estipulássemos o tempo de execução de um algoritmo computacional para uma determinada atividade no intervalo \\([0h,~1h]\\), como verificado na Figura 5.12.\n\n\n\n\n\n\nFigura 5.12: Tempo de execução de um algoritmo computacional.\n\n\n\nConsiderando \\(X\\) uma variável aleatória contínua que mede o tempo de execução do algoritmo no intervalo da Figura 5.12, qual seria a probabilidade dessa execução ser realizada em \\(0,5h\\), isto é, \\(P(X = 0,5)\\)? Sabemos que infinitas possibilidades são possíveis no intervalo. Se disséssemos que essa probabilidade é 0. Sim, exatamente, a probabilidade \\(P(X = 0,5) = 0\\).\nPara qualquer intervalo que assumíssemos, o fato de existir infinitas realizações para \\(X\\), se essa probabilidade fosse diferente de zero, por exemplo, um \\(\\phi_x\\) valor positivo próximo de zero, então \\(\\sum_{x \\in [0,1]} P(X = x) \\to \\infty\\), e isso seria uma contradição, de acordo com a Definição 5.17 (Axioma \\(i\\)), não importa o quão pequeno seja \\(\\phi_x\\). Mas não implica dizer que esta situação seria impossível, porque o evento \\(\\{X = 0,5\\}\\) existe no intervalo. Porém, como \\(P(\\Omega = [0,~1]) = 1\\), se todos os valores de \\(X\\) têm probabilidade 0?\n\n\n\n\n\n\nEvento certo não implica em certeza de ocorrência de seus elementos em um experimento!\n\n\n\nConsidere \\(X\\) uma variável aleatória contínua que assume valores no conjunto dos irracionais no intervalo \\([0,1]\\), similar ao exemplo que apresentamos na Figura 5.12. A probabilidade de \\(X\\) assumir um número racional, isso representa um evento certo e tem probabilidade 1, isto é, \\(P(\\{X = x_{\\mathbb{I}}\\} = \\{x_{\\mathbb{I}} \\in [0,1]: x_{\\mathbb{I}} \\in \\mathbb{I}\\}) = 1\\). Porém, um resultado possível é \\(1/2\\) que não é irracional. Da mesma forma, como afirmamos no início da seção que um evento com probabilidade \\(0\\) não implica que ele seja impossível.\n\n\n\n5.9.2.1 Função densidade de probabilidade (FDP)\nAnteriormente, afirmamos que uma variável aleatória \\(X\\) é contínua se \\(P,(X = x) = 0\\). Assim, como poderíamos atribuir probabilidade às variáveis aleatórias? Com o intuito de resolver esse problema, definimos a função densidade de probabilidade a seguir.\n\nDefinição 5.31: Função densidade de probabilidade\nSeja \\(f:\\mathbb{R}\\rightarrow \\mathbb{R}\\) uma função. Então \\(f\\) é uma função densidade se:\n\n\\(f(x)\\geq 0\\) para todo \\(x\\in\\mathbb{R}\\), e\n\\(\\int^{\\infty}_{-\\infty}f(x)dx=1\\).\n\n\n\nPodemos observar que a função densidade de probabilidade foi definida sem fazer referência a uma variável aleatória contínua. Apenas que satisfaça as duas condições apresentadas na Definição 5.31.\n\nExemplo 5.31Vamos verificar se \\(f(x)=\\frac{1}{128}e^{-x/128}\\) é uma densidade de probabilidade para \\(x\\geq 0\\). A variável aleatória \\(X\\) representa o tempo de vida de uma espécie vegetal arbórea dada em anos. Para verificarmos se \\(f_X\\) é uma função densidade de probabilidade, devemos provar as condições:\n\n\\(f(x)\\geq 0\\), pois \\(e^{-x/128}\\geq 0, \\ \\ \\forall x\\geq0\\), e \\(1/128\\) é uma constante sempre positiva.\nVerificar se \\(\\displaystyle\\int_{0}^{\\infty}f(x)dx=1\\).\n\nInicialmente vamos relembrar a derivada de uma função \\(h(x)=e^{-mx}\\): \\[\\begin{eqnarray*}\n            h'(x)&=&-me^{-mx},\n\\end{eqnarray*}\\] integrando em ambos os lados, temos: \\[\\begin{eqnarray*}\n            \\int h'(x)dx&=&\\int -me^{-mx}dx,\\\\\n            h(x)&=&-m\\int e^{-mx}dx,\\\\\n            \\frac{h(x)}{-m}&=&\\int e^{-mx}dx,\n\\end{eqnarray*}\\] como \\(h(x)=e^{-mx}\\), então, \\[\n\\begin{equation}\n            \\int e^{-mx}dx=\\frac{-e^{-mx}}{m}+c.\n\\end{equation}\n\\tag{5.49}\\]\nAssim, se considerarmos \\(m\\) \\(=\\) \\(1/128\\), então começamos a prova do item (ii).\n\\[\\begin{eqnarray*}\n            \\int_{0}^{\\infty}\\frac{1}{128}e^{-\\frac{1}{128}x}dx &=&\\frac{1}{128}\\underbrace{\\int_{0}^{\\infty}e^{-\\frac{1}{128}x}dx,}_{\\textrm{idêntica a }eq. (5.49) }\\\\\n            &=&\\frac{1}{128}\\left[\\frac{-e^{-(1/128)x}}{1/128} \\right]_{0}^{\\infty},\\\\\n            &=&\\frac{1}{128}\\left[0-\\left( \\frac{-e^{-(1/128)\\times 0}}{1/128}  \\right)  \\right],\\\\\n            &=&\\frac{1}{128}\\left[128e^{0} \\right] \\\\\n            &=&\\frac{1}{128}\\times 128 \\times 1=1.\n\\end{eqnarray*}\\] Portanto, \\(f(x)\\) é uma função densidade.\n\n\nVejamos o Exemplo 5.32, uma outra situação para determinarmos uma função densidade de probabilidade.\n\nExemplo 5.32Seja \\[\n    f(x)=\\left\\lbrace \\begin{array}{ll}\n        1/6x+k,&\\textrm{se }0\\leq x \\leq 3\\\\\n        0, & \\textrm{em qualquer outro caso}.\n    \\end{array}\\right.\n\\] Encontrar o valor de “\\(k\\)” na função para que \\(f(x)\\) seja FDP. Para determinar o valor de \\(k\\), então \\[\n    \\int_{0}^{3}(1/6x+k)dx=1.\n\\] Assim, \\[\n\\begin{eqnarray}\n        \\int_{0}^{3}(1/6x+k)dx&=&\\left[1/6\\frac{x^2}{2}+xk \\right]_0^{3} \\nonumber \\\\\n        &=&1/6\\frac{3^2}{2}+3k.\n\\end{eqnarray}\n\\tag{5.50}\\] Igualando (5.50) a 1, temos: \\[\n    1/6\\frac{3^2}{2}+3k=1 \\Rightarrow k=1/12.\n\\] Portanto, \\(f(x)=1/6x+1/12\\) é uma FDP.\n\n\nCom a Definição 5.31, podemos redefinir formalmente uma variável aleatória contínua.\n\nDefinição 5.32: Variável aleatória absolutamente contínuaUma variável aleatória \\(X\\) é absolutamente contínua se existe uma função densidade \\(f_X(x)\\), tal que \\[\n\\begin{eqnarray}        \nF_X(x)=\\int_{-\\infty}^{x}f_X(t)dt,\n\\end{eqnarray}\n\\tag{5.51}\\] para todo \\(x \\in \\mathbb{R}\\).\n\n\nA partir da Definição 5.32, usamos a notação para a FDP de \\(X\\) como \\(f_X\\), para associá-la com a respectiva variável aleatória contínua. Na Definições 5.30 e 5.32, percebemos que \\(f_X(x)\\) não é unicamente definida. Mas se requer que a integral de \\(f_X(x)\\) exista para todo \\(x\\). Vejamos o Exemplo 5.33.\n\nExemplo 5.33Considere \\(I_A\\) uma função indicadora do conjunto \\(A\\), e suponha que \\(F_X(x)\\) $= $ \\(xI_{[0,1)}(u)\\) \\(+\\) \\(I_{[1,\\infty)}(u)\\), então \\(f_X(u)=I_{(0,1)}(u)\\) satisfaz \\(F_X(x)\\) \\(=\\) \\(\\int^{x}_{-\\infty}f_X(u)du\\). Agora, se considerarmos \\(f_X(u)\\) \\(=\\) \\(I_{(0,1/2)}(u)\\) \\(+\\) \\(35I_{[1/2]}(u)\\) \\(+\\) \\(I_{(1/2,1)}(u)\\), também satistaz \\(F_X(x)\\) \\(=\\) \\(\\int^{x}_{-\\infty}f_X(u)du\\). Ou seja, a função densidade é mudada em alguns pontos, e \\(F_X\\) não se altera. Portanto, o correto ao invés de dizermos “a” função densidade de probabilidade, seria “uma” função densidade de probabilidade.\n\n\nDefiniremos a seguir uma FDA para o caso contínuo, já mencionado na Definição 5.32, expressão (5.51).\n\n\n5.9.2.2 FDA para as variáveis aleatórias contínuas\nAssim como no caso discreto, também apresentaremos a FDA para as variáveis aleatórias absolutamente contínuas.\n\nDefinição 5.33: Função de distribuição de uma variável aleatória contínuaSe \\(X\\) é uma variável aleatória absolutamente contínua, a função de distribuição \\(F_X\\), se existir uma função densidade \\(f_X\\), é definida por \\[\nF_X(x) = \\int^{x}_{-\\infty} f_X(t)dt, \\ x \\in \\mathbb{R}.\n\\]\n\n\n\nExemplo 5.34No canal do Youtube ocorreram 200 acessos em 48 horas. Qual a probabilidade de não haver acessos nos próximos cinco minutos?\nConsideremos \\(X\\) um variável aleatória que mede o tempo, a partir de um tempo inicial (\\(t_0\\)), até o tempo em que houve o primeiro acesso no canal. Podemos considerar também que se assumirmos \\(Y\\) como sendo uma variável aleatória que conta o número de acessos em 5 minutos, dizemos que \\(Y\\sim Poisson(\\lambda x)\\), em que \\(\\lambda\\) representa o número médio de acessos por minuto e \\(x\\) representa o valor do tempo, em minutos.\nDiante dessas informações, podemos determinar a distribuição de \\(X\\) a partir da distribuição de \\(Y\\). Assumir que não tenha acessos (\\(Y = 0\\)) nos próximos 5 minutos (\\(x\\)), significa dizer que o primeiro acesso superior aos 5 minutos, é equivalente a dizer que \\(Y = 0\\) do início da contagem do tempo até os cinco minutos. Generalizando a expressão para um \\(x\\) qualquer, e que o tempo de verificação do experimento seja maior que \\(x\\), então \\[\n\\begin{align}\nP(X &gt; x) = P(Y = 0) = \\frac{e^{-\\lambda x}(\\lambda x )^0}{0!} = e^{-\\lambda x}.\n\\end{align}\n\\tag{5.52}\\] Pela Definição 5.25, temos que a função de distribuição de \\(X\\) pode ser dada como: \\[\n\\begin{align}\n    F_X(x) = P(X \\leq x) & = 1 - P(X &gt; x) \\nonumber\\\\\n                & = 1 - e^{-\\lambda x}, \\quad \\textrm{(Resultado de 5.52)}\n\\end{align}\n\\tag{5.53}\\] para \\(x \\geq 0\\). O resultado em (5.53) representa a distribuição acumulada de uma variável aleatória \\(X\\) que tem distribuição exponencial, em notação \\(X \\sim Exp(\\lambda)\\).\nRetornando a solução do problema inicial, temos que:\n\n\n\n\\(200\\) acessos\n\\(\\to\\)\n$48 $ horas\n\n\n\n\\(\\lambda\\) acessos\n\\(\\to\\)\n\\(1\\) hora,\n\n\n\n\nlogo, \\(\\lambda = 4,166667\\) acessos por hora. Assim, usando (5.52), temos\n\\[\\begin{align*}\n  P(X &gt; 5 / 60) = P(X &gt; 0,083333) & = e^{-4,166667 \\times 0,833333} =  0,7066484,\n\\end{align*}\\] isto é, a chance de não haver acessos nos próximos 5 minutos é em torno de \\(71\\%\\).\n\n\nPodemos representar graficamente as funções: FDP e FDA. Com a Definição 5.33, podemos retornar ao que falamos anteriormente, pelo seguinte teorema:\n\nTeorema 5.16: Variável aleatória absolutamente contínua implica em variável aleatória contínuaSe \\(X\\) é uma variável absolutamente contínua, então \\(X\\) é também uma variável contínua.\n\n\n\nProvaPela continuidade da probabilidade, Teorema \\(\\ref{teo:propP(x)}\\), item (\\(vii\\)), considere \\(x \\in \\mathbb{R}\\). Então, podemos afirmar que \\(P(X = x) = P(x \\leq X \\leq x)\\). Agora, pela Definição 5.25 e para um pequeno valor positivo de \\(\\delta\\), temos \\[\\begin{align*}\n  P(X = x) & = P(x - \\delta \\leq X \\leq x)\\\\\n           & = F_X(x) - \\lim_{\\delta \\to 0}F_X(x - \\delta)\\\\\n           & = 0,\n\\end{align*}\\] para todo \\(x \\in \\mathbb{R}\\).\n\n\nHá casos patológicos, em que mesmo tendo uma variável aleatória contínua, \\(F_X(x)\\) não é diferenciável devido a \\(f_X(x)\\). Nesses casos, a variável aleatória não é absolutamente contínua Kachapova e Kachapov (2012) . Portanto, uma variável é absolutamente contínua se (5.51) se mantiver. Assim, iremos omitir a palavra “absolutamente” ao mencionarmos uma variável aleatória absolutamente contínua, uma vez que os casos em que isso não ocorre são considerados patológicos e não merecedores de atenção, exceto em casos muito particulares e avançados.\nDa mesma forma como ocorre no caso discreto, também apresentamos o suporte de \\(X\\) para o caso contínuo na Definição 5.34.\n\nDefinição 5.34: Suporte de \\(X\\) (v.a. contínua)O suporte de uma variável aleatória contínua, denotado por \\(\\mathcal{X}\\), tal que \\(\\mathcal{X} \\subset \\mathbb{R}\\) é dado por \\[\n\\begin{align}\n\\mathcal{X} & = \\{x:~ f_X(x) &gt; 0\\},\n\\end{align}\n\\tag{5.54}\\] sendo \\(f_X\\) apresentada na Definição 5.31.\n\n\nDiremos que integrar a função densidade de \\(X\\) em seu suporte resulta em 1, que é o equivalente ao somar todas as probabilidades no suporte de \\(X\\), sendo \\(X\\) uma variável aleatória discreta.\nA partir de uma função distribuição podemos obter uma função densidade, como também o contrário é válido, sendo apresentado no Teorema 5.17, a seguir.\n\nTeorema 5.17: Relação entre \\(F_X\\) e \\(f_X\\) de uma variável aleatória contínuaSeja \\(X\\) uma variável aleatória contínua. Então, a partir de uma função densidade \\(f_X(x)\\) pode ser obtido a função de distribuição \\(F_X(x)\\), e vice-versa.\n\n\n\nProvaSe \\(X\\) é uma v. a. contínua e sua \\(f_X(x)\\) é conhecida, então \\(F_X(x)\\) é obtida pela integração \\(\\int^{x}_{-\\infty}f_X(u)du\\), usando a própria Definição 5.33. Ao passo que, se \\(F_X(x)\\) é conhecida, então a função densidade pode ser obtida por \\(f_X(x) = dF_X(x)/dx\\), nos pontos em que \\(x\\) seja diferenciável, sendo validada pelo teorema fundamental do cálculo.\n\n\n\nExemplo 5.35Retornando ao resultado (5.53) obtido no Exemplo 5.34, podemos usar o Teorema 5.17 para descobrir a função densidade de probabilidade de \\(X\\), isto é, \\[\n\\begin{align}\n  f_X(x) & = \\frac{d}{dx}F_X(x)\\nonumber\\\\\n         & = \\lambda e^{-\\lambda x},\n\\end{align}\n\\tag{5.55}\\] que representa a função densidade de probabilidade de uma variável aleatória \\(X\\) que tem distribuição exponencial, com \\(\\lambda &gt; 0\\) e suporte de \\(X\\) igual a \\(\\mathcal{X} = [0, \\infty)\\).\n\n\nDiferentemente do gráfico de \\(F_X(x)\\) para \\(X\\) uma variável aleatória discreta, vamos observar o caso contínuo por meio do Código R 5.3. Pelo fato da função distribuição de uma variável aleatória contínua está bem comportada, é fácil observar as propriedades apresentadas no Teorema 5.14, Figuras 5.13 a 5.15. Por exemplo, a propriedade (\\(iii\\)) do Teorema 5.14, para este caso, poderia ser estendida para \\(x_n \\uparrow x\\) e para \\(x_n \\downarrow x\\) pelo fato da continuidade de \\(F_x\\), o que não seria verdade para o caso discreto, observe a Figura 5.11.\n\n\n\n\nCódigo R 5.3: Propriedades da FDA de uma variável aleatória contínua.\n\n\n# Anexando o pacote leem\nlibrary(leem)\n# Propriedade 1\nshowcdf(variable = 2, prop = 1)\n\n\n\n\n\n\n\n\n\n\nFigura 5.13: Propriedade (\\(i\\)) do Teorema 5.14 para FDA de uma v.a. contínua.\n\n\n\n\n\n\n# Propriedade 2\nshowcdf(variable = 2, prop = 2)\n\n\n\n\n\n\n\nFigura 5.14: Propriedade (\\(ii\\)) do Teorema 5.14 para FDA de uma v.a. contínua.\n\n\n\n\n\n\n# Propriedade 3\nshowcdf(variable = 2, prop = 3)\n\n\n\n\n\n\n\nFigura 5.15: Propriedade (\\(iii\\)) do Teorema 5.14 para FDA de uma v.a. contínua.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Probabilidades</span>"
    ]
  },
  {
    "objectID": "cap05.html#fquant&fs&fsq",
    "href": "cap05.html#fquant&fs&fsq",
    "title": "5  Probabilidades",
    "section": "5.10 Função quantil, Função de sobrevivência e função s-quantil",
    "text": "5.10 Função quantil, Função de sobrevivência e função s-quantil\nOutras funções são interessantes no contexto de variáveis aleatórias, principalmente quando as distribuições estiverem associados as estatísticas de testes de hipóteses, Capítulo 10. As funções apresentadas a seguir são: função quantil, função de sobrevivência e função s-quantil.\n\nDefinição 5.35: Função quantilConsiderando uma variável aleatória \\(X\\) com função de distribuição \\(F_X\\), então a função \\(Q: [0,1] \\to \\mathbb{R}\\), é chamada de função quantil, definida por: \\[\n\\begin{align}\n    Q(p) = F^{-1}(x) & = \\inf\\{x \\in \\mathbb{R}:~F(x) \\geq p\\},\n\\end{align}\n\\tag{5.56}\\]\npara todo \\(p \\in [0,1]\\). Dizemos ainda que \\(Q\\) representa a função inversa de \\(F_X\\), de modo que \\(x\\) representa o menor valor tal que \\(F_X(x) \\geq p\\). Portanto, \\(Q(p)\\) representa o \\(p\\)-ésimo quantil de \\(X\\).\n\n\nA expressão (5.56) é definida dessa forma devido a condição da \\(F_X\\) para a variável aleatória discreta ser descontínua à esquerda, como já mostrado anteriormente. Para o caso das variáveis aleatórias contínuas, pelos fato das FDAs dessas variáveis serem contínuas, para cada \\(p\\) sempre existirá um \\(Q(p) = x\\). Dessa forma, precisamos de uma definição geral como a apresentada na Definição 5.35. Apresentaremos uma sequências de exemplos para um melhor entendimento da função quantil.\n\nExemplo 5.36Considere \\(X\\) uma variável aleatória com distribuição exponencial, cuja função densidade é dada por: \\[\\begin{align*}\n    f_X(x) = \\lambda e^{-\\lambda x}, \\quad x \\geq 0, \\quad \\lambda &gt; 0.\n\\end{align*}\\] A função de distribuição é dada por: \\[\n\\begin{align}\n  F_X(x) & = \\int_{0}^{x}\\lambda e^{-\\lambda t} dt \\nonumber\\\\\n  & = \\lambda\\left[-\\frac{1}{\\lambda} e^{-\\lambda t }\\right]^{x}_{0} = 1 - e^{-\\lambda x}.\n\\end{align}\n\\tag{5.57}\\] Agora, vamos determinar a função quantil, \\(Q(p) = u\\), para um dado valor de \\(p\\), em que \\(0 &lt; p &lt; 1\\), tal que \\(F_X(u) = p\\). Vamos resolver a equação, dado que \\(F_X\\) ja foi obtido em (5.57), assim, \\[\\begin{align*}\n  1 - e^{-\\lambda u} & = p\\\\\n  e^{-\\lambda u} & = 1 - p.\n\\end{align*}\\] Aplicando o logaritmo natural, temos \\[\\begin{align*}\n  -\\lambda u& = ln(1 - p)\\\\\n  u & = -\\frac{1}{\\lambda}\\ln(1 - p),\n\\end{align*}\\] logo, a função quantil de \\(X\\) é \\[\nQ(p) = -\\frac{1}{\\lambda}\\ln(1 - p).\n\\]\n\n\nNem sempre é possível determinar analiticamente uma função quantil de uma determinada variável aleatória, devido as limitações de uma forma fechada para a inversa de \\(F_X\\). Mesmo assim, ainda é possível em muitas situações obter o valor para uma determinada função quantil. Vejamos mais um exemplo.\n\nExemplo 5.37Considere \\(X\\) uma variável aleatória discreta com distribuição binomial, cuja função de distribuição é dada por: \\[\\begin{align*}\n    F_X(x) = \\sum_{i =  0}^{x}\\binom{n}{i}\\theta^i(1-\\theta)^{n-i},\n\\end{align*}\\] em que os parâmetros da distribuição são \\(n &gt; 1\\) e \\(0 &lt; \\theta &lt; 1\\). Podemos perceber que inverter a \\(F_X\\) neste caso, não é algo simples. Short (2023) apresenta alguns resultados assintóticos para o quantil da binomial. Essa situação ocorre sempre quando a variável aleatória é discreta. Por isso que na Definição 5.35 afirmamos o quantil representa o menor valor tal que \\(F_X(x) \\geq p\\). Por exemplo, se considerarmos \\(n = 10\\) e \\(\\theta = 0,5\\), poderíamos estar interessados em saber qual o quantil de \\(X\\) para \\(p = 0,05\\), isto é, \\(Q(0,05)\\)? Uma alternativa então para calcularmos o quantil nessa situação será calcularmos a probabilidade dos valores de \\(X\\) até verificarmos de forma acumulada se a soma dessas probabilidades resultam no valor no mínimo igual \\(p\\), isto é, \\[\\begin{align*}\n    x = 0 & \\Rightarrow pX(0) = \\binom{10}{0}0,5^0(1-0,5)^{10-0} = 0,0009765625,\\\\\n    x = 1 & \\Rightarrow pX(1) = \\binom{10}{1}0,5^1(1-0,5)^{10-1} = 0,009765625,\\\\\n    x = 2 & \\Rightarrow pX(2) = \\binom{10}{2}0,5^2(1-0,5)^{10-2} = 0,04394531,\\\\\n    x = 3 & \\Rightarrow pX(3) = \\binom{10}{3}0,5^3(1-0,5)^{10-3} = 0,1171875.\\\\\n\\end{align*}\\] Dessa forma, podemos perceber que: \\[\\begin{align*}\n    F_X(0) & = p_X(0) =  0,0009765625,\\\\\n    F_X(1) & = p_X(0) + p_X(1) = 0,01074219,\\\\\n    F_X(2) & = p_X(0) + p_X(1) + p_X(2) = 0,0546875,\\\\\n    F_X(3) & = p_X(0) + p_X(1) + p_X(2) + p_X(3) = 0,171875.\\\\\n\\end{align*}\\] Assim, o \\(Q(0,05) = 2\\) porque este valor é o menor \\(x\\) tal que \\(F_X(x) \\geq p\\). Observe que \\(F_X(3) \\geq 0,05\\), porém \\(x = 3\\) não representa o menor valor para esta condição. Usando o pacote leem, podemos representar a função quantil da seguinte forma…",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Probabilidades</span>"
    ]
  },
  {
    "objectID": "cap05.html#exerprop",
    "href": "cap05.html#exerprop",
    "title": "5  Probabilidades",
    "section": "Exercícios propostos",
    "text": "Exercícios propostos\n\nExercício 5.1Defina o que é um experimento aleatório e exemplifique.\n\n\n\nSoluçãoVerifique a Definição 5.1 e formule uma resposta.\n\n\n\nExercício 5.2Defina o que é um espaço amostral e exemplifique.\n\n\n\nSoluçãoVerifique as Definições 5.2 e 5.3 e formule uma resposta.\n\n\n\nExercício 5.3\nPara cada um dos casos abaixo, escreva o espaço amostral correspondente e conte seus elementos.\n\nUma moeda é lançada duas vezes e observam-se as faces obtidas.\nUm dado é lançado duas vezes e a ocorrência de face par ou ímpar é observado.\nDois dados são lançados simultaneamente e estamos interessados na soma das faces observadas.\nEm uma cidade, famílias com 3 crianças são selecionadas ao acaso, anotando-se o sexo de cada uma.\n\n\n\n\nSolução\n\nConsideremos \\(C_i\\) e \\(K_i\\), as faces superiores cara e coroa, respectivamente, para as moedas \\(i = 1, 2\\). Assim, o espaço amostral é dado por \\(\\Omega = \\{(C_1, C_2), (C_1, K_2), (K_1, C_2) , (K_1, K_2)\\}\\) e \\(\\#\\Omega = 4\\);\nSegue o resultado para o dado:\n\n\n\n\nDado\n1\n2\n3\n4\n5\n6\n\n\n\nResultado\nÍmpar\nPar\nÍmpar\nPar\nÍmpar\nPar\n\n\n\n\nConsiderando que foi lançado duas vezes o dado, cada elemento é um par de resultados, e ainda, mesmo alguns resultados representando elementos iguais, como por exemplo, {(Par, Par)} = {(2, 2), (2, 4), (2, 6), …}, no espaço amostral só teremos o elemento (Par, Par). Assim, o espaço amostral é dado por \\(\\Omega\\) = {(Par, Par), (Par, Ímpar), (Ímpar, Par), (Ímpar, Ímpar)}, com \\(\\#\\Omega = 4\\);\n\nO espaço amostral para a somas das faces superiores de dois dados lançados é \\(\\Omega = \\{2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12\\}\\), com cardinalidade \\(\\#\\Omega = 11\\);\nO espaço amostral para esse experimento aleatório, considerando \\(F\\) - pessoa do sexo feminino e \\(M\\) - pessoa do sexo masculino, é: \\[\\begin{align*}\n  \\Omega &  = \\{(F,F,F), (F,F,M), (F,M,F), (M,F,F), (F,M,M),\\\\\n      & \\quad (M,M,F), (M,F,M), (M,M,M)\\},\n\\end{align*}\\] com cardinalidade \\(\\#\\Omega = 8\\).\n\n\n\n\nExercício 5.4\nDuas pessoas \\(A\\) e \\(B\\), lançam três moedas de modo independente, e nessa ordem, primeiro a pessoa A, depois a pessoa \\(B\\), alternadamente. Nesse jogo, ganha quem conseguir três faces iguais, sendo finalizado com a vitória de um dos competidores. Assim, perguntamos:\n\nQual a probabilidade de \\(A\\) ganhar?\nQual a probabilidade de \\(B\\) ganhar?\n\n\n\n\nSoluçãoEssa questão exige um conhecimento avançado de progressão aritmética. Vejamos, inicia-se o jogo com A, posteriormente, B. Enquanto ninguém ganhar o jogo prossegue. Dessa forma, as jogadas em que A pode ganhar são 1ª, 3ª, 5ª, 7ª, …, e assim por diante. As jogadas em que B pode ganhar são 2ª, 4ª, 6ª, …, e assim por diante.\n\nVejamos, as chances de A ganhar:\n\n\n\n\n\n\n\n\n\nJogada\nSituação\nProbabilidade\n\n\n1ª\n3 moedas caras ou 3 coroas\n\\(2\\times (1/2)^3 = 1/4\\)\n\n\n3ª\nA perder, B perder e A ganhar\n$(3/4)^2 /4 $\n\n\n5ª\nA perder, B perder, A perder, B perder e A ganhar\n\\((1/3)^4 \\times 1/4\\)\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\n\nPercebe-se que a sequência \\(1/4\\), \\(1/4[(3/4)^2]^1\\), \\(1/4[(3/4)^2]^2\\), \\(1/4[(3/4)^2]^3\\), \\(\\ldots\\), é uma progressão geométrica (PG) em que o primeiro elemento é \\(a_1 = 1/4\\) e a razão é \\(q = (3/4)^2\\). Pode-se mostrar que a soma infinita de uma PG é dada por: \\[\n\\begin{align}\n    S & = \\frac{a_1}{1 - q},\n\\end{align}\n\\tag{5.58}\\] que representa a probabilidade de A ganhar, isto é, \\[\\begin{align*}\n    P(\\textrm{A ganhar}) & = \\frac{1/4}{1 - (3/4)2} = 4/7;\n\\end{align*}\\]\n\nAs chances de B ganhar são:\n\n\n\n\n\n\n\n\n\nJogada\nSituação\nProbabilidade\n\n\n2ª\nA perder e B ganhar\n\\((1 - 1/4). 1/4 = 3/4 \\times 1/4\\)\n\n\n4ª\nA perder, B perder, A perder e B ganhar\n\\((3/4)^3 \\times 1/4\\)\n\n\n6ª\nA perder, B perder, A perder, B perder, A perder e B ganhar\n\\((3/4)^5 \\times 1/4\\)\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\n\nA série pode ser expressa como: \\(3/16\\), \\(3/16 \\times [(3/4)^2]^1\\), \\(3/16 \\times [(3/4)^2]^2\\), …, e assim por diante. Pelo mesmo raciocínio feito na probabilidade de A ganhar, temos que a probabilidade de B ganhar é: \\[\\begin{align*}\n    P(\\textrm{B ganhar}) &  = \\frac{3/16}{1 - (3/4)^2}  = \\frac{3}{7}.\n\\end{align*}\\]\n\n\n\nExercício 5.5\nUma Universidade tem 10 mil alunos dos quais 4 mil são considerados esportistas. Temos ainda que 500 alunos são do curso de Administração noturno, 700 de Ciências contábeis noturno, 100 são esportistas e da Administração noturno e 200 são esportistas e da Ciências contábeis noturno. Qual a probabilidade de:\n\nSer esportista;\nSer esportista e aluno da Administração;\nSer esportista ou aluno da Ciências contábeis;\nNão ser esportista nem aluno da Administração.\n\n\n\n\nSolução\n\n\nE - Evento ser Esportista, logo \\(P(E) = 4.000/10.000 = 0,40\\);\nEA - Esportista e aluno da Administração, logo P(EA) = 100/10.000;\nE - Evento ser esportista; C - Evento ser da C. Contábeis, logo, \\(P(E \\cup C) = P(E) + P(C) - P(E \\cap C) = 4.000/10.000 +\\) \\(700/10.000 - 200/10000 = 4.500/10.000\\).\nE - Evento ser esportista; A - Evento ser da administração, como \\(P(E \\cup A) = P(E) + P(A) - P(E \\cap A) = 4.000/10.000 +\\) \\(500/10.000 - 100/10.000 = 4.400/10.000\\), logo \\(P(E \\cup A)^c = 1 - 4.400/10.000\\).\n\n\n\n\nExercício 5.6Sejam A e B dois eventos em um dado espaço amostral, tais que \\(P(A) = 0,2\\), \\(P(B) = p\\), \\(P(A \\cup B) = 0,5\\) e \\(P(A \\cap B) = 0,1\\). Determine o valor de \\(p\\).\n\n\n\nSolução\\(P(A \\cup B) = P(A) + P(B) - P(A\\cap B) \\Rightarrow P(B) = P(A \\cup B) +\\) \\(P(A\\cap B) - P(A) = 0,5 + 0,1 - 0,2 = 0,4\\).\n\n\n\nExercício 5.7\nSe \\(P(A) = \\frac{1}{2}\\); \\(P(B) = \\frac{1}{4}\\), e A e B são mutuamente exclusivos, calcular:\n\n\\(P(A^c)\\).\n\\(P(B^c)\\).\n\\(P(A \\cap B)\\).\n\\(P(A \\cup B)\\).\n\\(P(A^c \\cap B^c)\\).\n\n\n\n\nSolução\n\n\\(P(A^c) = 1 - \\frac{1}{2} = \\frac{1}{2}\\);\n\\(P(B^c) = 1 - \\frac{1}{4} = \\frac{3}{4}\\);\n\\(P(A \\cap B) = 0\\);\n\\(P(A \\cup B) = P(A) + P(B) = \\frac{1}{2} + \\frac{1}{4} = \\frac{3}{4}\\);\n\\(P(A^c \\cap B^c) = P[(A \\cup B)^c] = 1 - \\frac{3}{4} = \\frac{1}{4}\\).\n\n\n\n\nExercício 5.8\nSe \\(P(A) = \\frac{1}{2}\\); \\(P(B) = \\frac{1}{3}\\) e \\(P(A \\cap B) = \\frac{1}{3}\\). Calcule:\n\n\\(P(A \\cup B)\\);\n\\(P(A^c \\cup B)\\);\n\\(P(A^c \\cap B^c)\\).\n\n\n\n\nSolução\n\n\\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B) = \\frac{1}{2} + \\frac{1}{3} - \\frac{1}{3} = \\frac{1}{2}\\);\n\\(P(A^c \\cup B) = P(A^c) + P(B) - P(A^c \\cap B) =\\) \\(P(A^c) + P(B) = \\frac{5}{6}\\), uma vez que \\(P(A^c \\cap B) = 0\\), pois \\(B \\subset A\\) (já que \\(P(A^c \\cap B) = P(B)\\));\n\\(P(A^c \\cap B^c) = P[(A \\cup B)^c] =\\) \\(1 - P(A \\cup B) = 1 - \\frac{1}{2} = \\frac{1}{2}\\);\n\n\n\n\nExercício 5.9\nDois dados são lançados simultaneamente. Qual a probabilidade de:\n\na soma ser menor que 4;\na soma ser 9;\no primeiro resultado ser maior que o segundo.\n\n\n\n\nSolução\n\n\n\nDado 1\n1\n2\n3\n4\n5\n6\n\n\nDado 2\n1\n2\n3\n4\n5\n6\n\n\n\n\nA - Evento: soma ser menor que 4, logo \\(P(A) = \\frac{\\#\\{\\textrm{Soma ser menor que 4}\\}}{36} = \\frac{3}{36}\\);\nB - Evento: soma ser 9, logo \\(P(B) = \\frac{\\#\\{\\textrm{Soma ser 9}\\}}{36} = \\frac{4}{36}\\)\nC - Evento: o primeiro resultado ser maior que o segundo, logo \\(P(C) = \\frac{\\#\\{\\textrm{1º Resultado ser maior que o 2º Resultado}\\}}{36} = \\frac{15}{36}\\).\n\n\n\n\nExercício 5.10Qual a probabilidade de sair um rei ou uma carta de copas, quando retiramos uma carta de um baralho?\n\n\n\nSoluçãoConsiderando que um baralho tem 52 cartas, 4 cartas rei, e 13 cartas com naipe copas, sendo 1 rei de copas, e ainda R: carta rei, C: Carta de copas, logo\n\\[\nP(R \\cup C) = P(R) + P(C) - P(R\\cap C) = \\frac{4}{52} + \\frac{13}{52} - \\frac{1}{52} = \\frac{16}{52}.\n\\]\n\n\n\nExercício 5.11\nAs probabilidades de três jogadores marcarem um pênalti são respectivamente: \\(\\frac{2}{3}\\), \\(\\frac{4}{5}\\) e \\(\\frac{7}{10}\\). Se cada um ``cobrar’’ uma única vez, qual a probabilidade de:\n\ntodos acertarem?\napenas um acertar?\ntodos errarem?\n\n\n\n\nSoluçãoEvento \\(J_1\\): o jogador 1 marca o pênalti; Evento \\(J_2\\): o jogador 2 marca o pênalti; Evento \\(J_3\\): o jogador 3 marca o pênalti. Assim,\n\nTodos acertarem:\n\n\\(P(J_1 \\cap J_2 \\cap J_3) = P(J_1) \\times P(J_2) \\times P(J_3) = \\frac{2}{3} \\times \\frac{4}{5} \\times \\frac{7}{10} = \\frac{28}{75}\\).\n\nApenas um acertar:\n\n\\[\\begin{align*}\n    P(J_1 \\cap J_2^c \\cap J_3^c) + P(J_1^c \\cap J_2 \\cap J_3^c) + P(J_1^c \\cap J_2^c \\cap J_3)\\\\\n    \\left(\\frac{2}{3} \\times \\frac{1}{5} \\times \\frac{3}{10}\\right) + \\left(\\frac{1}{3} \\times \\frac{4}{5} \\times \\frac{3}{10}\\right) + \\left(\\frac{1}{3} \\times \\frac{1}{5} \\times \\frac{7}{10}\\right)\\\\\n    \\frac{1}{25} + \\frac{2}{25} + \\frac{7}{150}\\\\\n    \\frac{1}{6}.\n  \\end{align*}\\]\n\nTodos errarem:\n\n\\(P[J_1^c \\cap J_2^c \\cap J_3^c] = \\frac{1}{3} \\times \\frac{1}{5} \\times \\frac{3}{10}= \\frac{1}{50}.\\)\n\n\n\nExercício 5.12\nDois armários guardam as bolas de voleibol e basquete. O armário 1 tem três bolas de voleibol e 1 de basquete, enquanto o armário 2 tem 3 de voleibol e 2 de basquete. Escolhendo-se ao acaso um armário e, em seguida, uma de suas bolas, calcule a probabilidade dela ser:\n\nDe voleibol, sabendo-se que o armário 1 foi escolhido;\nDe basquete, sabendo-se que o armário 2 foi escolhido;\nDe basquete.\n\n\n\n\nSolução\nConsiderando os eventos \\(V\\): bola de volei; \\(B\\): bola de basquete; \\(A_1\\): bola no armário 1; \\(A_2\\): bola no armário 2, assim\n\n\\(P(V|A_1) = \\frac{P(V \\cap A_1)}{A_1} = \\frac{3/9}{4/9} = \\frac{3}{4}\\).\n\\(P(B|A_2) = \\frac{P(B \\cap A_2)}{P(A_2)} = \\frac{2/9}{5/9} = \\frac{2}{5}\\).\nEssa questão nos remete uma atenção. O enunciado está desejando calcular a probabilidade de escolher um armário e em seguida uma de suas bolas, sendo esta de basquete. Como neste ítem não foi identificado qual armário seria o escolhido, vamos identificar o evento \\(A_1^*\\) que representa a escolha do armário 1, e o evento \\(A_2^*\\) que representa a escolha do armário 2. Estes eventos são diferentes dos eventos \\(A_1\\) e \\(A_2\\), respectivamente, pois estes últimos representam os eventos de escolher as bolas nestes respectivos armários e não a escolha do armário. Logo, a chance de escolhermos um dos armários é 50%, isto é, \\(P(A_2^*) = P(A_2^*) = 1/2\\). Dessa forma, a probabilidade de escolhermos um armário e uma bola de basquete pode ser dada por: \\[\\begin{align*}\nP(B) & = P(A_1^*) \\times P(B|A_1) + P(A_2^*) \\times P(B|A_2)\\\\\n      & = 1/2 \\times 1/4 + 1/2 \\times 2/5\\\\\n      & = \\frac{13}{40} = 0,3250.\n\\end{align*}\\]\n\n\n\n\nExercício 5.13Em certo colégio, 5% dos homens, 2% das mulheres têm mais do que 1,80m. Por outro lado, 60% dos estudantes são homens. Se um estudante é selecionado aleatoriamente e tem mais de 1,80m de altura, qual a probabilidade de que o estudante seja mulher?\n\n\n\nSolução\nSeja \\(A\\) o evento do estudante ter mais de 1,80m, e considere M o evento do estudante ser mulher. Temos as seguintes informações disponíveis, \\(P(H) = 0,60\\), \\(P(M) = 0,40\\), \\(P(A|H) = 0,05\\) e \\(P(A|M) = 0,02\\). Para calcularmos o evento A, temos \\[\\begin{align*}\n    P(A) & = P(A\\cap M) + P(A \\cap H)\\\\\n         & = P(A|M)P(M) + P(A|H)P(H)\\\\\n         & = 0,02 \\times 0,40 + 0,05 \\times 0,6\\\\\n         & = 0,038.\n\\end{align*}\\] Assim, para calcularmos \\(P(M|A)\\) temos \\[\\begin{align*}\n    P(M|A) & = \\frac{P(M \\cap A)}{P(A)}\\\\\n           & = \\frac{0,008}{0,038} = 0,2105.\n\\end{align*}\\]\n\n\n\nExercício 5.14\nA probabilidade de uma mulher está viva daqui a 30 anos é \\(\\frac{3}{4}\\) e a de seu marido, \\(\\frac{3}{5}\\). Calcular a probabilidade de:\n\napenas o homem está vivo;\nsomente a mulher está;\nambos estarem vivos.\n\n\n\n\nSolução\nConsidere o evento H - homem está vivo; e o evento M - mulher está viva. Assim,\n\n\\(P(H \\cap M^c) = P(H) \\times P(M^c) = \\frac{3}{5} \\times \\frac{1}{4} = \\frac{3}{20}\\);\n\\(P(H^c \\cap M) = P(H^c) \\times P(M) = \\frac{2}{5} \\times \\frac{3}{4} = \\frac{6}{20}\\);\n\\(P(H\\cap M) = P(H) \\times P(M) = \\frac{3}{5} \\times \\frac{3}{4} = \\frac{9}{20}\\).\n\n\n\n\nExercício 5.15\nSe \\(P(A\\cup B) = 0,8\\), \\(P(A) = 0,5\\) e \\(P(B) = x\\), determine o valor de \\(x\\) no caso de:\n\nA e B serem mutuamente exclusivos;\nA e B serem independentes.\n\n\n\n\nSolução\n\n\\(P(A\\cup B) = P(A) + P(B) \\Rightarrow P(B) = 0,8 - 0,5 = 0,3\\).\n\\(P(A \\cup B) = P(A) + P(B) - P(A\\cap B)\\). Se \\(A\\) e \\(B\\) são independentes, então \\(P(A \\cap B) = P(A) \\times P(B)\\). Logo, \\[\\begin{align*}\nP(A \\cup B) & = P(A) + P(B) - P(A)P(B)\\\\\n             & = P(A) + P(B)[1 - P(A)]\\\\\n             & = P(A) + P(B)P(A^c)\\\\\n     0,8     & = 0,5  + P(B)\\times 0,5,\n\\end{align*}\\] que resulta em \\(P(B) = \\frac{0,8 - 0,5}{0,5} = \\frac{0,3}{0,5} = 0,60\\).\n\n\n\n\nExercício 5.16Se P(B) = 0,4, P(A) = 0,7 e \\(P(A \\cap B) = 0,3\\), calcule \\(P(A|B^c)\\).\n\n\n\nSolução\nConsiderando que \\(P(B^c) = 1 - P(B) = 0,6\\), então\n\\[\\begin{align*}\n  P(A|B^c) & = \\frac{P(A\\cap B^c)}{P(B^c)} = \\frac{0,4}{0,6} = 0,6667.\n\\end{align*}\\]\n\n\n\nExercício 5.17O São Paulo Futebol Clube ganha com probabilidade 0,7 se chove e 0,8 se não chove. Em Dezembro, a probabilidade de chuva é de 0,3. O São Paulo ganhou uma partida em Dezembro, qual a probabilidade de ter chovido nesse dia?\n\n\n\nSoluçãoProblema resolvido pelo teorema de Bayes. Consideremos o evento \\(G\\) o evento das vitórias do São Paulo, e \\(X\\) o evento de chover. Assim, \\[\\begin{align*}\n    P(X|G) & = \\frac{P(G|X)P(X)}{P(G|X)P(X) + P(G|X^c)P(X^c)}\\\\\n           & = \\frac{0,7\\times 0,3}{0,7 \\times 0,3 + 0,8 \\times 0,7}\\\\\n           & = \\frac{0,21}{0,77} = 0,2727.\n\\end{align*}\\]\n\n\n\nExercício 5.18Três máquinas A, B, e C produzem, respectivamente 30%, 50% e 20% do total de peças de uma fábrica. As porcentagens e peças defeituosas nas respectivas máquinas são 3%, 5% e 2%. Uma peça é sorteada ao acaso, e verifica-se que é defeituosa. Qual a probabilidade de que a peça tenha vindo da máquina B?\n\n\n\nSoluçãoConsiderando D o evento defeito, temos \\[\\begin{align*}\n    P(B|D) & = \\frac{P(D|B)P(B)}{P(D|A)P(A) + P(D|B)P(B) + P(D|C)P(C)}\\\\\n           & = \\frac{0,05 \\times 0,50}{0,03 \\times 0,30 + 0,05 \\times 0,50 + 0,02 \\times 0,20}\\\\\n           & = \\frac{0,0250}{0,038} = 0,6579.\n\\end{align*}\\]\n\n\n\nExercício 5.19\nNuma certa população, a probabilidade de gostar de teatro é de 1/3, enquanto que a de gostar de cinema é 1/2. Determine a probabilidade de gostar de teatro e não de cinema, nos seguintes casos:\n\nGostar de teatro e gostar de cinema são eventos disjuntos.\nGostar de teatro e gostar de cinema são eventos independentes.\nTodos que gostam de teatro gostam de cinema.\nA probabilidade de gostar de teatro e de cinema é de 1/8.\nDentre os que não gostam de cinema, a probabilidade de não gostar de teatro é de 3/4.\n\n\n\n\nSolução\nSeja T o evento de gostar de teatro, e B o evento de gostar de cinema. Assim, temos que \\(T = (T \\cap B) \\cup (T \\cap B^c)\\).\n\nComo \\(P(T \\cap B) = 0\\), então \\(P(T \\cap B^c) = P(T) = 1/3\\).\n\\(P(T \\cap B^c) = P(T) - P(T)P(B) = 1/3 - 1/3 \\times 1/2 = 1/6\\).\nNesse caso, \\(T \\subset B\\), logo \\(T \\cap B^c = \\emptyset\\). Assim, \\(P(T \\cap B^c) = 0\\).\n\\(P(T \\cap B^c) = P(T) - P(T \\cap B) = 1/3 - 1/8 = 5/24\\).\nSabemos que \\(P(T^c|B^c) = 3/4\\), e que \\(P(T^c|B^c) + P(T|B^c) = 1\\), então \\(P(T|B^c) = 1/4\\). Sabemos também que \\[\\begin{align*}\nP(T \\cap B^c) & = P(T|B^c) \\times P(B^c)\\\\\n               & = P(T|B^c) \\times [1 - P(B)]\\\\\n               & = 1/4 (1 - 1/2)\\\\\n               & = 1/8.\n\\end{align*}\\]\n\n\n\n\nExercício 5.20A probabilidade de fechamento de cada relé do circuito apresentado a seguir é dada por \\(p\\). Se todos os relés funcionarem independentemente, qual será a probabilidade de que haja corrente entre os terminais L e R?\n![](figures/cap5/circuitos1.png]\n\n\n\nSolução\n\\[\\begin{align*}\n    P(A \\cup B) & = P(A) + P(B) - P(A \\cap B)\\\\\n                & = p^2 + p^2 - p^4\\\\\n                & = 2p^2 - p^4.\n\\end{align*}\\]\n\n\n\nExercício 5.21A probabilidade de fechamento de cada relé do circuito apresentado a seguir é dada por \\(p\\). Se todos os relés funcionarem independentemente, qual será a probabilidade de que haja corrente entre os terminais L e R?\n\n\n\n\nSolução\n\\[\\begin{align*}\n    P(A \\cup B \\cup C) & = P(A) + P(B) + P(C) - P(A \\cap B) - P(A \\cap C) -\\\\\n    & \\quad - P(B \\cap C) + P(A \\cap B \\cap C)\\\\\n    & = p^2 + p + p^2 - p^3 - p^4 - p^3 + p^5\\\\\n    & = 2p^2 + p + 2p^3 - p^5.\n\\end{align*}\\]\n\n\n\nExercício 5.22Considerando a população brasileira vacinada de covid-19 até o dia 13/06/2021, de acordo com o Ministério da Saúde, de uma população vacinável de \\(160.044.909\\) milhões de pessoas, observou-se que \\(826.158\\) mil pessoas tomaram apenas a primeira dose da vacina, \\(1.950.914\\) milhões de pessoas tomaram a primeira e a segunda dose, sendo que \\(157.267.837\\) milhões de pessoas ainda não tomaram vacina. Considerando essas informações apresente a função de distribuição de \\(X\\), sendo \\(X\\) o número de doses aplicadas na população vacinável.\n\n\n\nSolução\\[\\begin{align*}\n  F_X(x) & = \\left\\{\\begin{array}{ll}\n                      0,  & \\textrm{se } x &lt; 0, \\\\\n                      &\\\\\n                      \\frac{157.267.837}{160.044.908}, & \\textrm{se } 0 \\leq x &lt; 1, \\\\\n                      &\\\\\n                      \\frac{158.093.995}{160.044.908}, & \\textrm{se } 1 \\leq x &lt; 2, \\\\\n                      &\\\\\n                      1,  & \\textrm{se } x \\geq 2. \\\\\n                    \\end{array}\n  \\right.\n\\end{align*}\\]\n\n\n\nExercício 5.23\nConsidere \\(X\\) uma variável aleatória discreta, cuja sua função de distribuição é dada por: \\[\\begin{align*}\n  F_X(x) & = \\left\\{\\begin{array}{ll}\n                      0,  & \\textrm{se } x &lt; 5, \\\\\n                      0,2, & \\textrm{se } 5 \\leq x &lt; 7, \\\\\n                      0,5, & \\textrm{se } 7 \\leq x &lt; 8, \\\\\n                      0,9, & \\textrm{se } 8 \\leq x &lt; 20, \\\\\n                      1,  & \\textrm{se } x \\geq 20. \\\\\n                    \\end{array}\n  \\right.\n\\end{align*}\\] Determine:\n\na função de probabilidade de \\(X\\);\n\\(P(X \\leq 7)\\);\n\\(P(X &lt; 7)\\);\n\\(P(8 \\leq X \\leq 18)\\);\n\\(P(X \\geq 15)\\);\nqual é o valor da esperança matemática? E a mediana? E a moda?\n\n\n\n\nSoluçãoConsidere a função de probabilidade:\n\n\n\n\\(x\\)\n5\n7\n8\n20\n\n\n\\(p_X(x)\\)\n0,2\n0,3\n0,4\n0,1\n\n\n\nAssim, temos que:\n\n\\(P(X \\geq 7) = P(X = 5) + P(X = 7) = 0,2 + 0,3 = 0,5\\);\n\\(P(X &lt; 7) = P(X = 5) = 0,2\\);\n\\(P(8 \\leq X \\leq 18) = P(X = 8) = 0,4\\);\n\\(P(X \\geq 15) = P(X = 20) = 0,1\\);\nA esperança é calculada da seguinte forma:\n\n\\[\\begin{align*}\n    E[X] & = 5 \\times 0,2 + 7 \\times 0,3 + 8 \\times 0,4 + 20 \\times 0,1 = 8,3~\\textrm{unid.},\n\\end{align*}\\]\na mediana é um número entre \\(7\\) e \\(8\\), pois abaixo e acima desses respectivos números temos \\(50\\%\\), e por conveniência assumimos \\(\\mu_d = (7 + 8) / 2 = 7,5\\) unid., isto é, o ponto médio entre os dois valores centrais, e por fim, a moda é o valor de maior chance, isto é, \\(\\mu_0 = 8\\) unid..\n\n\n\nExercício 5.24Sejam dois eventos não vazios \\(A\\) e \\(B\\) de \\(\\Omega\\), e que \\(\\omega \\in C = (A\\cap B^c)\\cup (A^c\\cap B)\\) representam os elementos que estão exatamente em um dos dois eventos, isto é, não há elementos em comum entre esses dois eventos. Assim, prove que \\[\\begin{align*}\n  P(C) & = P(A) + P(A) - 2P(A\\cap B).\n\\end{align*}\\]\n\n\n\nSoluçãoSeja \\[\n\\begin{align}\n  P(A) = P(A \\cap B) + P(A \\cap B^c)\n\\end{align}\n\\tag{5.59}\\] e \\[\n\\begin{align}\n  P(B) = P(A \\cap B) + P(B \\cap A^c)\n\\end{align}\n\\tag{5.60}\\] Considere ainda que os eventos \\(A \\cap B^c\\) e \\(A^c \\cap B\\) são disjuntos. Assim, \\[\n\\begin{align}\n    P[(A \\cap B^c)\\cup (A^c \\cap B)] &  = P(A \\cap B^c) + \\\\\n    & \\quad + P(A^c \\cap B).\\\\\n\\end{align}\n\\tag{5.61}\\] Substituindo (5.59) e (5.60) em (5.61), temos \\[\\begin{align*}\n    P[(A \\cap B^c)\\cup (A^c \\cap B)] &  = [P(A) - P(A \\cap B)] +\\\\\n    & \\quad + [P(B) - P(A \\cap B)]\\\\\n    & = P(A) + P(B) -2P(A \\cap B),\n\\end{align*}\\] o que prova o resultado.\n\n\n\nExercício 5.25No Exemplo 5.35 apresentamos a FDP de uma variável aleatória com distribuição exponencial. Porém, não provamos que de fato é uma função densidade de probabilidade. Baseado na Definição 5.31, mostre que a expressão \\(\\eqref{eq:fdpexp}\\) é uma FDP.\n\n\n\n\n\n\nJAMES, B. R. Probabilidade: um curso em nível intermediário. 3. ed. Rio de Janeiro: IMPA, 2004. p. 304\n\n\nKACHAPOVA, F.; KACHAPOV, I. Students? misconceptions about random variables. International Journal of Mathematical Education in Science and Technology, v. 143, n. 7, p. 963–971, 2012.\n\n\nMONTGOMERY, D. C.; RUNGER, G. C. Estatística Aplicada e Probabilidade para Engenheiros. 6. ed. Rio de Janeiro: LTC, 2016. p. 629\n\n\nMORETTIN, L. G. Estatística básica: probabilidade e inferência. Volume único ed. São Paulo: Pearson Prentice Hall, 2010. p. 390\n\n\nSHORT, M. On binomial quantile and proportion bounds: With applications in engineering and informatics. Communications in Statistics - Theory and Methods, v. 52, n. 12, p. 4183–4199, jun. 2023.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Probabilidades</span>"
    ]
  },
  {
    "objectID": "cap05.html#footnotes",
    "href": "cap05.html#footnotes",
    "title": "5  Probabilidades",
    "section": "",
    "text": "Em notação, temos que \\(\\{A_i\\}_{i = 1}^{n} = A_1,~A_2,~\\ldots,~, A_n\\).↩︎\nEm notação, temos que \\(\\{A_i\\}_{i \\geq 1} = A_1,~A_2,~\\ldots\\).↩︎",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Probabilidades</span>"
    ]
  },
  {
    "objectID": "cap09.html",
    "href": "cap09.html",
    "title": "9  Teoria da estimação",
    "section": "",
    "text": "Exercícios propostos",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Teoria da estimação</span>"
    ]
  },
  {
    "objectID": "cap09.html#exerprop",
    "href": "cap09.html#exerprop",
    "title": "9  Teoria da estimação",
    "section": "",
    "text": "Exercício 9.1Um experimento objetivou detectar a tensão máxima necessária (em MPa) até o aparecimento de trincas em parabrisas de caminhões pesados de uma determinada marca, do qual verifiou-se a tensão máxima até o aparecimento numa amostra de 10 parabrisas, cujos valores são: \\(9,02\\); \\(8,82\\); \\(7,63\\); \\(8,40\\); \\(9,29\\); \\(9,39\\); \\(7,79\\); \\(8,64\\); \\(7,37\\); \\(8,74\\). Considerando que os dados têm distribuição normal, apresente um estimador intervalar para a média populacional \\(\\mu\\) para a tensão máxima necessária (em MPa) até o aparecimento de trincas em parabrisas de caminhões pesados de uma determinada marca, com um nível de confiança de \\(95\\%\\) de confiança.\n\n\n\nExercício 9.2Considere \\(X_1\\), \\(X_2\\), \\(\\ldots\\), \\(X_n\\) uma amostra aleatória de uma população com distribuição exponencial de parâmero \\(\\lambda\\), tal que sua função densidade de probabilidade é dada por: \\[\\begin{align*}\n  f_X(x) & = \\left\\{\\begin{array}{ll}\n                      \\lambda e^{-\\lambda x}, & x &gt; 0, \\\\\n                      0 & \\textrm{caso contrário,}\n                    \\end{array}\\right.\n\\end{align*}\\] em que \\(\\lambda &gt; 0\\). Determine um estimador para \\(\\lambda\\) pelo método de máxima verossimilhança e pelo método dos momentos.\n\n\n\nExercício 9.3Considere \\(X_1\\), \\(X_2\\), \\(\\ldots\\), \\(X_n\\) uma amostra aleatória de uma população com distribuição uniforme no intervalo \\([0, \\theta]\\), tal que sua função densidade de probabilidade é dada por: \\[\\begin{align*}\n  f_X(x) & = \\left\\{\\begin{array}{ll}\n                        \\frac{1}{\\theta}, & 0 \\leq x \\leq \\theta\\\\\n                      0 & \\textrm{caso contrário.}\n                    \\end{array}\\right.\n\\end{align*}\\] Determine um estimador para \\(\\theta\\) pelo método de máxima verossimilhança.\n\n\n\nExercício 9.4Considere um experimento do qual se observa o desempenho de um sistema operacional implantado em uma determinada indústria de robótica. Foi verificado que o tempo de resposta (em milissegundos) de um comando do operador a uma determinada atividade usando esse sistema operacional, tem distribuição normal com desvio padrão de \\(20\\) milissegundos. Retirado uma amostra de tamanho \\(n = 100\\), com média de \\(52,05\\) milissegudos, determine um estimador intervalar para a média populacional do tempo de resposta do comando do operador a uma determinada atividade, para verificarmos o desempenho do sistema operacional implantado, com um nível de confiança de \\(95\\%\\) de probabilidade.\n\n\n\nExercício 9.5Considere duas máquinas que produzem peças, dos quais estamos avaliando a resistência à tensão dessas máquinas (MPa). Retirou-se uma amostra de 8 peças de cada máquina, e obtendo as seguintes resistências:\n\n\n\nMáquina 1\n161\n147\n162\n161\n154\n136\n142\n\n\nMáquina 2\n140\n162\n147\n133\n130\n137\n137\n\n\n\nConsidere que a resistência à tensão apresenta distribuição normal e que as variâncias populacionais são desconhecidas para os dados obtidos pelas duas máquinas, porém iguais, encontre um estimador intervalar para a diferença das médias dos dois grupos, com um nível de confiança de \\(99\\%\\) de probabilidade.\n\n\n\nExercício 9.6Verifique se o estimador de máxima verossimilhança de \\(\\hat{p} = \\bar{Y}/ k\\), de uma amostra aleatória \\(Y_1\\), \\(Y_2\\), \\(\\ldots\\), \\(Y_k\\) de uma distribuição Binomial de parâmetros \\(n\\) (conhecido) e \\(p\\), é um estimador não viesado de \\(p\\). Verifique também se esse estimador é consistente.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Teoria da estimação</span>"
    ]
  },
  {
    "objectID": "cap10.html",
    "href": "cap10.html",
    "title": "10  Teoria da decisão",
    "section": "",
    "text": "Exercícios propostos",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Teoria da decisão</span>"
    ]
  },
  {
    "objectID": "cap10.html#exerprop",
    "href": "cap10.html#exerprop",
    "title": "10  Teoria da decisão",
    "section": "",
    "text": "Exercício 10.1\nUm professor aplica um teste do tipo certo-errado com 10 questões. Queremos testar a hipótese de que o aluno está adivinhando. A hipótese nula é que o aluno acerta ao acaso as questões. A hipótese alternativa é que o aluno tem algum conhecimento. Sendo \\(p\\) a probabilidade (desconhecida) do aluno acertar cada questão, então a hipótese estatística de interesse pode ser dada como \\(H_0: p = 1/2\\). Como hipótese alternativa \\(H_1: p &gt; 1/2\\), isto é, o aluno tem algum conhecimento para resolver as questões. Determine:\n\nA probabilidade do erro tipo I, supondo que adotamos a seguinte regra de decisão: o aluno não está adivinhando se acertar 8 ou mais questões.\nQual seria a regra de decisão, se assumíssemos um nível de significância \\(\\alpha \\leq 0,20\\)?\n\n\n\n\nSolução\n\nVamos assumir que as questões são independentes e que a variável aleatória \\(X\\) denota o número de acertos entre as 10 questões. Portanto, \\(X\\) tem distribuição binomial com parâmetros \\(n = 10\\) e \\(p\\) desconhecido. Supondo que adotamos a seguinte regra de decisão: o aluno não está advinhando se acertar 8 ou mais questões. Isto equivale a \\[\\begin{align*}\n  \\textrm{Rejeitar } H_0 \\textrm{ se } & X \\geq 8.\n\\end{align*}\\] Dessa forma, a região crítica do teste é \\(C_{\\Upsilon} = \\{X: X &gt; 8\\}\\). É possível também que o aluno acerte 8 ou mais questões e esteja advinhando, isto é, podemos rejeitar \\(H_0\\) dado que ela é verdadeira. A probabilidade de que isso ocorra é: \\[\\begin{align*}\n  P(X \\geq 8|p = 1/2) & = \\sum_{k = 8}^{10}(1/2)^{k}(1 - 1/2)^{10 - k} \\approx 0,055.\n\\end{align*}\\]\nAgora, assumindo um \\(\\alpha \\leq 0,2\\), vamos observar os resutlados a seguir: \\[\\begin{align*}\n      P(X \\geq 6|p = 1/2) & = \\sum_{k = 6}^{10}(1/2)^{k}(1 - 1/2)^{10 - k} \\approx 0,3769531\\\\\n      P(X \\geq 7|p = 1/2) & = \\sum_{k = 7}^{10}(1/2)^{k}(1 - 1/2)^{10 - k} \\approx 0,171875\n      \\\\\n      P(X \\geq 8|p = 1/2) & = \\sum_{k = 8}^{10}(1/2)^{k}(1 - 1/2)^{10 - k} \\approx 0,0546875\\\\\n      P(X \\geq 9|p = 1/2) & = \\sum_{k = 9}^{10}(1/2)^{k}(1 - 1/2)^{10 - k} \\approx 0,01074219\\\\\n     \\end{align*}\\] Neste caso, verificamos que assumir como tomada de decisão de que o aluno não está adivinhando se ele acertasse no mínimo 6 questões, cometeríamos um erro de 0,3769531, sendo acima do erro adotado (\\(\\alpha \\leq 0,2\\)). Portanto, a probabilidade mais próxima e abaixo de \\(\\alpha\\), será adotar como decisão, “Rejeitar se \\(X \\geq 7\\)”.\n\n\n\n\nExercício 10.2Considere um experimento do qual se observa o desempenho de um sistema operacional implantado em uma determinada indústria de robótica. Foi verificado que o tempo de resposta (em milissegundos) de um comando do operador a uma determinada atividade usando esse sistema operacional, tem distribuição normal com desvio padrão de \\(20\\) milissegundos. Retirado uma amostra de tamanho \\(n = 100\\), com média de \\(52,05\\) ms. O fabricante nos informou que o tempo médio de resposta da máquina, devido ao sistema operacional, não ultrapassa \\(50\\) ms. Diante disso, use um teste de hipótese para verificar a informação do fabricante, ao nível de significância de \\(5\\%\\) de probabilidade.\n\n\n\nExercício 10.3Considere que a resistência à tensão apresenta distribuição normal e que as variâncias populacionais são desconhecidas para os dados obtidos pelas duas máquinas, porém iguais. Verifique por meio de um teste de hipóteses, se a resistência à tensão média da máquina 1 é superior a da máquina 2, ao nível de significância de \\(10\\%\\) de probabilidade.\n\n\n\nExercício 10.4Um estudo realizado sobre dois tipos de concreto para verificar a taxa de infiltração de água em sua estrutura foi realizado. Os dois tipos de concreto (C1 e C2) diferiam na porcentagem de material retido na peneira de abertura no processo de fabricação desses concretos, em que para fabricação de C1 os agregados retidos na peneira foram 100% de 6,3mm, ao passo que C2 os agregados retidos na peneira foram de 6,3mm (50%) e 4,75mm (50%). Um experimento (ensaio com carga variável) avaliou 40 corpos de provas desses dois tipos de concreto, e mediu a condutividade hidráulica (taxa de infiltração de água em \\(cm/s\\)), dos quais os dados são obtidos na tabela abaixo:\n\n\n\n\n\n\n\n\n\nConcreto\nAmostra\nMédia amostral (\\(cm/s\\))\nDesvio padrão amostral (\\(cm/s\\))\n\n\n\n\nC1\n40\n0,523\n0,054\n\n\nC2\n40\n0,641\n0,061\n\n\n\nConsiderando que a condutividade hidráulica tem distribuição normal, verifique se há diferenças estatísticas entre as médias populacionais das condutividades hidráulicas desses dois tipos de concreto, ao nível de significância de \\(10\\%\\) de probabilidade. Considere que as variâncias populacionais são homocedásticas.\n\n\n\nExercício 10.5\nUm estudo realizado por Seker et al. (2002) avaliaram os efeitos da energia eletromagnética de celulares, no cérebro de ratos. O experimento foi conduzido in vivo, sob dois grupos de ratos, um primeiro grupo controle sem exposição da energia eletromagética provindo dos celulares, e outro grupo teste apresentando essa exposição. Algumas variáveis foram analisada, dentre as quais, a pressão sanguínea arterial desses ratos (\\(mmHg\\)), coletadas durante o experimento. Os resultados são apresentado na tabela abaixo:\n\n\n\n\n\n\n\n\n\nGrupo\nAmostra\nMédia amostral (\\(mmHg\\))\nDesvio padrão amostral (\\(mmHg\\))\n\n\n\n\nTeste  (Grupo 1)\n9\n115\n10\n\n\nControle  (Grupo 2)\n8\n90\n5\n\n\n\nDessa forma, indagamos:\n\nPodemos afirmar que os efeitos da energia eletromagnética expostos aos ratos, proveniente de celulares, podem ter elevado a pressão sanguínea arterial dos ratos? Considere a realização do testes usando os níveis de significância a 1% e 5% de probabilidade, e que a variável mensurada para ambos os grupos apresentam distribuição normal com variâncias desconhecidas e diferentes (heterocedasticidade).\nDetermine o valor-p para o teste realidade no ítem anterior.\nPor meio de um intervalo de confiança, responda a indagação do ítem (a)\nPodemos afirmar que, em média, a pressão sanguínea do grupo teste é no mínimo \\(16~mmHg\\) maior do que a média do grupo controle, ao nível de significância de \\(5\\%\\) de probabilidade, baseado nas mesmas suposições do ítem (a)?\nComo poderíamos responder responder o ítem (d) por meio de um intervalo de confiança?\n\n\n\n\nExercício 10.6Baseado nos ítens (d) e (e) do Exercício Proposto 10.6, justifique o que levou a formular as hipóteses complementares desse problema.\n\n\n\n\n\n\nSEKER, S. S. et al. EM effects of different mobile handsets on rats’ brain2002 IEEE International Symposium on Electromagnetic Compatibility. Anais...2002",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Teoria da decisão</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "COMPANY, B. P. BP statistical review of world energy.\nLondon: British Petroleum Company, 2018.\n\n\nDEVORE, J. L. Probabilidade e Estatística para Engenharia e\nCiências. 6. ed. São Paulo: Cengage Learning, 2006. p. 692\n\n\nFERREIRA, D. F. Estatística Básica. 2 Revisada ed.\nLavras: Editora UFLA, 2009. p. 664\n\n\nJAMES, B. R. Probabilidade: um curso em nível\nintermediário. 3. ed. Rio de Janeiro: IMPA, 2004. p. 304\n\n\nKACHAPOVA, F.; KACHAPOV, I. Students? misconceptions about random\nvariables. International Journal of Mathematical Education in\nScience and Technology, v. 143, n. 7, p. 963–971, 2012.\n\n\nMAGALHÃES, M. N.; LIMA, A. C. P. DE. Noções de Probabilidade e\nEstatística. 7. ed. São Paulo: Edusp, 2015. p. 416\n\n\nMONTGOMERY, D. C.; RUNGER, G. C. Estatística Aplicada e\nProbabilidade para Engenheiros. 6. ed. Rio de Janeiro: LTC,\n2016. p. 629\n\n\nMORETTIN, L. G. Estatística básica: probabilidade e\ninferência. Volume único ed. São Paulo: Pearson Prentice Hall,\n2010. p. 390\n\n\nPRESIDENTIAL COMISSION. On the Space Shuttle Challanger\nAccident. Washington: National Aeronautics; Space\nAdministration, 1986.\n\n\nSEKER, S. S. et al. EM effects of\ndifferent mobile handsets on rats’ brain2002 IEEE\nInternational Symposium on Electromagnetic Compatibility.\nAnais...2002\n\n\nSHORT, M. On\nbinomial quantile and proportion bounds: With applications\nin engineering and informatics. Communications in Statistics\n- Theory and Methods, v. 52, n. 12, p. 4183–4199, jun. 2023.\n\n\nSILVA, J. G. C. DA. Planejamento da Pesquisa Experimental: Base\nConceitual e Metodológica. Pelotas: Instituto de Física e\nMatemática, 2007. p. 509\n\n\nTAVARES, E. L.; ANJOS, L. A. DO. Perfil antropométrico da população\nidosa brasileira. Resultados da Pesquisa Nacional sobre saúde e\nNutrição. Cad. Saúde Pública, v. 15, n. 4, p. 759–768,\n1999.\n\n\nWICKHAM, H. ggplot2: Elegant graphics for data\nanalysis. 2. ed. New York: Springer International Publishing,\n2016. p. 260",
    "crumbs": [
      "References"
    ]
  }
]